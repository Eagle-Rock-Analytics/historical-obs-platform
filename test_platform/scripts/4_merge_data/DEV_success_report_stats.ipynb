{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb530e2d",
   "metadata": {},
   "source": [
    "# QAQC flag counts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1128c",
   "metadata": {},
   "source": [
    "This function generates and exports a dataframe with counts of unique QAQC flag values per variable, in their native timestep, before hourly standardization.\n",
    "These tables are used to produce the following QAQC flag statistics for the QAQC success report:\n",
    "\n",
    "- % of all obs flagged\n",
    "\n",
    "- % of obs per var flagged\n",
    "\n",
    "- % of obs per network flagged\n",
    "\n",
    "- % of flags per QA/QC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4432f44",
   "metadata": {},
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ff277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "# New logger function\n",
    "from merge_log_config import logger\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4606f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79288b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ds_to_df(ds):\n",
    "    \"\"\"Converts xarray ds for a station to pandas df in the format needed for processing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: xr.Dataset\n",
    "        Data object with information about each network and station\n",
    "    verbose: boolean\n",
    "        Flag as to whether to print runtime statements to terminal. Default is False. Set in ALLNETWORKS_merge.py run.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        Table object with information about each network and station\n",
    "    MultiIndex: pd.DataFrame (I think)\n",
    "        Original multi-index of station and time, to be used on conversion back to ds\n",
    "    attrs:\n",
    "        Save ds attributes to inherent to the final merged file\n",
    "    var_attrs:\n",
    "        Save variable attributes to inherent to the final merged file\n",
    "    \"\"\"\n",
    "\n",
    "    # Save attributes to inherent them to the final merged file\n",
    "    attrs = ds.attrs\n",
    "    var_attrs = {var: ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    df = ds.to_dataframe()\n",
    "\n",
    "    # Save instrumentation heights\n",
    "    if \"anemometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"anemometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.anemometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling anemometer_height_m with NaN.\")\n",
    "            df[\"anemometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "    if \"thermometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"thermometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.thermometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling thermometer_height_m with NaN.\")\n",
    "            df[\"thermometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "\n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df[\"station\"] = station\n",
    "\n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "\n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    return df, MultiIndex, attrs, var_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a144f0",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f56e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eraqc_counts_original_timestep(df: pd.DataFrame, network: str, station: str) -> None:\n",
    "    \"\"\"\n",
    "    Generates a dataframe of raw qaqc flag value counts for every variable,\n",
    "    in their native timestep, before hourly standardization.\n",
    "    Exports the dataframe as a csv to AWS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        station dataset converted to dataframe through QAQC pipeline\n",
    "    network: str\n",
    "        network name\n",
    "    station: str\n",
    "        station name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # identify _eraqc variables\n",
    "    eraqc_vars = [var for var in df.columns if \"_eraqc\" in var]\n",
    "\n",
    "    # filter df for only qaqc columns\n",
    "    # also replace Nan values with 'no_flag' for two reasons:\n",
    "    #   1. to enable us to count total observations for the success report\n",
    "    #   2. to clarify what the Nan value indicates\n",
    "    df = df[eraqc_vars].fillna('no_flag') \n",
    "\n",
    "    # generate df of counts of each unique flag for each variable\n",
    "    # fill all Nan values with 0, since Nan = no observations counted\n",
    "    flag_counts = df.apply(pd.Series.value_counts).fillna(0)\n",
    "\n",
    "    # rename columns\n",
    "    flag_counts.columns = flag_counts.columns.str.replace(\"_eraqc\", \"\", regex=True)\n",
    "\n",
    "    # rename index (i.e. eraqc values) and then reset index\n",
    "    flag_counts = flag_counts.rename_axis(\"eraqc_flag_values\").reset_index()\n",
    "\n",
    "    # send file to AWS\n",
    "    new_buffer = StringIO()\n",
    "    flag_counts.to_csv(new_buffer, index=False)\n",
    "    content = new_buffer.getvalue()\n",
    "    key = f\"4_merge_wx/{network}/eraqc_counts/original_timestep_{station}.csv\"\n",
    "\n",
    "    s3_cl.put_object(\n",
    "        Bucket=bucket_name,\n",
    "        Body=content,\n",
    "        Key=key,\n",
    "    )\n",
    "\n",
    "    return None # flag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f64b9a",
   "metadata": {},
   "source": [
    "### Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b92a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"s3://wecc-historical-wx/3_qaqc_wx/VALLEYWATER/VALLEYWATER_6001.zarr\"\n",
    "url = \"s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_72493023230.zarr\"\n",
    "ds = xr.open_zarr(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, MultiIndex, attrs, var_attrs = merge_ds_to_df(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'ASOSAWOS'\n",
    "station = \"ASOSAWOS_72493023230\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5592f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if set to None\n",
    "# eraqc_counts(df, network, station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff41585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if set to flag_counts\n",
    "flag_counts = eraqc_counts(df, network, station)\n",
    "flag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26fc3c",
   "metadata": {},
   "source": [
    "### CHECK: let's look at the output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = f\"4_merge_wx/{network}/eraqc_counts/original_timestep_{station}.csv\"\n",
    "\n",
    "list_import = s3_cl.get_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=key,\n",
    ")\n",
    "\n",
    "flag_counts_table = pd.read_csv(BytesIO(list_import[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da141354",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_counts_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
