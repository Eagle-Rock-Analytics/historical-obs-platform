{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station Matching\n",
    "\n",
    "The goal of this notebook is to identify stations that changed IDs. The IDs fo these pairs of matching stations will be stored in a csv, which then be fed into concentation as a lookup table. Pairs will receive unique flags, with the older station receiving a different flag than the newer station.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from functools import reduce\n",
    "import datetime\n",
    "from pandas import *\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "import tempfile  # Used for downloading (and then deleting) netcdfs to local drive from s3 bucket\n",
    "\n",
    "import s3fs\n",
    "\n",
    "# import tempfile  # Used for downloading (and then deleting) netcdfs to local drive from s3 bucket\n",
    "import os\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=ShapelyDeprecationWarning\n",
    ")  # Warning is raised when creating Point object from coords. Can't figure out why.\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "s3 = s3fs.S3FileSystem #must be set to this to use such commands as ls\n",
    "#s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "## AWS buckets\n",
    "bucket = \"wecc-historical-wx\"\n",
    "qaqcdir = \"3_qaqc_wx/VALLEYWATER/\"\n",
    "mergedir = \"4_merge_wx/VALLEYWATER/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define temporary directory in local drive for downloading data from S3 bucket\n",
    "# If the directory doesn't exist, it will be created\n",
    "# If we used zarr, this wouldn't be neccessary\n",
    "temp_dir = \"./tmp\"\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.mkdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nc_from_s3_clean(network_name, station_id, temp_dir):\n",
    "    \"\"\"Read netcdf file containing station data for a single station of interest from AWS s3 bucket\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network_name: str\n",
    "        Name of network (i.e. \"ASOSAWOS\")\n",
    "        Must correspond with a valid directory in the s3 bucket (i.e. \"CAHYDRO\", \"CDEC\", \"ASOSAWOS\")\n",
    "    station_id: str\n",
    "        Station identifier; i.e. the name of the netcdf file in the bucket (i.e. \"ASOSAWOS_72012200114.nc\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    station_data: xr.Dataset\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The data is first downloaded from AWS into a tempfile, which is then deleted after xarray reads in the file\n",
    "    I'd like to see us use a zarr workflow if possible to avoid this.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Temp file for downloading from s3\n",
    "    temp_file = tempfile.NamedTemporaryFile(\n",
    "        dir=temp_dir, prefix=\"\", suffix=\".nc\", delete=True\n",
    "    )\n",
    "\n",
    "    # Create s3 file system\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "    # Get URL to netcdf in S3\n",
    "    s3_url = \"s3://wecc-historical-wx/2_clean_wx/{}/{}.nc\".format(\n",
    "        network_name, station_id\n",
    "    )\n",
    "\n",
    "    # Read in the data using xarray\n",
    "    s3_file_obj = s3.get(s3_url, temp_file.name)\n",
    "    station_data = xr.open_dataset(temp_file.name, engine=\"h5netcdf\").load()\n",
    "\n",
    "    # Close temporary file\n",
    "    temp_file.close()\n",
    "\n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zarr_from_s3(station_id, temp_dir):\n",
    "    \"\"\"Read zarr file containing station data for a single station of interest from AWS s3 bucket\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network_name: str\n",
    "        Name of network (i.e. \"ASOSAWOS\")\n",
    "        Must correspond with a valid directory in the s3 bucket (i.e. \"CAHYDRO\", \"CDEC\", \"ASOSAWOS\")\n",
    "    station_id: str\n",
    "        Station identifier; i.e. the name of the netcdf file in the bucket (i.e. \"ASOSAWOS_72012200114.nc\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    station_data: xr.Dataset\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The data is first downloaded from AWS into a tempfile, which is then deleted after xarray reads in the file\n",
    "    \"\"\"\n",
    "\n",
    "    # Temp file for downloading from s3\n",
    "    temp_file = tempfile.NamedTemporaryFile(\n",
    "        dir=temp_dir, prefix=\"\", suffix=\".zarr\", delete=True\n",
    "    )\n",
    "\n",
    "    # Create s3 file system\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "    # Get URL to netcdf in S3\n",
    "    s3_url = \"s3://wecc-historical-wx/3_qaqc_wx/VALLEYWATER/VALLEYWATER_{}.zarr\".format(\n",
    "        station_id\n",
    "    )\n",
    "    print(s3_url)\n",
    "\n",
    "    # Read in the data using xarray\n",
    "    s3_file_obj = s3.get(s3_url, temp_file.name)\n",
    "    station_data = xr.open_dataset(temp_file.name, engine=\"zarr\").load()\n",
    "\n",
    "    # Close temporary file\n",
    "    temp_file.close()\n",
    "\n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaqc_ds_to_df(ds, verbose=False):\n",
    "    \"\"\"Converts xarray ds for a station to pandas df in the format needed for the pipeline\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        input data from the clean step\n",
    "    verbose : bool, optional\n",
    "        if True, provides runtime output to the terminal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        converted xr.Dataset into dataframe\n",
    "    MultiIndex : pd.Index\n",
    "        multi-index of station and time\n",
    "    attrs : list of str\n",
    "        attributes from xr.Dataset\n",
    "    var_attrs : list of str\n",
    "        variable attributes from xr.Dataset\n",
    "    era_qc_vars : list of str\n",
    "        QAQC variables\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is the notebook friendly version (no logger statements).\n",
    "    \"\"\"\n",
    "    ## Add qc_flag variable for all variables, including elevation;\n",
    "    ## defaulting to nan for fill value that will be replaced with qc flag\n",
    "\n",
    "    for key, val in ds.variables.items():\n",
    "        if val.dtype == object:\n",
    "            if key == \"station\":\n",
    "                if str in [type(v) for v in ds[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "            else:\n",
    "                if str in [type(v) for v in ds.isel(station=0)[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "\n",
    "    exclude_qaqc = [\n",
    "        \"time\",\n",
    "        \"station\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"qaqc_process\",\n",
    "        \"sfcWind_method\",\n",
    "        \"pr_duration\",\n",
    "        \"pr_depth\",\n",
    "        \"PREC_flag\",\n",
    "        \"rsds_duration\",\n",
    "        \"rsds_flag\",\n",
    "        \"anemometer_height_m\",\n",
    "        \"thermometer_height_m\",\n",
    "    ]  # lat, lon have different qc check\n",
    "\n",
    "    raw_qc_vars = []  # qc_variable for each data variable, will vary station to station\n",
    "    era_qc_vars = []  # our ERA qc variable\n",
    "    old_era_qc_vars = []  # our ERA qc variable\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if \"q_code\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variable, need to keep for comparison, then drop\n",
    "        if \"_qc\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variables, need to keep for comparison, then drop\n",
    "        if \"_eraqc\" in var:\n",
    "            era_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variables, need to keep for comparison, then drop\n",
    "            old_era_qc_vars.append(var)\n",
    "\n",
    "    print(f\"era_qc existing variables:\\n{era_qc_vars}\")\n",
    "    n_qc = len(era_qc_vars)\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if var not in exclude_qaqc and var not in raw_qc_vars and \"_eraqc\" not in var:\n",
    "            qc_var = var + \"_eraqc\"  # variable/column label\n",
    "\n",
    "            # if qaqc var does not exist, adds new variable in shape of original variable with designated nan fill value\n",
    "            if qc_var not in era_qc_vars:\n",
    "                print(f\"nans created for {qc_var}\")\n",
    "                ds = ds.assign({qc_var: xr.ones_like(ds[var]) * np.nan})\n",
    "                era_qc_vars.append(qc_var)\n",
    "\n",
    "    print(\"{} created era_qc variables\".format(len(era_qc_vars) - len(old_era_qc_vars)))\n",
    "    if len(era_qc_vars) != n_qc:\n",
    "        print(\"{}\".format(np.setdiff1d(old_era_qc_vars, era_qc_vars)))\n",
    "\n",
    "    # Save attributes to inheret them to the QAQC'ed file\n",
    "    attrs = ds.attrs\n",
    "    var_attrs = {var: ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        df = ds.to_dataframe()\n",
    "\n",
    "    # instrumentation heights\n",
    "    if \"anemometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"anemometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.anemometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            print(\"Filling anemometer_height_m with NaN.\", flush=True)\n",
    "            df[\"anemometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "    if \"thermometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"thermometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.thermometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            print(\"Filling thermometer_height_m with NaN.\", flush=True)\n",
    "            df[\"thermometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "\n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df[\"station\"] = station\n",
    "\n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "\n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    # Add time variables needed by multiple functions\n",
    "    df[\"hour\"] = pd.to_datetime(df[\"time\"]).dt.hour\n",
    "    df[\"day\"] = pd.to_datetime(df[\"time\"]).dt.day\n",
    "    df[\"month\"] = pd.to_datetime(df[\"time\"]).dt.month\n",
    "    df[\"year\"] = pd.to_datetime(df[\"time\"]).dt.year\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.date\n",
    "\n",
    "    return df  # , MultiIndex, attrs, var_attrs, era_qc_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identify Matching Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identical latitiude and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in ASOSAWOS stations\n",
    "\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "asosawos = s3_cl.get_object(\n",
    "    Bucket=\"wecc-historical-wx\", Key=\"1_raw_wx/ASOSAWOS/stationlist_ASOSAWOS.csv\"\n",
    ")\n",
    "asosawos_list = pd.read_csv(BytesIO(asosawos[\"Body\"].read()))\n",
    "\n",
    "\n",
    "print(asosawos_list) # 399 records (last two are nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Round asosawos down to 3 decimal points of accuracy\n",
    "asosawos_round = asosawos_list.round({\"LAT\": 3, \"LON\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0    NCDCID   WBAN    COOPID CALL             NAME  \\\n",
      "231         231  20022657  24027  487845.0  RKS  ROCK SPRINGS AP   \n",
      "397         397  20022657  24027  487845.0  RKS  ROCK SPRINGS AP   \n",
      "\n",
      "             ALTNAME        COUNTRY  ST      COUNTY     LAT      LON  \\\n",
      "231  ROCK SPRINGS AP  UNITED STATES  WY  SWEETWATER  41.595 -109.053   \n",
      "397              NaN  UNITED STATES  WY  SWEETWATER  41.595 -109.053   \n",
      "\n",
      "          ELEV  UTC                             STNTYPE   STARTDATE  \\\n",
      "231  2059.8384   -7  AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC  20010517.0   \n",
      "397  2059.8384   -7  AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC         NaN   \n",
      "\n",
      "    GHCN-DailyID  Barometer_elev  Anemometer_elev  \n",
      "231  USW00024027          6763.0             33.0  \n",
      "397          NaN             NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "print(asosawos_round[asosawos_round.duplicated(subset=['LAT','LON'], keep=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations within a certain distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approach 1: using sjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into GeoDataFrames\n",
    "# using EPSG 3310\n",
    "\n",
    "gdf_asosawos = gpd.GeoDataFrame(asosawos_list, \n",
    "                        geometry=[Point(lon, lat) for lon, lat in zip(asosawos_list['LON'], asosawos_list['LAT'])],\n",
    "                        crs=\"EPSG:4326\").to_crs(epsg=3310)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a buffer around points in gdf1 (e.g., 10 km buffer)\n",
    "gdf_asosawos['buffer'] = gdf_asosawos.geometry.buffer(.1)  # Buffer in degrees, 0.1 degrees approx equals 10 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial join using the buffer\n",
    "merged = gpd.sjoin(gdf_asosawos, gdf_asosawos[['geometry', 'buffer']], how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# The 'merged' GeoDataFrame contains points from gdf_isd that are within the buffer around points in gdf_asosawos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged) # there are not ISD stations within 10km of an ASOSAWOS station missed by the exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the nearest point in the geodataframe\n",
    "\n",
    "# insert emtpy column\n",
    "\n",
    "gdf_asosawos['nearest_station'] = pd.Series(dtype='U16')\n",
    "gdf_asosawos['distance'] = pd.Series(dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in gdf_asosawos.iterrows():\n",
    "    point = row.geometry\n",
    "    multipoint = gdf_asosawos.drop(index, axis=0).geometry.unary_union\n",
    "    queried_geom, nearest_geom = nearest_points(point, multipoint)\n",
    "    dist_from_point = \n",
    "    gdf_asosawos.loc[index, 'nearest_geometry'] = nearest_geom\n",
    "    gdf_asosawos.loc[index, 'distance'] = nearest_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NCDCID</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>COOPID</th>\n",
       "      <th>CALL</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ALTNAME</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>...</th>\n",
       "      <th>STNTYPE</th>\n",
       "      <th>STARTDATE</th>\n",
       "      <th>GHCN-DailyID</th>\n",
       "      <th>Barometer_elev</th>\n",
       "      <th>Anemometer_elev</th>\n",
       "      <th>geometry</th>\n",
       "      <th>buffer</th>\n",
       "      <th>nearest_station</th>\n",
       "      <th>distance</th>\n",
       "      <th>nearest_geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001445</td>\n",
       "      <td>93107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NKX</td>\n",
       "      <td>SAN DIEGO MIRAMAR NAS</td>\n",
       "      <td>SAN DIEGO MIRAMAR NAS</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>CA</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>...</td>\n",
       "      <td>ASOS,MILITARY</td>\n",
       "      <td>19460501.0</td>\n",
       "      <td>USW00093107</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (268594.210 -567731.751)</td>\n",
       "      <td>POLYGON ((268594.310 -567731.751, 268594.310 -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (268380.7766827465 -573515.895529184)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20001392</td>\n",
       "      <td>93115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NRS</td>\n",
       "      <td>IMPERIAL BEACH REAM FLD NAS</td>\n",
       "      <td>IMPERIAL BEACH REAM FLD NAS</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>CA</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>...</td>\n",
       "      <td>ASOS</td>\n",
       "      <td>19900601.0</td>\n",
       "      <td>USW00093115</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>POINT (271115.479 -600748.790)</td>\n",
       "      <td>POLYGON ((271115.579 -600748.790, 271115.579 -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (282674.1091138162 -599519.0084458143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20001424</td>\n",
       "      <td>23199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJK</td>\n",
       "      <td>EL CENTRO NAF</td>\n",
       "      <td>EL CENTRO NAF</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>CA</td>\n",
       "      <td>IMPERIAL</td>\n",
       "      <td>...</td>\n",
       "      <td>ASOS</td>\n",
       "      <td>19900601.0</td>\n",
       "      <td>USW00023199</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>POINT (406379.109 -566292.451)</td>\n",
       "      <td>POLYGON ((406379.209 -566292.451, 406379.208 -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (414534.71525172977 -565668.0918465396)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20003403</td>\n",
       "      <td>23061</td>\n",
       "      <td>50130.0</td>\n",
       "      <td>ALS</td>\n",
       "      <td>ALAMOSA-BERGMAN FLD</td>\n",
       "      <td>ALAMOSA-BERGMAN FLD</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>CO</td>\n",
       "      <td>ALAMOSA</td>\n",
       "      <td>...</td>\n",
       "      <td>ASOS,COOP,PLCD,WXSVC</td>\n",
       "      <td>19920901.0</td>\n",
       "      <td>USW00023061</td>\n",
       "      <td>7536.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>POINT (1244561.911 28820.201)</td>\n",
       "      <td>POLYGON ((1244562.011 28820.201, 1244562.010 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1304213.5410201757 44831.97136883857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20003486</td>\n",
       "      <td>93058</td>\n",
       "      <td>56740.0</td>\n",
       "      <td>PUB</td>\n",
       "      <td>PUEBLO MEM AP</td>\n",
       "      <td>PUEBLO MEM AP</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>CO</td>\n",
       "      <td>PUEBLO</td>\n",
       "      <td>...</td>\n",
       "      <td>ASOS,COOP,PLCD,WXSVC</td>\n",
       "      <td>19921001.0</td>\n",
       "      <td>USW00093058</td>\n",
       "      <td>4655.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>POINT (1347557.192 140631.522)</td>\n",
       "      <td>POLYGON ((1347557.292 140631.522, 1347557.291 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1318986.009418833 179847.9929464655)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>30003059</td>\n",
       "      <td>94086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PNA</td>\n",
       "      <td>PINEDALE WENZ FLD AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>WY</td>\n",
       "      <td>SUBLETTE</td>\n",
       "      <td>...</td>\n",
       "      <td>AWOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (835061.761 575502.976)</td>\n",
       "      <td>POLYGON ((835061.861 575502.976, 835061.861 57...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (812853.3423008773 548915.6029244149)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>20022657</td>\n",
       "      <td>24027</td>\n",
       "      <td>487845.0</td>\n",
       "      <td>RKS</td>\n",
       "      <td>ROCK SPRINGS AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>WY</td>\n",
       "      <td>SWEETWATER</td>\n",
       "      <td>...</td>\n",
       "      <td>AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (911903.967 450185.982)</td>\n",
       "      <td>POLYGON ((911904.067 450185.982, 911904.067 45...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (911903.9670986698 450185.98208982404)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>30083363</td>\n",
       "      <td>342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FWZ</td>\n",
       "      <td>S PASS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>WY</td>\n",
       "      <td>FREMONT</td>\n",
       "      <td>...</td>\n",
       "      <td>AWOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (922215.161 554338.873)</td>\n",
       "      <td>POLYGON ((922215.261 554338.873, 922215.261 55...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (922956.2946331993 587702.7931789225)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>30083498</td>\n",
       "      <td>475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAA</td>\n",
       "      <td>SHIVELY FIELD AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>WY</td>\n",
       "      <td>CARBON</td>\n",
       "      <td>...</td>\n",
       "      <td>AWOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1098509.279 457151.554)</td>\n",
       "      <td>POLYGON ((1098509.379 457151.554, 1098509.378 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1062617.9563132052 492836.3751639202)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>30083362</td>\n",
       "      <td>341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JPD</td>\n",
       "      <td>TEN SLEEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>WY</td>\n",
       "      <td>WASHAKIE</td>\n",
       "      <td>...</td>\n",
       "      <td>AWOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1029940.963 750156.072)</td>\n",
       "      <td>POLYGON ((1029941.063 750156.072, 1029941.062 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (1062061.072136632 780376.6406068588)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    NCDCID   WBAN    COOPID CALL                         NAME  \\\n",
       "0             0  10001445  93107       NaN  NKX        SAN DIEGO MIRAMAR NAS   \n",
       "1             1  20001392  93115       NaN  NRS  IMPERIAL BEACH REAM FLD NAS   \n",
       "2             2  20001424  23199       NaN  NJK                EL CENTRO NAF   \n",
       "3             3  20003403  23061   50130.0  ALS          ALAMOSA-BERGMAN FLD   \n",
       "4             4  20003486  93058   56740.0  PUB                PUEBLO MEM AP   \n",
       "..          ...       ...    ...       ...  ...                          ...   \n",
       "396         396  30003059  94086       NaN  PNA         PINEDALE WENZ FLD AP   \n",
       "397         397  20022657  24027  487845.0  RKS              ROCK SPRINGS AP   \n",
       "398         398  30083363    342       NaN  FWZ                       S PASS   \n",
       "399         399  30083498    475       NaN  SAA             SHIVELY FIELD AP   \n",
       "400         400  30083362    341       NaN  JPD                    TEN SLEEP   \n",
       "\n",
       "                         ALTNAME        COUNTRY  ST      COUNTY  ...  \\\n",
       "0          SAN DIEGO MIRAMAR NAS  UNITED STATES  CA   SAN DIEGO  ...   \n",
       "1    IMPERIAL BEACH REAM FLD NAS  UNITED STATES  CA   SAN DIEGO  ...   \n",
       "2                  EL CENTRO NAF  UNITED STATES  CA    IMPERIAL  ...   \n",
       "3            ALAMOSA-BERGMAN FLD  UNITED STATES  CO     ALAMOSA  ...   \n",
       "4                  PUEBLO MEM AP  UNITED STATES  CO      PUEBLO  ...   \n",
       "..                           ...            ...  ..         ...  ...   \n",
       "396                          NaN  UNITED STATES  WY    SUBLETTE  ...   \n",
       "397                          NaN  UNITED STATES  WY  SWEETWATER  ...   \n",
       "398                          NaN  UNITED STATES  WY     FREMONT  ...   \n",
       "399                          NaN  UNITED STATES  WY      CARBON  ...   \n",
       "400                          NaN  UNITED STATES  WY    WASHAKIE  ...   \n",
       "\n",
       "                                STNTYPE   STARTDATE  GHCN-DailyID  \\\n",
       "0                         ASOS,MILITARY  19460501.0   USW00093107   \n",
       "1                                  ASOS  19900601.0   USW00093115   \n",
       "2                                  ASOS  19900601.0   USW00023199   \n",
       "3                  ASOS,COOP,PLCD,WXSVC  19920901.0   USW00023061   \n",
       "4                  ASOS,COOP,PLCD,WXSVC  19921001.0   USW00093058   \n",
       "..                                  ...         ...           ...   \n",
       "396                                AWOS         NaN           NaN   \n",
       "397  AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC         NaN           NaN   \n",
       "398                                AWOS         NaN           NaN   \n",
       "399                                AWOS         NaN           NaN   \n",
       "400                                AWOS         NaN           NaN   \n",
       "\n",
       "     Barometer_elev Anemometer_elev                        geometry  \\\n",
       "0          -99999.0             NaN  POINT (268594.210 -567731.751)   \n",
       "1              20.0            33.0  POINT (271115.479 -600748.790)   \n",
       "2          -99999.0            33.0  POINT (406379.109 -566292.451)   \n",
       "3            7536.0            33.0   POINT (1244561.911 28820.201)   \n",
       "4            4655.0            33.0  POINT (1347557.192 140631.522)   \n",
       "..              ...             ...                             ...   \n",
       "396             NaN             NaN   POINT (835061.761 575502.976)   \n",
       "397             NaN             NaN   POINT (911903.967 450185.982)   \n",
       "398             NaN             NaN   POINT (922215.161 554338.873)   \n",
       "399             NaN             NaN  POINT (1098509.279 457151.554)   \n",
       "400             NaN             NaN  POINT (1029940.963 750156.072)   \n",
       "\n",
       "                                                buffer  nearest_station  \\\n",
       "0    POLYGON ((268594.310 -567731.751, 268594.310 -...              NaN   \n",
       "1    POLYGON ((271115.579 -600748.790, 271115.579 -...              NaN   \n",
       "2    POLYGON ((406379.209 -566292.451, 406379.208 -...              NaN   \n",
       "3    POLYGON ((1244562.011 28820.201, 1244562.010 2...              NaN   \n",
       "4    POLYGON ((1347557.292 140631.522, 1347557.291 ...              NaN   \n",
       "..                                                 ...              ...   \n",
       "396  POLYGON ((835061.861 575502.976, 835061.861 57...              NaN   \n",
       "397  POLYGON ((911904.067 450185.982, 911904.067 45...              NaN   \n",
       "398  POLYGON ((922215.261 554338.873, 922215.261 55...              NaN   \n",
       "399  POLYGON ((1098509.379 457151.554, 1098509.378 ...              NaN   \n",
       "400  POLYGON ((1029941.063 750156.072, 1029941.062 ...              NaN   \n",
       "\n",
       "     distance                               nearest_geometry  \n",
       "0         NaN    POINT (268380.7766827465 -573515.895529184)  \n",
       "1         NaN   POINT (282674.1091138162 -599519.0084458143)  \n",
       "2         NaN  POINT (414534.71525172977 -565668.0918465396)  \n",
       "3         NaN   POINT (1304213.5410201757 44831.97136883857)  \n",
       "4         NaN    POINT (1318986.009418833 179847.9929464655)  \n",
       "..        ...                                            ...  \n",
       "396       NaN    POINT (812853.3423008773 548915.6029244149)  \n",
       "397       NaN   POINT (911903.9670986698 450185.98208982404)  \n",
       "398       NaN    POINT (922956.2946331993 587702.7931789225)  \n",
       "399       NaN   POINT (1062617.9563132052 492836.3751639202)  \n",
       "400       NaN    POINT (1062061.072136632 780376.6406068588)  \n",
       "\n",
       "[401 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_asosawos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approach 2: distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to calculate the distance between points\n",
    "\n",
    "def distance_sort_filter(row, df2, buffer=None, id=False):\n",
    "\n",
    "    dist = df2.geometry.distance(row).sort_values()\n",
    "\n",
    "    if buffer:\n",
    "        dist = dist[dist<buffer]\n",
    "\n",
    "    if id:\n",
    "        distances = {df2.loc[idx]['WBAN']:value for idx,value in zip(dist.index, dist.values)}\n",
    "    else:\n",
    "        distances = {idx:value for idx,value in zip(dist.index, dist.values)}\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a csv with three columns\n",
    "1. ID: station ID (which column do I use for this?)\n",
    "2. match flag: stations that match each other have the same flags (1,2,3,4,etc.)\n",
    "3. age flag: which station in each pair is older (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NCDCID</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>COOPID</th>\n",
       "      <th>CALL</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ALTNAME</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV</th>\n",
       "      <th>UTC</th>\n",
       "      <th>STNTYPE</th>\n",
       "      <th>STARTDATE</th>\n",
       "      <th>GHCN-DailyID</th>\n",
       "      <th>Barometer_elev</th>\n",
       "      <th>Anemometer_elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>20022657</td>\n",
       "      <td>24027</td>\n",
       "      <td>487845.0</td>\n",
       "      <td>RKS</td>\n",
       "      <td>ROCK SPRINGS AP</td>\n",
       "      <td>ROCK SPRINGS AP</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>WY</td>\n",
       "      <td>SWEETWATER</td>\n",
       "      <td>41.595</td>\n",
       "      <td>-109.053</td>\n",
       "      <td>2059.8384</td>\n",
       "      <td>-7</td>\n",
       "      <td>AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC</td>\n",
       "      <td>20010517.0</td>\n",
       "      <td>USW00024027</td>\n",
       "      <td>6763.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>20022657</td>\n",
       "      <td>24027</td>\n",
       "      <td>487845.0</td>\n",
       "      <td>RKS</td>\n",
       "      <td>ROCK SPRINGS AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>WY</td>\n",
       "      <td>SWEETWATER</td>\n",
       "      <td>41.595</td>\n",
       "      <td>-109.053</td>\n",
       "      <td>2059.8384</td>\n",
       "      <td>-7</td>\n",
       "      <td>AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    NCDCID   WBAN    COOPID CALL             NAME  \\\n",
       "231         231  20022657  24027  487845.0  RKS  ROCK SPRINGS AP   \n",
       "397         397  20022657  24027  487845.0  RKS  ROCK SPRINGS AP   \n",
       "\n",
       "             ALTNAME        COUNTRY  ST      COUNTY     LAT      LON  \\\n",
       "231  ROCK SPRINGS AP  UNITED STATES  WY  SWEETWATER  41.595 -109.053   \n",
       "397              NaN  UNITED STATES  WY  SWEETWATER  41.595 -109.053   \n",
       "\n",
       "          ELEV  UTC                             STNTYPE   STARTDATE  \\\n",
       "231  2059.8384   -7  AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC  20010517.0   \n",
       "397  2059.8384   -7  AIRWAYS,ASOS,AWOS,COOP,USHCN,WXSVC         NaN   \n",
       "\n",
       "    GHCN-DailyID  Barometer_elev  Anemometer_elev  \n",
       "231  USW00024027          6763.0             33.0  \n",
       "397          NaN             NaN              NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = asosawos_round[asosawos_round['WBAN']==24027]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function - generate station map\n",
    "def get_maps(subdf1, subdf2, shapepath):\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "    # Make a geodataframe.\n",
    "    gdf1 = gpd.GeoDataFrame(subdf1, geometry=gpd.points_from_xy(subdf1.LON, subdf1.LAT))\n",
    "    gdf2 = gpd.GeoDataFrame(subdf2, geometry=gpd.points_from_xy(subdf2.LON, subdf2.LAT))\n",
    "\n",
    "    gdf1.set_crs(epsg=4326, inplace=True) # Set CRS\n",
    "    gdf2.set_crs(epsg=4326, inplace=True) # Set CRS\n",
    "    \n",
    "    # Project data to match base tiles.\n",
    "    gdf1_wm = gdf1.to_crs(epsg=3857) # Web mercator\n",
    "    gdf2_wm = gdf2.to_crs(epsg=3857) # Web mercator\n",
    "\n",
    "    # Read in geometry of continental US.\n",
    "    us = gpd.read_file(shapepath)\n",
    "\n",
    "    # Remove territories, AK, HI\n",
    "    rem_list = [\"HI\", \"AK\", \"MP\", \"GU\", \"AS\", \"PR\", \"VI\"]\n",
    "    us = us.loc[us.STUSPS.isin(rem_list) == False]\n",
    "\n",
    "    # Use to clip stations\n",
    "    us = us.to_crs(epsg = 3857)\n",
    "\n",
    "    gdf1_us = gdf1_wm.clip(us)\n",
    "    gdf2_us = gdf2_wm.clip(us)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "    # Version 1 - full map\n",
    "    ax = gdf1_us.plot(color='blue', figsize=(15, 15), alpha=0.6, markersize=5, legend=True)\n",
    "    gdf2_us.plot(ax=ax, color='red', alpha=0.6, markersize=5, legend=True)  # Plot gdf2 on same axis, with a different color\n",
    "\n",
    "    # Add basemap\n",
    "    cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "    # Set up the axis\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Optional: Create custom legend\n",
    "    ax.legend(['asosawos', 'isd'], loc='upper right')\n",
    "\n",
    "    \n",
    "shapepath = \"s3://wecc-historical-wx/0_maps/tl_2021_us_state\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find matches within a certain distance - Approach 3\n",
    "\n",
    "using spatial join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
