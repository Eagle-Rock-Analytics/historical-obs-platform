{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d0a3ef",
   "metadata": {},
   "source": [
    "# QAQC flag counts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe6225",
   "metadata": {},
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14260284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from functools import reduce\n",
    "\n",
    "import inspect\n",
    "\n",
    "import logging\n",
    "# Create a simple logger that just prints to the console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60e983a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9fdbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ds_to_df(ds):\n",
    "    \"\"\"Converts xarray ds for a station to pandas df in the format needed for processing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: xr.Dataset\n",
    "        Data object with information about each network and station\n",
    "    verbose: boolean\n",
    "        Flag as to whether to print runtime statements to terminal. Default is False. Set in ALLNETWORKS_merge.py run.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        Table object with information about each network and station\n",
    "    MultiIndex: pd.DataFrame (I think)\n",
    "        Original multi-index of station and time, to be used on conversion back to ds\n",
    "    attrs:\n",
    "        Save ds attributes to inherent to the final merged file\n",
    "    var_attrs:\n",
    "        Save variable attributes to inherent to the final merged file\n",
    "    \"\"\"\n",
    "\n",
    "    # Save attributes to inherent them to the final merged file\n",
    "    attrs = ds.attrs\n",
    "    var_attrs = {var: ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    df = ds.to_dataframe()\n",
    "\n",
    "    # Save instrumentation heights\n",
    "    if \"anemometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"anemometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.anemometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling anemometer_height_m with NaN.\")\n",
    "            df[\"anemometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "    if \"thermometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"thermometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.thermometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling thermometer_height_m with NaN.\")\n",
    "            df[\"thermometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "\n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df[\"station\"] = station\n",
    "\n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "\n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    return df, MultiIndex, attrs, var_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed0f64",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f59fe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include count of total number of observations\n",
    "\n",
    "def eraqc_counts_hourly_timestep(df: pd.DataFrame, network: str, station: str) -> None:\n",
    "    \"\"\"\n",
    "    Generates a dataframe of raw qaqc flag value counts for every variable,\n",
    "    for the hourly timestep, after hourly standardization.\n",
    "    Exports the dataframe as a csv to AWS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        station dataset converted to dataframe through QAQC pipeline\n",
    "    network: str\n",
    "        network name\n",
    "    station: str\n",
    "        station name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # identify _eraqc variables\n",
    "    eraqc_vars = [var for var in df.columns if \"_eraqc\" in var]\n",
    "\n",
    "    # filter df for only qaqc columns\n",
    "    # also replace Nan values with 'no_flag' for two reasons:\n",
    "    #   1. to enable us to count total observations for the success report\n",
    "    #   2. to clarify what the Nan value indicates\n",
    "    df = df[eraqc_vars].fillna('no_flag') \n",
    "\n",
    "    # generate df of counts of each unique flag for each variable\n",
    "    # fill all Nan values with 0, since Nan = no observations counted\n",
    "    flag_counts = df.apply(\n",
    "        lambda x: x.str.split(\",\", expand=True).stack().value_counts()\n",
    "    ).fillna(0)\n",
    "\n",
    "    # add a row with total counts per variable\n",
    "    # flag_counts['total_obs'] = \n",
    "\n",
    "    # rename columns\n",
    "    flag_counts.columns = flag_counts.columns.str.replace(\"_eraqc\", \"\", regex=True)\n",
    "\n",
    "    # rename index (i.e. eraqc values) and then reset index\n",
    "    flag_counts = flag_counts.rename_axis(\"eraqc_flag_values\").reset_index()\n",
    "\n",
    "    # send file to AWS\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/{network}/eraqc_counts/{station}_flag_counts_hourly_standardized.csv\"\n",
    "    flag_counts.to_csv(csv_s3_filepath, index=False)\n",
    "\n",
    "    return flag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28220b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2f3e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"s3://wecc-historical-wx/3_qaqc_wx/VALLEYWATER/VALLEYWATER_6001.zarr\"\n",
    "url = \"s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_72493023230.zarr\"\n",
    "ds = xr.open_zarr(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cbb0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, MultiIndex, attrs, var_attrs = merge_ds_to_df(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f02584",
   "metadata": {},
   "source": [
    "### Perform hourly standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(x):\n",
    "    if len(x) == 0:\n",
    "        return \"nan\"\n",
    "    else:\n",
    "        return \",\".join(x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_hourly_standardization(\n",
    "    df: pd.DataFrame, var_attrs: dict, logger: logging.Logger\n",
    ") -> tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"Resamples meteorological variables to hourly timestep according to standard conventions.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        station dataset converted to dataframe through QAQC pipeline\n",
    "    var_attrs: library\n",
    "        attributes for sub-hourly variables\n",
    "    logger : logging.Logger\n",
    "        Logger instance for recording messages during processing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame | None\n",
    "        returns a dataframe with all columns resampled to one hour (column name retained)\n",
    "    var_attrs : dict | None\n",
    "        returns variable attributes dictionary updated to note that sub-hourly variables are now hourly\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Rules:\n",
    "    1. Top of the hour: take the first value in each hour. Standard convention for temperature, dewpoint, wind speed, direction, relative humidity, air pressure.\n",
    "    2. Summation across the hour: sum observations within each hour. Standard convention for precipitation and solar radiation.\n",
    "    3. Constant across the hour: take the first value in each hour. This applied to variables that do not change.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f\"{inspect.currentframe().f_code.co_name}: Starting...\")\n",
    "\n",
    "    # Variables that remain constant within each hour\n",
    "    constant_vars = [\n",
    "        \"time\",\n",
    "        \"station\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"elevation\",\n",
    "        \"anemometer_height_m\",\n",
    "        \"thermometer_height_m\",\n",
    "    ]\n",
    "\n",
    "    # Aggregation across hour variables, standard meteorological convention: precipitation and solar radiation\n",
    "    sum_vars = [\n",
    "        \"time\",\n",
    "        \"pr\",\n",
    "        \"pr_localmid\",\n",
    "        \"pr_24h\",\n",
    "        \"pr_1h\",\n",
    "        \"pr_15min\",\n",
    "        \"pr_5min\",\n",
    "        \"rsds\",\n",
    "    ]\n",
    "\n",
    "    # Top of the hour variables, standard meteorological convention: temperature, dewpoint temperature, pressure, humidity, winds\n",
    "    instant_vars = [\n",
    "        \"hurs_derived\",\n",
    "        \"time\",\n",
    "        \"tas\",\n",
    "        \"tas_derived\",\n",
    "        \"tdps\",\n",
    "        \"tdps_derived\",\n",
    "        \"ps\",\n",
    "        \"psl\",\n",
    "        \"ps_altimeter\",\n",
    "        \"ps_derived\",\n",
    "        \"hurs\",\n",
    "        \"sfcWind\",\n",
    "        \"sfcWind_dir\",\n",
    "    ]\n",
    "\n",
    "    # QAQC flags, which remain constants within each hour\n",
    "    vars_to_remove = [\"qc\", \"eraqc\", \"duration\", \"method\", \"flag\", \"depth\", \"process\"]\n",
    "\n",
    "    try:\n",
    "\n",
    "        qaqc_vars = [\n",
    "            var\n",
    "            for var in df.columns\n",
    "            if any(True for item in vars_to_remove if item in var)\n",
    "        ]\n",
    "\n",
    "        # Subset the dataframe according to rules\n",
    "        constant_df = df[[col for col in constant_vars if col in df.columns]]\n",
    "\n",
    "        qaqc_df = df[[col for col in qaqc_vars if col in df.columns if col != \"time\"]]\n",
    "        qaqc_df = qaqc_df.astype(str)\n",
    "        qaqc_df.insert(0, \"time\", df[\"time\"])\n",
    "\n",
    "        sum_df = df[[col for col in sum_vars if col in df.columns]]\n",
    "\n",
    "        instant_df = df[[col for col in instant_vars if col in df.columns]]\n",
    "\n",
    "        # Performing hourly aggregation, only if subset contains more than one (ie more than the 'time' time) column\n",
    "        # This is to account for input dataframes that do not contain ALL subsets of variables defined above - just a subset of them.\n",
    "        result_list = []\n",
    "        if len(constant_df.columns) > 1:\n",
    "            constant_result = constant_df.resample(\"1h\", on=\"time\").first()\n",
    "            result_list.append(constant_result)\n",
    "\n",
    "        if len(instant_df.columns) > 1:\n",
    "            instant_result = instant_df.resample(\"1h\", on=\"time\").first()\n",
    "            result_list.append(instant_result)\n",
    "\n",
    "        if len(sum_df.columns) > 1:\n",
    "            sum_result = sum_df.resample(\"1h\", on=\"time\").apply(\n",
    "                lambda x: np.nan if x.isna().all() else x.sum(skipna=True)\n",
    "            )\n",
    "            result_list.append(sum_result)\n",
    "\n",
    "        if len(qaqc_df.columns) > 1:\n",
    "            qaqc_result = qaqc_df.resample(\"1h\", on=\"time\").apply(\n",
    "                lambda x: \",\".join(x.unique())\n",
    "            )  # adding unique flags\n",
    "            result_list.append(qaqc_result)\n",
    "\n",
    "        # Aggregate and output reduced dataframe - this merges all dataframes defined\n",
    "        # This function sets \"time\" to the index; reset index to return to original index\n",
    "        result = reduce(\n",
    "            lambda left, right: pd.merge(left, right, on=[\"time\"], how=\"outer\"),\n",
    "            result_list,\n",
    "        )\n",
    "        result.reset_index(inplace=True)  # Convert time index --> column\n",
    "\n",
    "        # Update attributes for sub-hourly variables\n",
    "        sub_hourly_vars = [i for i in df.columns if \"min\" in i and \"qc\" not in i]\n",
    "        for var in sub_hourly_vars:\n",
    "            var_attrs[var][\"standardization\"] = (\n",
    "                \"{} has been standardized to an hourly timestep, but will retain its original name\".format(\n",
    "                    var\n",
    "                )\n",
    "            )\n",
    "        logger.info(f\"{inspect.currentframe().f_code.co_name}: Completed successfully\")\n",
    "\n",
    "        return result, var_attrs\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"{inspect.currentframe().f_code.co_name}: Failed\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8336f",
   "metadata": {},
   "source": [
    "### Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79dfcb",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/54544084/how-to-apply-series-value-counts-on-dataframe\n",
    "\n",
    "https://note.nkmk.me/en/python-pandas-value-counts/\n",
    "\n",
    "df['X'].apply(lambda x : len(np.unique(x.split(','))))\n",
    "\n",
    "df_qc[\"ps_altimeter_eraqc\"].str.split(\",\", expand=True).nunique(1)\n",
    "\n",
    "business['Category'].str.split(',').apply(len)\n",
    "\n",
    "https://stackoverflow.com/questions/60143292/at-column-count-word-in-comma-separated-sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0bd18b",
   "metadata": {},
   "source": [
    "Why is there a space??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b54aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan', '23.0', '', 'nan,23.0', '23.0,nan'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_st['ps_altimeter_eraqc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d1353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['elevation_eraqc', 'pr_eraqc', 'ps_altimeter_eraqc', 'ps_eraqc',\n",
       "       'psl_eraqc', 'sfcWind_dir_eraqc', 'sfcWind_eraqc', 'tas_eraqc',\n",
       "       'tdps_eraqc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qc.columns\n",
    "# more than nan\n",
    "# ps_altimeter_eraqc\n",
    "# ps_eraqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48d7dfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 21., 23.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qc[\"ps_eraqc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8161854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAQC flags, which remain constants within each hour\n",
    "vars_to_remove = [\"qc\", \"eraqc\", \"duration\", \"method\", \"flag\", \"depth\", \"process\"]\n",
    "qaqc_vars = [\n",
    "    var for var in df.columns if any(True for item in vars_to_remove if item in var)\n",
    "]\n",
    "qaqc_df = df[[col for col in qaqc_vars if col in df.columns if col != \"time\"]]\n",
    "qaqc_df = qaqc_df.astype(str)\n",
    "qaqc_df.insert(0, \"time\", df[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "854b42d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan', '21.0', '23.0'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaqc_df[\"ps_eraqc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2336275",
   "metadata": {},
   "outputs": [],
   "source": [
    "qaqc_df_filt = qaqc_df[['time','ps_eraqc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ecb18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_filt = qaqc_df_filt.loc[\n",
    "    (qaqc_df_filt[\"time\"] >= \"1981-02-04\") & (qaqc_df_filt[\"time\"] < \"1981-02-06\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd8490b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_filt['ps_eraqc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f11fe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ps_eraqc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>1981-02-04 00:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>1981-02-04 01:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>1981-02-04 02:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10331</th>\n",
       "      <td>1981-02-04 03:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>1981-02-04 04:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10333</th>\n",
       "      <td>1981-02-04 05:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10334</th>\n",
       "      <td>1981-02-04 06:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10335</th>\n",
       "      <td>1981-02-04 07:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336</th>\n",
       "      <td>1981-02-04 08:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10337</th>\n",
       "      <td>1981-02-04 09:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10338</th>\n",
       "      <td>1981-02-04 10:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10339</th>\n",
       "      <td>1981-02-04 11:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10340</th>\n",
       "      <td>1981-02-04 12:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341</th>\n",
       "      <td>1981-02-04 13:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10342</th>\n",
       "      <td>1981-02-04 14:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10343</th>\n",
       "      <td>1981-02-04 15:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10344</th>\n",
       "      <td>1981-02-04 16:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10345</th>\n",
       "      <td>1981-02-04 17:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10346</th>\n",
       "      <td>1981-02-04 18:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10347</th>\n",
       "      <td>1981-02-04 19:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10348</th>\n",
       "      <td>1981-02-04 20:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10349</th>\n",
       "      <td>1981-02-04 21:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350</th>\n",
       "      <td>1981-02-04 22:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10351</th>\n",
       "      <td>1981-02-04 23:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>1981-02-05 00:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>1981-02-05 01:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354</th>\n",
       "      <td>1981-02-05 02:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>1981-02-05 03:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>1981-02-05 04:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>1981-02-05 05:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10358</th>\n",
       "      <td>1981-02-05 06:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>1981-02-05 08:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>1981-02-05 09:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10361</th>\n",
       "      <td>1981-02-05 10:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10362</th>\n",
       "      <td>1981-02-05 11:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10363</th>\n",
       "      <td>1981-02-05 12:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364</th>\n",
       "      <td>1981-02-05 13:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10365</th>\n",
       "      <td>1981-02-05 14:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td>1981-02-05 15:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10367</th>\n",
       "      <td>1981-02-05 16:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10368</th>\n",
       "      <td>1981-02-05 17:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369</th>\n",
       "      <td>1981-02-05 18:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>1981-02-05 19:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>1981-02-05 20:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>1981-02-05 21:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>1981-02-05 22:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>1981-02-05 23:00:00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time ps_eraqc\n",
       "10328 1981-02-04 00:00:00      nan\n",
       "10329 1981-02-04 01:00:00      nan\n",
       "10330 1981-02-04 02:00:00      nan\n",
       "10331 1981-02-04 03:00:00      nan\n",
       "10332 1981-02-04 04:00:00      nan\n",
       "10333 1981-02-04 05:00:00      nan\n",
       "10334 1981-02-04 06:00:00      nan\n",
       "10335 1981-02-04 07:00:00      nan\n",
       "10336 1981-02-04 08:00:00      nan\n",
       "10337 1981-02-04 09:00:00      nan\n",
       "10338 1981-02-04 10:00:00      nan\n",
       "10339 1981-02-04 11:00:00      nan\n",
       "10340 1981-02-04 12:00:00      nan\n",
       "10341 1981-02-04 13:00:00      nan\n",
       "10342 1981-02-04 14:00:00      nan\n",
       "10343 1981-02-04 15:00:00      nan\n",
       "10344 1981-02-04 16:00:00      nan\n",
       "10345 1981-02-04 17:00:00      nan\n",
       "10346 1981-02-04 18:00:00      nan\n",
       "10347 1981-02-04 19:00:00      nan\n",
       "10348 1981-02-04 20:00:00      nan\n",
       "10349 1981-02-04 21:00:00      nan\n",
       "10350 1981-02-04 22:00:00      nan\n",
       "10351 1981-02-04 23:00:00      nan\n",
       "10352 1981-02-05 00:00:00      nan\n",
       "10353 1981-02-05 01:00:00      nan\n",
       "10354 1981-02-05 02:00:00      nan\n",
       "10355 1981-02-05 03:00:00      nan\n",
       "10356 1981-02-05 04:00:00      nan\n",
       "10357 1981-02-05 05:00:00      nan\n",
       "10358 1981-02-05 06:00:00      nan\n",
       "10359 1981-02-05 08:00:00      nan\n",
       "10360 1981-02-05 09:00:00      nan\n",
       "10361 1981-02-05 10:00:00      nan\n",
       "10362 1981-02-05 11:00:00      nan\n",
       "10363 1981-02-05 12:00:00      nan\n",
       "10364 1981-02-05 13:00:00      nan\n",
       "10365 1981-02-05 14:00:00      nan\n",
       "10366 1981-02-05 15:00:00      nan\n",
       "10367 1981-02-05 16:00:00      nan\n",
       "10368 1981-02-05 17:00:00      nan\n",
       "10369 1981-02-05 18:00:00      nan\n",
       "10370 1981-02-05 19:00:00      nan\n",
       "10371 1981-02-05 20:00:00      nan\n",
       "10372 1981-02-05 21:00:00      nan\n",
       "10373 1981-02-05 22:00:00      nan\n",
       "10374 1981-02-05 23:00:00      nan"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78c1f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qaqc_result_test = df_time_filt.resample(\"1h\", on=\"time\").apply(\n",
    "    lambda x: my_func(x)\n",
    "    # lambda x: \",\".join(x.unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9878f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaqc_result_test[\"ps_eraqc\"].unique()\n",
    "\n",
    "# empty string shows up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efc5606c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_eraqc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-02-04 00:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 01:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 02:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 03:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 04:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 05:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 06:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 07:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 08:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 09:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 10:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 11:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 12:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 13:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 14:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 15:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 16:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 17:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 18:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 19:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 20:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 21:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 22:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-04 23:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 00:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 01:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 02:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 03:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 04:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 05:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 06:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 07:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 08:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 09:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 10:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 11:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 12:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 13:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 14:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 15:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 16:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 17:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 18:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 19:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 20:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 21:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 22:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05 23:00:00</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ps_eraqc\n",
       "time                        \n",
       "1981-02-04 00:00:00      nan\n",
       "1981-02-04 01:00:00      nan\n",
       "1981-02-04 02:00:00      nan\n",
       "1981-02-04 03:00:00      nan\n",
       "1981-02-04 04:00:00      nan\n",
       "1981-02-04 05:00:00      nan\n",
       "1981-02-04 06:00:00      nan\n",
       "1981-02-04 07:00:00      nan\n",
       "1981-02-04 08:00:00      nan\n",
       "1981-02-04 09:00:00      nan\n",
       "1981-02-04 10:00:00      nan\n",
       "1981-02-04 11:00:00      nan\n",
       "1981-02-04 12:00:00      nan\n",
       "1981-02-04 13:00:00      nan\n",
       "1981-02-04 14:00:00      nan\n",
       "1981-02-04 15:00:00      nan\n",
       "1981-02-04 16:00:00      nan\n",
       "1981-02-04 17:00:00      nan\n",
       "1981-02-04 18:00:00      nan\n",
       "1981-02-04 19:00:00      nan\n",
       "1981-02-04 20:00:00      nan\n",
       "1981-02-04 21:00:00      nan\n",
       "1981-02-04 22:00:00      nan\n",
       "1981-02-04 23:00:00      nan\n",
       "1981-02-05 00:00:00      nan\n",
       "1981-02-05 01:00:00      nan\n",
       "1981-02-05 02:00:00      nan\n",
       "1981-02-05 03:00:00      nan\n",
       "1981-02-05 04:00:00      nan\n",
       "1981-02-05 05:00:00      nan\n",
       "1981-02-05 06:00:00      nan\n",
       "1981-02-05 07:00:00      nan\n",
       "1981-02-05 08:00:00      nan\n",
       "1981-02-05 09:00:00      nan\n",
       "1981-02-05 10:00:00      nan\n",
       "1981-02-05 11:00:00      nan\n",
       "1981-02-05 12:00:00      nan\n",
       "1981-02-05 13:00:00      nan\n",
       "1981-02-05 14:00:00      nan\n",
       "1981-02-05 15:00:00      nan\n",
       "1981-02-05 16:00:00      nan\n",
       "1981-02-05 17:00:00      nan\n",
       "1981-02-05 18:00:00      nan\n",
       "1981-02-05 19:00:00      nan\n",
       "1981-02-05 20:00:00      nan\n",
       "1981-02-05 21:00:00      nan\n",
       "1981-02-05 22:00:00      nan\n",
       "1981-02-05 23:00:00      nan"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaqc_result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba5fa7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_time_filt = df.loc[\n",
    "    (df[\"time\"] >= \"1981-02-04\") & (df[\"time\"] < \"1981-02-06\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028cb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_time_filt[[\"time\", \"ps_eraqc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed966344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 21., 23.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ps_eraqc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775f6f7",
   "metadata": {},
   "source": [
    "Oh! I think I figured out why that space is appearing. For time gaps! When the data skips a few hours, or even days - there are no flags to concatenate. So they show up as spaces! Now let us confirm this by resamplign over a region with a time gap. And check if there is a time gap I the region I specified above.\n",
    "\n",
    "Might work better if we convert flag values to numeric.\n",
    "\n",
    "change our wording:\n",
    "resampling or aggregating?\n",
    "do we want to preserve the gaps but fill in gaps at the to of the hour?\n",
    "looks like the resampler preserves gaps\n",
    "\n",
    "clean up this notebook to be a demo of this situation/artefact/potential issue\n",
    "\n",
    "Why are standardizing to an hourly timestep? We SHOULD do a TRUE resampling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29689d6",
   "metadata": {},
   "source": [
    "### Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7191e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"ASOSAWOS\"\n",
    "station = \"ASOSAWOS_72493023230\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5a173b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eraqc_flag_values</th>\n",
       "      <th>elevation</th>\n",
       "      <th>pr</th>\n",
       "      <th>ps_altimeter</th>\n",
       "      <th>ps</th>\n",
       "      <th>psl</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>35504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7296.0</td>\n",
       "      <td>22079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nan</td>\n",
       "      <td>338512.0</td>\n",
       "      <td>338512.0</td>\n",
       "      <td>338490.0</td>\n",
       "      <td>331214.0</td>\n",
       "      <td>316410.0</td>\n",
       "      <td>338512.0</td>\n",
       "      <td>338496.0</td>\n",
       "      <td>338428.0</td>\n",
       "      <td>338004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eraqc_flag_values  elevation        pr  ps_altimeter        ps       psl  \\\n",
       "0                      35504.0   35504.0       35504.0   35504.0   35504.0   \n",
       "1              21.0        0.0       0.0           0.0    7296.0   22079.0   \n",
       "2              23.0        0.0       0.0          24.0       3.0      23.0   \n",
       "3              26.0        0.0       0.0           0.0       0.0       0.0   \n",
       "4              27.0        0.0       0.0           0.0       0.0       0.0   \n",
       "5              28.0        0.0       0.0           0.0       0.0       0.0   \n",
       "6               nan   338512.0  338512.0      338490.0  331214.0  316410.0   \n",
       "\n",
       "   sfcWind_dir   sfcWind       tas      tdps  \n",
       "0      35504.0   35504.0   35504.0   35504.0  \n",
       "1          0.0       0.0       0.0       0.0  \n",
       "2          0.0       0.0      10.0     200.0  \n",
       "3          0.0       0.0      94.0     332.0  \n",
       "4          0.0      16.0       0.0      14.0  \n",
       "5          0.0       0.0       0.0      25.0  \n",
       "6     338512.0  338496.0  338428.0  338004.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run if set to flag_counts\n",
    "flag_counts = eraqc_counts_hourly_timestep(df_st, network, station)\n",
    "flag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f71942",
   "metadata": {},
   "source": [
    "There are empty string sin flag columns\n",
    "Function to take care of those empty strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15258e6",
   "metadata": {},
   "source": [
    "### CHECK: let's look at the output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07729803",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = f\"4_merge_wx/{network}/eraqc_counts/original_timestep_{station}.csv\"\n",
    "\n",
    "list_import = s3_cl.get_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=key,\n",
    ")\n",
    "\n",
    "flag_counts_table = pd.read_csv(BytesIO(list_import[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_counts_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
