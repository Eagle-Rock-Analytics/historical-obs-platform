{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d0a3ef",
   "metadata": {},
   "source": [
    "# QAQC flag counts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe6225",
   "metadata": {},
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14260284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from functools import reduce\n",
    "\n",
    "import inspect\n",
    "\n",
    "import logging\n",
    "# Create a simple logger that just prints to the console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e983a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fdbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ds_to_df(ds):\n",
    "    \"\"\"Converts xarray ds for a station to pandas df in the format needed for processing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: xr.Dataset\n",
    "        Data object with information about each network and station\n",
    "    verbose: boolean\n",
    "        Flag as to whether to print runtime statements to terminal. Default is False. Set in ALLNETWORKS_merge.py run.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        Table object with information about each network and station\n",
    "    MultiIndex: pd.DataFrame (I think)\n",
    "        Original multi-index of station and time, to be used on conversion back to ds\n",
    "    attrs:\n",
    "        Save ds attributes to inherent to the final merged file\n",
    "    var_attrs:\n",
    "        Save variable attributes to inherent to the final merged file\n",
    "    \"\"\"\n",
    "\n",
    "    # Save attributes to inherent them to the final merged file\n",
    "    attrs = ds.attrs\n",
    "    var_attrs = {var: ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    df = ds.to_dataframe()\n",
    "\n",
    "    # Save instrumentation heights\n",
    "    if \"anemometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"anemometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.anemometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling anemometer_height_m with NaN.\")\n",
    "            df[\"anemometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "    if \"thermometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"thermometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.thermometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling thermometer_height_m with NaN.\")\n",
    "            df[\"thermometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "\n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df[\"station\"] = station\n",
    "\n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "\n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    return df, MultiIndex, attrs, var_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74b64f",
   "metadata": {},
   "source": [
    "## Set the stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28220b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f2f3e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"s3://wecc-historical-wx/3_qaqc_wx/VALLEYWATER/VALLEYWATER_6001.zarr\"\n",
    "url = \"s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_72493023230.zarr\"\n",
    "ds = xr.open_zarr(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5cbb0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, MultiIndex, attrs, var_attrs = merge_ds_to_df(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f02584",
   "metadata": {},
   "source": [
    "### Perform hourly standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f5edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(x):\n",
    "    if len(x) == 0:\n",
    "        return \"nan\"\n",
    "    else:\n",
    "        return \",\".join(x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3d1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_hourly_standardization(\n",
    "    df: pd.DataFrame, var_attrs: dict, logger: logging.Logger\n",
    ") -> tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"Resamples meteorological variables to hourly timestep according to standard conventions.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        station dataset converted to dataframe through QAQC pipeline\n",
    "    var_attrs: library\n",
    "        attributes for sub-hourly variables\n",
    "    logger : logging.Logger\n",
    "        Logger instance for recording messages during processing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame | None\n",
    "        returns a dataframe with all columns resampled to one hour (column name retained)\n",
    "    var_attrs : dict | None\n",
    "        returns variable attributes dictionary updated to note that sub-hourly variables are now hourly\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Rules:\n",
    "    1. Top of the hour: take the first value in each hour. Standard convention for temperature, dewpoint, wind speed, direction, relative humidity, air pressure.\n",
    "    2. Summation across the hour: sum observations within each hour. Standard convention for precipitation and solar radiation.\n",
    "    3. Constant across the hour: take the first value in each hour. This applied to variables that do not change.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f\"{inspect.currentframe().f_code.co_name}: Starting...\")\n",
    "\n",
    "    # Variables that remain constant within each hour\n",
    "    constant_vars = [\n",
    "        \"time\",\n",
    "        \"station\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"elevation\",\n",
    "        \"anemometer_height_m\",\n",
    "        \"thermometer_height_m\",\n",
    "    ]\n",
    "\n",
    "    # Aggregation across hour variables, standard meteorological convention: precipitation and solar radiation\n",
    "    sum_vars = [\n",
    "        \"time\",\n",
    "        \"pr\",\n",
    "        \"pr_localmid\",\n",
    "        \"pr_24h\",\n",
    "        \"pr_1h\",\n",
    "        \"pr_15min\",\n",
    "        \"pr_5min\",\n",
    "        \"rsds\",\n",
    "    ]\n",
    "\n",
    "    # Top of the hour variables, standard meteorological convention: temperature, dewpoint temperature, pressure, humidity, winds\n",
    "    instant_vars = [\n",
    "        \"hurs_derived\",\n",
    "        \"time\",\n",
    "        \"tas\",\n",
    "        \"tas_derived\",\n",
    "        \"tdps\",\n",
    "        \"tdps_derived\",\n",
    "        \"ps\",\n",
    "        \"psl\",\n",
    "        \"ps_altimeter\",\n",
    "        \"ps_derived\",\n",
    "        \"hurs\",\n",
    "        \"sfcWind\",\n",
    "        \"sfcWind_dir\",\n",
    "    ]\n",
    "\n",
    "    # QAQC flags, which remain constants within each hour\n",
    "    vars_to_remove = [\"qc\", \"eraqc\", \"duration\", \"method\", \"flag\", \"depth\", \"process\"]\n",
    "\n",
    "    try:\n",
    "\n",
    "        qaqc_vars = [\n",
    "            var\n",
    "            for var in df.columns\n",
    "            if any(True for item in vars_to_remove if item in var)\n",
    "        ]\n",
    "\n",
    "        # Subset the dataframe according to rules\n",
    "        constant_df = df[[col for col in constant_vars if col in df.columns]]\n",
    "\n",
    "        qaqc_df = df[[col for col in qaqc_vars if col in df.columns if col != \"time\"]]\n",
    "        qaqc_df = qaqc_df.astype(str)\n",
    "        qaqc_df.insert(0, \"time\", df[\"time\"])\n",
    "\n",
    "        sum_df = df[[col for col in sum_vars if col in df.columns]]\n",
    "\n",
    "        instant_df = df[[col for col in instant_vars if col in df.columns]]\n",
    "\n",
    "        # Performing hourly aggregation, only if subset contains more than one (ie more than the 'time' time) column\n",
    "        # This is to account for input dataframes that do not contain ALL subsets of variables defined above - just a subset of them.\n",
    "        result_list = []\n",
    "        if len(constant_df.columns) > 1:\n",
    "            constant_result = constant_df.resample(\"1h\", on=\"time\").first()\n",
    "            result_list.append(constant_result)\n",
    "\n",
    "        if len(instant_df.columns) > 1:\n",
    "            instant_result = instant_df.resample(\"1h\", on=\"time\").first()\n",
    "            result_list.append(instant_result)\n",
    "\n",
    "        if len(sum_df.columns) > 1:\n",
    "            sum_result = sum_df.resample(\"1h\", on=\"time\").apply(\n",
    "                lambda x: np.nan if x.isna().all() else x.sum(skipna=True)\n",
    "            )\n",
    "            result_list.append(sum_result)\n",
    "\n",
    "        if len(qaqc_df.columns) > 1:\n",
    "            qaqc_result = qaqc_df.resample(\"1h\", on=\"time\").apply(\n",
    "                lambda x: my_func(x)\n",
    "            )  # adding unique flags\n",
    "            result_list.append(qaqc_result)\n",
    "\n",
    "        # Aggregate and output reduced dataframe - this merges all dataframes defined\n",
    "        # This function sets \"time\" to the index; reset index to return to original index\n",
    "        result = reduce(\n",
    "            lambda left, right: pd.merge(left, right, on=[\"time\"], how=\"outer\"),\n",
    "            result_list,\n",
    "        )\n",
    "        result.reset_index(inplace=True)  # Convert time index --> column\n",
    "\n",
    "        # Update attributes for sub-hourly variables\n",
    "        sub_hourly_vars = [i for i in df.columns if \"min\" in i and \"qc\" not in i]\n",
    "        for var in sub_hourly_vars:\n",
    "            var_attrs[var][\"standardization\"] = (\n",
    "                \"{} has been standardized to an hourly timestep, but will retain its original name\".format(\n",
    "                    var\n",
    "                )\n",
    "            )\n",
    "        logger.info(f\"{inspect.currentframe().f_code.co_name}: Completed successfully\")\n",
    "\n",
    "        return result, var_attrs\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"{inspect.currentframe().f_code.co_name}: Failed\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45cfd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting data to speed things up\n",
    "df_sub = df[['time','ps_eraqc','pr_eraqc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e088f107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:merge_hourly_standardization: Starting...\n",
      "INFO:root:merge_hourly_standardization: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "df_st, var_attrs = merge_hourly_standardization(df, var_attrs, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ba641",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed0f64",
   "metadata": {},
   "source": [
    "### Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59fe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include count of total number of observations\n",
    "\n",
    "def eraqc_counts_hourly_timestep(df: pd.DataFrame, network: str, station: str) -> None:\n",
    "    \"\"\"\n",
    "    Generates a dataframe of raw qaqc flag value counts for every variable,\n",
    "    for the hourly timestep, after hourly standardization.\n",
    "    Exports the dataframe as a csv to AWS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        station dataset converted to dataframe through QAQC pipeline\n",
    "    network: str\n",
    "        network name\n",
    "    station: str\n",
    "        station name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # identify _eraqc variables\n",
    "    eraqc_vars = [var for var in df.columns if \"_eraqc\" in var]\n",
    "\n",
    "    # filter df for only qaqc columns\n",
    "    # also replace Nan values with 'no_flag' for two reasons:\n",
    "    #   1. to enable us to count total observations for the success report\n",
    "    #   2. to clarify what the Nan value indicates\n",
    "    df_qaqc = df[eraqc_vars]\n",
    "\n",
    "    # generate df of counts of each unique flag for each variable\n",
    "    # fill all Nan values with 0, since Nan = no observations counted\n",
    "    flag_counts = df_qaqc.apply(\n",
    "        lambda x: x.str.split(\",\", expand=True).stack().value_counts()\n",
    "    ).fillna(0)\n",
    "\n",
    "    # rename columns\n",
    "    flag_counts.columns = flag_counts.columns.str.replace(\"_eraqc\", \"\", regex=True)\n",
    "\n",
    "    # set all counts to integers, for readability\n",
    "    flag_counts = flag_counts.astype(int)\n",
    "\n",
    "    # rename index (i.e. eraqc values) and then reset index\n",
    "    flag_counts = flag_counts.rename_axis(\"eraqc_flag_values\")\n",
    "\n",
    "    # replace 'nan' (a string) with 'no_flag', for clarity\n",
    "    flag_counts = flag_counts.rename(index={\"nan\": \"no_flag\"})\n",
    "\n",
    "    # add row with count of non_nan values per variable\n",
    "    flag_vars = flag_counts.columns\n",
    "    flag_counts.loc[\"non_nan_obs_count\"] = df[flag_vars].notna().sum()\n",
    "\n",
    "    # send file to AWS\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/{network}/eraqc_counts/{station}_flag_counts_hourly_standardized.csv\"\n",
    "    flag_counts.to_csv(csv_s3_filepath, index=True)\n",
    "\n",
    "    return flag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8336f",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "aaaa125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # identify _eraqc variables\n",
    "eraqc_vars = [var for var in df_st.columns if \"_eraqc\" in var]\n",
    "\n",
    "df_qaqc = df_st[eraqc_vars]\n",
    "\n",
    "# generate df of counts of each unique flag for each variable\n",
    "# fill all Nan values with 0, since Nan = no observations counted\n",
    "flag_counts = df_qaqc.apply(\n",
    "    lambda x: x.str.split(\",\", expand=True).stack().value_counts()\n",
    ").fillna(0)\n",
    "\n",
    "# rename columns\n",
    "flag_counts.columns = flag_counts.columns.str.replace(\"_eraqc\", \"\", regex=True)\n",
    "\n",
    "# set all counts to integers, for readability\n",
    "flag_counts = flag_counts.astype(int)\n",
    "\n",
    "# rename index (i.e. eraqc values) and then reset index\n",
    "flag_counts = flag_counts.rename_axis(\"eraqc_flag_values\")\n",
    "\n",
    "# replace 'nan' (a string) with 'no_flag', for clarity\n",
    "flag_counts = flag_counts.rename(index={\"nan\": \"no_flag\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479ff57",
   "metadata": {},
   "source": [
    "Add row with total obs per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62151b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>pr</th>\n",
       "      <th>ps_altimeter</th>\n",
       "      <th>ps</th>\n",
       "      <th>psl</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>102100.0</td>\n",
       "      <td>102070.0</td>\n",
       "      <td>102090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.75</td>\n",
       "      <td>286.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102130.0</td>\n",
       "      <td>102080.0</td>\n",
       "      <td>102120.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>287.55</td>\n",
       "      <td>284.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102170.0</td>\n",
       "      <td>102120.0</td>\n",
       "      <td>102140.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>287.55</td>\n",
       "      <td>284.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102170.0</td>\n",
       "      <td>102130.0</td>\n",
       "      <td>102170.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>287.55</td>\n",
       "      <td>284.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102240.0</td>\n",
       "      <td>102200.0</td>\n",
       "      <td>102230.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.05</td>\n",
       "      <td>284.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374011</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101630.0</td>\n",
       "      <td>101300.0</td>\n",
       "      <td>101600.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>293.75</td>\n",
       "      <td>285.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374012</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101560.0</td>\n",
       "      <td>101230.0</td>\n",
       "      <td>101560.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>294.25</td>\n",
       "      <td>285.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374013</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101490.0</td>\n",
       "      <td>101170.0</td>\n",
       "      <td>101470.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>295.95</td>\n",
       "      <td>285.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374014</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101420.0</td>\n",
       "      <td>101100.0</td>\n",
       "      <td>101410.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>295.95</td>\n",
       "      <td>285.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374015</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101350.0</td>\n",
       "      <td>101030.0</td>\n",
       "      <td>101350.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>295.35</td>\n",
       "      <td>286.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374016 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        elevation   pr  ps_altimeter        ps       psl  sfcWind_dir  \\\n",
       "0             2.0  6.0      102100.0  102070.0  102090.0          NaN   \n",
       "1             2.0  NaN      102130.0  102080.0  102120.0        270.0   \n",
       "2             2.0  NaN      102170.0  102120.0  102140.0        270.0   \n",
       "3             2.0  NaN      102170.0  102130.0  102170.0         40.0   \n",
       "4             2.0  NaN      102240.0  102200.0  102230.0        340.0   \n",
       "...           ...  ...           ...       ...       ...          ...   \n",
       "374011       27.0  0.0      101630.0  101300.0  101600.0        260.0   \n",
       "374012       27.0  0.0      101560.0  101230.0  101560.0        270.0   \n",
       "374013       27.0  0.0      101490.0  101170.0  101470.0        290.0   \n",
       "374014       27.0  0.0      101420.0  101100.0  101410.0        290.0   \n",
       "374015       27.0  0.0      101350.0  101030.0  101350.0        290.0   \n",
       "\n",
       "        sfcWind     tas    tdps  \n",
       "0           0.0  288.75  286.45  \n",
       "1           3.6  287.55  284.25  \n",
       "2           3.1  287.55  284.25  \n",
       "3           2.1  287.55  284.85  \n",
       "4           0.0  287.05  284.25  \n",
       "...         ...     ...     ...  \n",
       "374011      3.6  293.75  285.35  \n",
       "374012      4.6  294.25  285.95  \n",
       "374013      5.7  295.95  285.95  \n",
       "374014      5.7  295.95  285.95  \n",
       "374015      6.7  295.35  286.45  \n",
       "\n",
       "[374016 rows x 9 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will look ugly, but I'm just included it to have the information I need for the success report\n",
    "\n",
    "flag_vars = flag_counts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_counts.loc['non_nan_obs_count']= df_st[flag_vars].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d65469cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>pr</th>\n",
       "      <th>ps_altimeter</th>\n",
       "      <th>ps</th>\n",
       "      <th>psl</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eraqc_flag_values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7296</td>\n",
       "      <td>22079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_flag</th>\n",
       "      <td>374016</td>\n",
       "      <td>374016</td>\n",
       "      <td>373994</td>\n",
       "      <td>366718</td>\n",
       "      <td>351914</td>\n",
       "      <td>374016</td>\n",
       "      <td>374000</td>\n",
       "      <td>373932</td>\n",
       "      <td>373508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>338512</td>\n",
       "      <td>181934</td>\n",
       "      <td>329119</td>\n",
       "      <td>163315</td>\n",
       "      <td>172818</td>\n",
       "      <td>292987</td>\n",
       "      <td>333820</td>\n",
       "      <td>333437</td>\n",
       "      <td>332644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   elevation      pr  ps_altimeter      ps     psl  \\\n",
       "eraqc_flag_values                                                    \n",
       "21.0                       0       0             0    7296   22079   \n",
       "23.0                       0       0            24       3      23   \n",
       "26.0                       0       0             0       0       0   \n",
       "27.0                       0       0             0       0       0   \n",
       "28.0                       0       0             0       0       0   \n",
       "no_flag               374016  374016        373994  366718  351914   \n",
       "test                  338512  181934        329119  163315  172818   \n",
       "\n",
       "                   sfcWind_dir  sfcWind     tas    tdps  \n",
       "eraqc_flag_values                                        \n",
       "21.0                         0        0       0       0  \n",
       "23.0                         0        0      10     200  \n",
       "26.0                         0        0      94     332  \n",
       "27.0                         0       16       0      14  \n",
       "28.0                         0        0       0      25  \n",
       "no_flag                 374016   374000  373932  373508  \n",
       "test                    292987   333820  333437  332644  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e8eeec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>pr</th>\n",
       "      <th>ps_altimeter</th>\n",
       "      <th>ps</th>\n",
       "      <th>psl</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>35504</td>\n",
       "      <td>192082</td>\n",
       "      <td>44897</td>\n",
       "      <td>210701</td>\n",
       "      <td>201198</td>\n",
       "      <td>81029</td>\n",
       "      <td>40196</td>\n",
       "      <td>40579</td>\n",
       "      <td>41372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>338512</td>\n",
       "      <td>181934</td>\n",
       "      <td>329119</td>\n",
       "      <td>163315</td>\n",
       "      <td>172818</td>\n",
       "      <td>292987</td>\n",
       "      <td>333820</td>\n",
       "      <td>333437</td>\n",
       "      <td>332644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       elevation      pr  ps_altimeter      ps     psl  sfcWind_dir  sfcWind  \\\n",
       "False      35504  192082         44897  210701  201198        81029    40196   \n",
       "True      338512  181934        329119  163315  172818       292987   333820   \n",
       "\n",
       "          tas    tdps  \n",
       "False   40579   41372  \n",
       "True   333437  332644  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_st[flag_vars].notna().apply(pd.Series.value_counts)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e07bb242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374016"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_st[flag_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4572b09a",
   "metadata": {},
   "source": [
    "are any nan rows flagged?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29689d6",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7191e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"ASOSAWOS\"\n",
    "station = \"ASOSAWOS_72493023230\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5a173b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>pr</th>\n",
       "      <th>ps_altimeter</th>\n",
       "      <th>ps</th>\n",
       "      <th>psl</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eraqc_flag_values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7296</td>\n",
       "      <td>22079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_flag</th>\n",
       "      <td>374016</td>\n",
       "      <td>374016</td>\n",
       "      <td>373994</td>\n",
       "      <td>366718</td>\n",
       "      <td>351914</td>\n",
       "      <td>374016</td>\n",
       "      <td>374000</td>\n",
       "      <td>373932</td>\n",
       "      <td>373508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   elevation      pr  ps_altimeter      ps     psl  \\\n",
       "eraqc_flag_values                                                    \n",
       "21.0                       0       0             0    7296   22079   \n",
       "23.0                       0       0            24       3      23   \n",
       "26.0                       0       0             0       0       0   \n",
       "27.0                       0       0             0       0       0   \n",
       "28.0                       0       0             0       0       0   \n",
       "no_flag               374016  374016        373994  366718  351914   \n",
       "\n",
       "                   sfcWind_dir  sfcWind     tas    tdps  \n",
       "eraqc_flag_values                                        \n",
       "21.0                         0        0       0       0  \n",
       "23.0                         0        0      10     200  \n",
       "26.0                         0        0      94     332  \n",
       "27.0                         0       16       0      14  \n",
       "28.0                         0        0       0      25  \n",
       "no_flag                 374016   374000  373932  373508  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run if set to flag_counts\n",
    "flag_counts = eraqc_counts_hourly_timestep(df_st, network, station)\n",
    "flag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "07729803",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = f\"4_merge_wx/{network}/eraqc_counts/{station}_flag_counts_hourly_standardized.csv\"\n",
    "\n",
    "list_import = s3_cl.get_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=key,\n",
    ")\n",
    "\n",
    "flag_counts_table = pd.read_csv(BytesIO(list_import[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f6c2d0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eraqc_flag_values</th>\n",
       "      <th>elevation</th>\n",
       "      <th>pr</th>\n",
       "      <th>ps_altimeter</th>\n",
       "      <th>ps</th>\n",
       "      <th>psl</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7296</td>\n",
       "      <td>22079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no_flag</td>\n",
       "      <td>374016</td>\n",
       "      <td>374016</td>\n",
       "      <td>373994</td>\n",
       "      <td>366718</td>\n",
       "      <td>351914</td>\n",
       "      <td>374016</td>\n",
       "      <td>374000</td>\n",
       "      <td>373932</td>\n",
       "      <td>373508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eraqc_flag_values  elevation      pr  ps_altimeter      ps     psl  \\\n",
       "0              21.0          0       0             0    7296   22079   \n",
       "1              23.0          0       0            24       3      23   \n",
       "2              26.0          0       0             0       0       0   \n",
       "3              27.0          0       0             0       0       0   \n",
       "4              28.0          0       0             0       0       0   \n",
       "5           no_flag     374016  374016        373994  366718  351914   \n",
       "\n",
       "   sfcWind_dir  sfcWind     tas    tdps  \n",
       "0            0        0       0       0  \n",
       "1            0        0      10     200  \n",
       "2            0        0      94     332  \n",
       "3            0       16       0      14  \n",
       "4            0        0       0      25  \n",
       "5       374016   374000  373932  373508  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_counts_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144a3e1",
   "metadata": {},
   "source": [
    "# Revisiting flag counts at the original timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5dae45",
   "metadata": {},
   "source": [
    "I need to add non-counts for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eraqc_counts_hourly_timestep(df: pd.DataFrame, network: str, station: str) -> None:\n",
    "    \"\"\"\n",
    "    Generates a dataframe of raw qaqc flag value counts for every variable,\n",
    "    for the hourly timestep, after hourly standardization.\n",
    "    Exports the dataframe as a csv to AWS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        station dataset converted to dataframe through QAQC pipeline\n",
    "    network: str\n",
    "        network name\n",
    "    station: str\n",
    "        station name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # identify _eraqc variables\n",
    "    eraqc_vars = [var for var in df.columns if \"_eraqc\" in var]\n",
    "\n",
    "    # filter df for only qaqc columns\n",
    "    # also replace Nan values with 'no_flag' for two reasons:\n",
    "    #   1. to enable us to count total observations for the success report\n",
    "    #   2. to clarify what the Nan value indicates\n",
    "    df = df[eraqc_vars]\n",
    "\n",
    "    # generate df of counts of each unique flag for each variable\n",
    "    # fill all Nan values with 0, since Nan = no observations counted\n",
    "    flag_counts = df.apply(\n",
    "        lambda x: x.str.split(\",\", expand=True).stack().value_counts()\n",
    "    ).fillna(0)\n",
    "\n",
    "    # rename columns\n",
    "    flag_counts.columns = flag_counts.columns.str.replace(\"_eraqc\", \"\", regex=True)\n",
    "\n",
    "    # set all counts to integers, for readability\n",
    "    flag_counts = flag_counts.astype(int)\n",
    "\n",
    "    # rename index (i.e. eraqc values) and then reset index\n",
    "    flag_counts = flag_counts.rename_axis(\"eraqc_flag_values\")\n",
    "\n",
    "    # replace 'nan' (a string) with 'no_flag', for clarity\n",
    "    flag_counts = flag_counts.rename(index={\"nan\": \"no_flag\"})\n",
    "\n",
    "    # add row with count of non_nan values per variable\n",
    "    flag_vars = flag_counts.columns\n",
    "    flag_counts.loc[\"non_nan_obs_count\"] = df[flag_vars].notna().sum()\n",
    "\n",
    "    # send file to AWS\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/{network}/eraqc_counts/{station}_flag_counts_hourly_standardized.csv\"\n",
    "    flag_counts.to_csv(csv_s3_filepath, index=True)\n",
    "\n",
    "    return flag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "17b6e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt = df[['time','ps','ps_eraqc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "684164c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_vals = df_filt[df_filt['ps'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8e047cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 21.])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_vals['ps_eraqc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47f7ee",
   "metadata": {},
   "source": [
    "Do we include 'nan' values in the total number of observations? \n",
    "- nan values can be flagged, see above\n",
    "\n",
    "The houry standardization process add rows within time gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ab4055dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that remain constant within each hour\n",
    "constant_vars = [\n",
    "    \"time\",\n",
    "    \"station\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"elevation\",\n",
    "    \"anemometer_height_m\",\n",
    "    \"thermometer_height_m\",\n",
    "]\n",
    "\n",
    "# Aggregation across hour variables, standard meteorological convention: precipitation and solar radiation\n",
    "sum_vars = [\n",
    "    \"time\",\n",
    "    \"pr\",\n",
    "    \"pr_localmid\",\n",
    "    \"pr_24h\",\n",
    "    \"pr_1h\",\n",
    "    \"pr_15min\",\n",
    "    \"pr_5min\",\n",
    "    \"rsds\",\n",
    "]\n",
    "\n",
    "# Top of the hour variables, standard meteorological convention: temperature, dewpoint temperature, pressure, humidity, winds\n",
    "instant_vars = [\n",
    "    \"hurs_derived\",\n",
    "    \"time\",\n",
    "    \"tas\",\n",
    "    \"tas_derived\",\n",
    "    \"tdps\",\n",
    "    \"tdps_derived\",\n",
    "    \"ps\",\n",
    "    \"psl\",\n",
    "    \"ps_altimeter\",\n",
    "    \"ps_derived\",\n",
    "    \"hurs\",\n",
    "    \"sfcWind\",\n",
    "    \"sfcWind_dir\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c14e24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a time gap at 1981-02-05 07:00:00\n",
    "\n",
    "df_st_time_filt = df_st.loc[\n",
    "    (df_st[\"time\"] >= \"1981-02-05 00:00:00\") & (df_st[\"time\"] < \"1981-02-05 23:00:00\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9aa16081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elevation</th>\n",
       "      <th>anemometer_height_m</th>\n",
       "      <th>thermometer_height_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9624</th>\n",
       "      <td>1981-02-05 00:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9625</th>\n",
       "      <td>1981-02-05 01:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9626</th>\n",
       "      <td>1981-02-05 02:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9627</th>\n",
       "      <td>1981-02-05 03:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9628</th>\n",
       "      <td>1981-02-05 04:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9629</th>\n",
       "      <td>1981-02-05 05:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9630</th>\n",
       "      <td>1981-02-05 06:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9631</th>\n",
       "      <td>1981-02-05 07:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9632</th>\n",
       "      <td>1981-02-05 08:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9633</th>\n",
       "      <td>1981-02-05 09:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9634</th>\n",
       "      <td>1981-02-05 10:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9635</th>\n",
       "      <td>1981-02-05 11:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9636</th>\n",
       "      <td>1981-02-05 12:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>1981-02-05 13:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>1981-02-05 14:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9639</th>\n",
       "      <td>1981-02-05 15:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>1981-02-05 16:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9641</th>\n",
       "      <td>1981-02-05 17:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642</th>\n",
       "      <td>1981-02-05 18:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9643</th>\n",
       "      <td>1981-02-05 19:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9644</th>\n",
       "      <td>1981-02-05 20:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9645</th>\n",
       "      <td>1981-02-05 21:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9646</th>\n",
       "      <td>1981-02-05 22:00:00</td>\n",
       "      <td>ASOSAWOS_72493023230</td>\n",
       "      <td>37.733</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time               station     lat    lon  elevation  \\\n",
       "9624 1981-02-05 00:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9625 1981-02-05 01:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9626 1981-02-05 02:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9627 1981-02-05 03:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9628 1981-02-05 04:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9629 1981-02-05 05:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9630 1981-02-05 06:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9631 1981-02-05 07:00:00                  None     NaN    NaN        NaN   \n",
       "9632 1981-02-05 08:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9633 1981-02-05 09:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9634 1981-02-05 10:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9635 1981-02-05 11:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9636 1981-02-05 12:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9637 1981-02-05 13:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9638 1981-02-05 14:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9639 1981-02-05 15:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9640 1981-02-05 16:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9641 1981-02-05 17:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9642 1981-02-05 18:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9643 1981-02-05 19:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9644 1981-02-05 20:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9645 1981-02-05 21:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "9646 1981-02-05 22:00:00  ASOSAWOS_72493023230  37.733 -122.2        2.0   \n",
       "\n",
       "      anemometer_height_m  thermometer_height_m  \n",
       "9624                10.06                   NaN  \n",
       "9625                10.06                   NaN  \n",
       "9626                10.06                   NaN  \n",
       "9627                10.06                   NaN  \n",
       "9628                10.06                   NaN  \n",
       "9629                10.06                   NaN  \n",
       "9630                10.06                   NaN  \n",
       "9631                  NaN                   NaN  \n",
       "9632                10.06                   NaN  \n",
       "9633                10.06                   NaN  \n",
       "9634                10.06                   NaN  \n",
       "9635                10.06                   NaN  \n",
       "9636                10.06                   NaN  \n",
       "9637                10.06                   NaN  \n",
       "9638                10.06                   NaN  \n",
       "9639                10.06                   NaN  \n",
       "9640                10.06                   NaN  \n",
       "9641                10.06                   NaN  \n",
       "9642                10.06                   NaN  \n",
       "9643                10.06                   NaN  \n",
       "9644                10.06                   NaN  \n",
       "9645                10.06                   NaN  \n",
       "9646                10.06                   NaN  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_st_time_filt[[col for col in constant_vars if col in df_st_time_filt.columns]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4024e0",
   "metadata": {},
   "source": [
    "Within time gaps in the input dataframe, the standardization process does the following:\n",
    "- inserts None for \"station\"\n",
    "- inserts 'nan' for flag columns\n",
    "- inserts NaN for all other columns\n",
    "\n",
    "Is this what we want? Do we want to include data in the time gaps in the success report statistics?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
