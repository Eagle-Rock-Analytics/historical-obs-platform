{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c073d99",
   "metadata": {},
   "source": [
    "# Success Report Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10b04b",
   "metadata": {},
   "source": [
    "per station \n",
    "- total % flagged\n",
    "- % flagged per variable\n",
    "- % flagged per QAQC flag\n",
    "\n",
    "NEED: per station raw counts tables\n",
    "\n",
    "per network\n",
    "- % flagged per variable (highest and lowest)\n",
    "- % flagged per QAQC flag (highest and lowest)\n",
    "- % flagged per station (highest and lowest)\n",
    "\n",
    "NEED: raw counts per variable, raw counts per QAQC flag, raw counts per station\n",
    "\n",
    "HOW: sum total and flagged per station, variable, and QAQC flag\n",
    "\n",
    "total\n",
    "- % flagged per network\n",
    "- % flagged per variable (highest and lowest)\n",
    "- % flagged per QAQC flag (highest and lowest)\n",
    "\n",
    "NEED: raw counts per variable, raw counts per QAQC flag, raw counts per station\n",
    "\n",
    "HOW: sum total and flagged per network, variable, and QAQC flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce425205",
   "metadata": {},
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from functools import reduce\n",
    "\n",
    "import inspect\n",
    "\n",
    "import logging\n",
    "# Create a simple logger that just prints to the console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "stations_csv_path = f\"s3://{bucket_name}/2_clean_wx/temp_clean_all_station_list.csv\"\n",
    "qaqc_dir = \"3_qaqc_wx\"\n",
    "merge_dir = \"4_merge_wx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7594f1f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_sum(flag_df_1, flag_df_2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts(). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df_1: pd.DataFrame\n",
    "        dataframe of previously summed station flag counts\n",
    "    flag_df_2: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summed_df: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    if len(flag_df_1) == 0:\n",
    "        return flag_df_2\n",
    "    else:\n",
    "        total_df = pd.concat([flag_df_1, flag_df_2])\n",
    "\n",
    "        summed_df = total_df.groupby('eraqc_flag_values', as_index=False).sum()\n",
    "        return summed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_sum_flag_counts(network: str, timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all station QAQC flag counts in a network for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network: str\n",
    "        network name\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing station flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/{network}_flag_counts_{timestep}_timestep.csv\"\n",
    "    # summed_counts_df.to_csv(csv_s3_filepath, index=False)\n",
    "    print(\n",
    "        f\"Sending summed counts dataframe for {network} to: {csv_s3_filepath}\"\n",
    "    )\n",
    "\n",
    "    return summed_counts_df  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cf721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_flag_counts(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all network-level QAQC flag counts for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing network-level flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/per_network_flag_counts\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all networks CSVs\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "\n",
    "    csv_s3_filepath = (\n",
    "        f\"s3://wecc-historical-wx/4_merge_wx/total_flag_counts_{timestep}_timestep.csv\"\n",
    "    )\n",
    "    # summed_counts_df.to_csv(csv_s3_filepath, index=False)\n",
    "    print(f\"Sending final summed counts dataframe for to: {csv_s3_filepath}\")\n",
    "\n",
    "    return summed_counts_df  # None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4eb5a4",
   "metadata": {},
   "source": [
    "## Run the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d1071",
   "metadata": {},
   "source": [
    "After the merge step is compelte, run network_sum_flag_counts() for all networks. Then run total_sum_flag_counts() a single timee. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"ASOSAWOS\"\n",
    "timestep = \"hourly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7971945",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_result = network_sum_flag_counts(network, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result = total_sum_flag_counts(timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10ed84",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d928bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_hourly_network = pd.read_csv(\n",
    "    f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/ASOSAWOS_flag_counts_hourly_timestep.csv\"\n",
    ")\n",
    "counts_native_network = pd.read_csv(\n",
    "    f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/ASOSAWOS_flag_counts_native_timestep.csv\"\n",
    ")\n",
    "\n",
    "counts_hourly_total = pd.read_csv(\n",
    "    f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/ASOSAWOS_flag_counts_hourly_timestep.csv\"\n",
    ")\n",
    "\n",
    "counts_native_total = pd.read_csv(\n",
    "    f\"s3://wecc-historical-wx/4_merge_wx/total_flag_counts_native_timestep.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0829c",
   "metadata": {},
   "source": [
    "Load in previously generate flag counts tables, as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "station1 = \"ASOSAWOS_72493023230\"\n",
    "station2 = \"ASOSAWOS_69007093217\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6023fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1_native = f\"4_merge_wx/{network}/eraqc_counts_native_timestep/{station1}_flag_counts_native_timestep.csv\"\n",
    "key1_hourly = f\"4_merge_wx/{network}/eraqc_counts_hourly_timestep/{station1}_flag_counts_hourly_standardized.csv\"\n",
    "\n",
    "key2_native = f\"4_merge_wx/{network}/eraqc_counts_native_timestep/{station2}_flag_counts_native_timestep.csv\"\n",
    "key2_hourly = f\"4_merge_wx/{network}/eraqc_counts_hourly_timestep/{station2}_flag_counts_hourly_standardized.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_counts1_hourly = pd.read_csv(f\"s3://wecc-historical-wx/{key1_hourly}\")\n",
    "flag_counts1_native = pd.read_csv(f\"s3://wecc-historical-wx/{key1_native}\")\n",
    "\n",
    "flag_counts2_hourly = pd.read_csv(f\"s3://wecc-historical-wx/{key2_hourly}\")\n",
    "flag_counts2_native = pd.read_csv(f\"s3://wecc-historical-wx/{key2_native}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196bae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_counts1_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55655a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_counts1_native"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c29ec1",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce23be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081be385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_flag_counts(network: str, timestep:str, level: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all QAQC flag counts at a given level (across stations or across networks) and for a given timestep (hourly or native)\n",
    "    and sends to AWS. These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network: str\n",
    "        network name, only used when 'level' = 'network'\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "    level: str\n",
    "        if set to 'network', merge across all station flag count tables\n",
    "        if set to 'total', merge across all network flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    if timestep not in ('hourly','native'):\n",
    "        print('invalid timestep: ',timestep) \n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    ## Assign AWS level and final CSV destiation depening on 'level' argument\n",
    "\n",
    "    if level == 'network':\n",
    "        # AWS level to loop through\n",
    "        flags_prefix = f\"{merge_dir}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "        # where to send the final CSV\n",
    "        csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/{network}_flag_counts_{timestep}_timestep.csv\"\n",
    "    \n",
    "    elif level == 'total':\n",
    "        # AWS level to loop through\n",
    "        flags_prefix = f\"{merge_dir}/per_network_flag_counts\"\n",
    "        # where to send the final CSV\n",
    "        csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/total_flag_counts_{timestep}_timestep.csv\"\n",
    "    \n",
    "    else: \n",
    "        print('invalid level: ', level)\n",
    "        return None\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "    \n",
    "    summed_counts_df.to_csv(csv_s3_filepath, index=False)\n",
    "    print('Sending final summed counts dataframe to: ', csv_s3_filepath)\n",
    "\n",
    "    return summed_counts_df # None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
