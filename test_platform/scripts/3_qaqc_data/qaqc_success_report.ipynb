{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c073d99",
   "metadata": {},
   "source": [
    "# Success Report Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10b04b",
   "metadata": {},
   "source": [
    "per station \n",
    "- total % flagged\n",
    "- % flagged per variable\n",
    "- % flagged per QAQC flag\n",
    "\n",
    "NEED: per station raw counts tables\n",
    "\n",
    "per network\n",
    "- % flagged per variable (highest and lowest)\n",
    "- % flagged per QAQC flag (highest and lowest)\n",
    "- % flagged per station (highest and lowest)\n",
    "\n",
    "NEED: raw counts per variable, raw counts per QAQC flag, raw counts per station\n",
    "\n",
    "HOW: sum total and flagged per station, variable, and QAQC flag\n",
    "\n",
    "total\n",
    "- % flagged per network\n",
    "- % flagged per variable (highest and lowest)\n",
    "- % flagged per QAQC flag (highest and lowest)\n",
    "\n",
    "NEED: raw counts per variable, raw counts per QAQC flag, raw counts per station\n",
    "\n",
    "HOW: sum total and flagged per network, variable, and QAQC flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce425205",
   "metadata": {},
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e2b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from functools import reduce\n",
    "\n",
    "import inspect\n",
    "\n",
    "import logging\n",
    "# Create a simple logger that just prints to the console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7320ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "stations_csv_path = f\"s3://{bucket_name}/2_clean_wx/temp_clean_all_station_list.csv\"\n",
    "qaqc_dir = \"3_qaqc_wx\"\n",
    "merge_dir = \"4_merge_wx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7594f1f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8c45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_sum(flag_df_1, flag_df_2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts(). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df_1: pd.DataFrame\n",
    "        dataframe of previously summed station flag counts\n",
    "    flag_df_2: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summed_df: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    if len(flag_df_1) == 0:\n",
    "        return flag_df_2\n",
    "    else:\n",
    "        total_df = pd.concat([flag_df_1, flag_df_2])\n",
    "\n",
    "        summed_df = total_df.groupby('eraqc_flag_values', as_index=False).sum()\n",
    "        return summed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081be385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:22: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:22: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/tmp/ipykernel_1294/1508735193.py:22: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if timestep is not 'hourly' or 'native':\n"
     ]
    }
   ],
   "source": [
    "def sum_flag_counts(network: str, timestep:str, level: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all QAQC flag counts at a given level (across stations or across networks) and for a given timestep (hourly or native)\n",
    "    and sends to AWS. These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network: str\n",
    "        network name\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "    level: str\n",
    "        if set to 'network', merge across all station flag count tables\n",
    "        if set to 'total', merge across all network flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    if timestep is not 'hourly' or 'native':\n",
    "        print('invalid timestep: ',timestep) \n",
    "        return None\n",
    "\n",
    "    # store summed flag counts here\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    if level == 'network':\n",
    "        flags_prefix = f\"{merge_dir}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "    elif level == 'total':\n",
    "        flags_prefix = f\"{merge_dir}/{network}/{network}_flag_counts_{timestep}_timestep.csv\"\n",
    "    else: \n",
    "        print('invalid level: ', level)\n",
    "        return None\n",
    "\n",
    "    ## merge timestep flag counts\n",
    "\n",
    "    # loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## send file to AWS\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/{network}/{network}_flag_counts_{timestep}_timestep.csv\"\n",
    "    summed_counts_df.to_csv(csv_s3_filepath, index=True)\n",
    "    print('Sending final summed counts dataframe to: ', csv_s3_filepath)\n",
    "\n",
    "    return summed_counts_df # None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb122f",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"ASOSAWOS\"\n",
    "station1 = \"ASOSAWOS_72493023230\"\n",
    "station2 = \"ASOSAWOS_69007093217\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e97663",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(stations_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6023fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1_native = f\"4_merge_wx/{network}/eraqc_counts_native_timestep/{station1}_flag_counts_native_timestep.csv\"\n",
    "key1_hourly = f\"4_merge_wx/{network}/eraqc_counts_hourly_timestep/{station1}_flag_counts_hourly_standardized.csv\"\n",
    "\n",
    "key2_native = f\"4_merge_wx/{network}/eraqc_counts_native_timestep/{station2}_flag_counts_native_timestep.csv\"\n",
    "key2_hourly = f\"4_merge_wx/{network}/eraqc_counts_hourly_timestep/{station2}_flag_counts_hourly_standardized.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_counts1_hourly = pd.read_csv(f\"s3://wecc-historical-wx/{key1_hourly}\")\n",
    "flag_counts1_native = pd.read_csv(f\"s3://wecc-historical-wx/{key1_native}\")\n",
    "\n",
    "flag_counts2_hourly = pd.read_csv(f\"s3://wecc-historical-wx/{key2_hourly}\")\n",
    "flag_counts2_native = pd.read_csv(f\"s3://wecc-historical-wx/{key2_native}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce23be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
