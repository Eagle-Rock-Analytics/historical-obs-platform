{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script performs qa/qc protocols for cleaned station data for ingestion into the Historical Observations Platform, and is\n",
    "independent of network.\n",
    "Approach:\n",
    "(1) Remove duplicate stations\n",
    "(2) Handle variables that report at different intervals and/or change frequency over time (convert to hourly?)\n",
    "(3) QA/QC testing, including consistency checks, gaps, checks against climatological distributions, and cross variable checks.\n",
    "(4) Case study analysis for accuracy -- SHOULD THIS BE A SEPARATE SCRIPT/PROCESS?\n",
    "\n",
    "Inputs: Cleaned data for an individual network\n",
    "Outputs: QA/QC-processed data for an individual network, priority variables, all times. Organized by station as .nc file.\n",
    "\"\"\"\n",
    "\n",
    "# Step 0: Environment set-up\n",
    "# Import libraries\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import boto3\n",
    "import s3fs\n",
    "from io import StringIO\n",
    "import time\n",
    "import tempfile\n",
    "from mpi4py import MPI\n",
    "import logging\n",
    "from simplempi import simpleMPI\n",
    "\n",
    "# Import all qaqc script functions\n",
    "try:\n",
    "    from qaqc_plot import *\n",
    "    from qaqc_utils import *\n",
    "    from qaqc_wholestation import *\n",
    "    from qaqc_logic_checks import *\n",
    "    from qaqc_buoy_check import *\n",
    "    from qaqc_frequent import *\n",
    "    from qaqc_unusual_gaps import *\n",
    "    from qaqc_unusual_large_jumps import *\n",
    "    from qaqc_climatological_outlier import *\n",
    "    from qaqc_unusual_streaks import *\n",
    "    from qaqc_deaccumulate import *\n",
    "except Exception as e:\n",
    "    print(\"Error importing qaqc script: {}\".format(e))\n",
    "\n",
    "from log_config import setup_logger\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "## Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "## Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "\n",
    "# Define temporary directory in local drive for downloading data from S3 bucket\n",
    "# If the directory doesn't exist, it will be created\n",
    "# If we used zarr, this wouldn't be neccessary\n",
    "temp_dir = \"./tmp\"\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.mkdir(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def setup_error_handling():\n",
    "    \"\"\"Sets-up error handling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    errors : dict\n",
    "        dictionary of file, timing, and error message\n",
    "    end_api : datetime\n",
    "        time at beginnging of data download\n",
    "    tiemstamp: datetime\n",
    "        time at runtime\n",
    "    \"\"\"\n",
    "    errors = {\"File\": [], \"Time\": [], \"Error\": []}  # Set up error handling\n",
    "    end_api = datetime.datetime.now().strftime(\n",
    "        \"%Y%m%d%H%M\"\n",
    "    )  # Set end time to be current time at beginning of download: for error handling csv\n",
    "    timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "    return errors, end_api, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "def print_qaqc_failed(\n",
    "    errors, station=None, end_api=None, message=None, test=None, verbose=False\n",
    "):\n",
    "    \"\"\"QAQC failure messaging\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    errors : dict\n",
    "        dictionary of file, timing, and error message\n",
    "    station : str, optional\n",
    "        station name\n",
    "    end_api : datetime, optional\n",
    "        time at beginning of data download\n",
    "    message : str, optional\n",
    "        error message\n",
    "    test : str, optional\n",
    "        QAQC test name to include in error message\n",
    "    verbose : bool, optional\n",
    "        if True, provides runtime output to local terminal\n",
    "    \"\"\"\n",
    "    logger.info(\n",
    "        \"{0} {1}, skipping station\".format(station, message),\n",
    "    )\n",
    "    errors[\"File\"].append(station)\n",
    "    errors[\"Time\"].append(end_api)\n",
    "    errors[\"Error\"].append(\"Failure on {}\".format(test))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nc_from_s3_clean(network_name, station_id, temp_dir):\n",
    "    \"\"\"Read netcdf file containing station data for a single station of interest from AWS s3 bucket\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network_name: str\n",
    "        Name of network (i.e. \"ASOSAWOS\")\n",
    "        Must correspond with a valid directory in the s3 bucket (i.e. \"CAHYDRO\", \"CDEC\", \"ASOSAWOS\")\n",
    "    station_id: str\n",
    "        Station identifier; i.e. the name of the netcdf file in the bucket (i.e. \"ASOSAWOS_72012200114.nc\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    station_data: xr.Dataset\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The data is first downloaded from AWS into a tempfile, which is then deleted after xarray reads in the file\n",
    "    I'd like to see us use a zarr workflow if possible to avoid this.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Temp file for downloading from s3\n",
    "    temp_file = tempfile.NamedTemporaryFile(\n",
    "        dir=temp_dir, prefix=\"\", suffix=\".nc\", delete=True\n",
    "    )\n",
    "\n",
    "    # Create s3 file system\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "    # Get URL to netcdf in S3\n",
    "    s3_url = \"s3://wecc-historical-wx/2_clean_wx/{}/{}.nc\".format(\n",
    "        network_name, station_id\n",
    "    )\n",
    "\n",
    "    # Read in the data using xarray\n",
    "    s3_file_obj = s3.get(s3_url, temp_file.name)\n",
    "    station_data = xr.open_dataset(temp_file.name, engine=\"h5netcdf\").load()\n",
    "\n",
    "    # Close temporary file\n",
    "    temp_file.close()\n",
    "\n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaqc_ds_to_df_other(ds, verbose=False):\n",
    "    \"\"\"Converts xarray ds for a station to pandas df in the format needed for the pipeline\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        input data from the clean step\n",
    "    verbose : bool, optional\n",
    "        if True, provides runtime output to the terminal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        converted xr.Dataset into dataframe\n",
    "    MultiIndex : pd.Index\n",
    "        multi-index of station and time\n",
    "    attrs : list of str\n",
    "        attributes from xr.Dataset\n",
    "    var_attrs : list of str\n",
    "        variable attributes from xr.Dataset\n",
    "    era_qc_vars : list of str\n",
    "        QAQC variables\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is the notebook friendly version (no logger statements).\n",
    "    \"\"\"\n",
    "    ## Add qc_flag variable for all variables, including elevation;\n",
    "    ## defaulting to nan for fill value that will be replaced with qc flag\n",
    "\n",
    "    for key, val in ds.variables.items():\n",
    "        if val.dtype == object:\n",
    "            if key == \"station\":\n",
    "                if str in [type(v) for v in ds[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "            else:\n",
    "                if str in [type(v) for v in ds.isel(station=0)[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "\n",
    "    exclude_qaqc = [\n",
    "        \"time\",\n",
    "        \"station\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"qaqc_process\",\n",
    "        \"sfcWind_method\",\n",
    "        \"pr_duration\",\n",
    "        \"pr_depth\",\n",
    "        \"PREC_flag\",\n",
    "        \"rsds_duration\",\n",
    "        \"rsds_flag\",\n",
    "        \"anemometer_height_m\",\n",
    "        \"thermometer_height_m\",\n",
    "    ]  # lat, lon have different qc check\n",
    "\n",
    "    raw_qc_vars = []  # qc_variable for each data variable, will vary station to station\n",
    "    era_qc_vars = []  # our ERA qc variable\n",
    "    old_era_qc_vars = []  # our ERA qc variable\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if \"q_code\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variable, need to keep for comparison, then drop\n",
    "        if \"_qc\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variables, need to keep for comparison, then drop\n",
    "        if \"_eraqc\" in var:\n",
    "            era_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variables, need to keep for comparison, then drop\n",
    "            old_era_qc_vars.append(var)\n",
    "\n",
    "    print(f\"era_qc existing variables:\\n{era_qc_vars}\")\n",
    "    n_qc = len(era_qc_vars)\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if var not in exclude_qaqc and var not in raw_qc_vars and \"_eraqc\" not in var:\n",
    "            qc_var = var + \"_eraqc\"  # variable/column label\n",
    "\n",
    "            # if qaqc var does not exist, adds new variable in shape of original variable with designated nan fill value\n",
    "            if qc_var not in era_qc_vars:\n",
    "                print(f\"nans created for {qc_var}\")\n",
    "                ds = ds.assign({qc_var: xr.ones_like(ds[var]) * np.nan})\n",
    "                era_qc_vars.append(qc_var)\n",
    "\n",
    "    print(\"{} created era_qc variables\".format(len(era_qc_vars) - len(old_era_qc_vars)))\n",
    "    if len(era_qc_vars) != n_qc:\n",
    "        print(\"{}\".format(np.setdiff1d(old_era_qc_vars, era_qc_vars)))\n",
    "\n",
    "    # Save attributes to inheret them to the QAQC'ed file\n",
    "    attrs = ds.attrs\n",
    "    # var_attrs = {var: ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        df = ds.to_dataframe()\n",
    "\n",
    "    # instrumentation heights\n",
    "    if \"anemometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"anemometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.anemometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            print(\"Filling anemometer_height_m with NaN.\", flush=True)\n",
    "            df[\"anemometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "    if \"thermometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"thermometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.thermometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            print(\"Filling thermometer_height_m with NaN.\", flush=True)\n",
    "            df[\"thermometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "\n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df[\"station\"] = station\n",
    "\n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "\n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    # Add time variables needed by multiple functions\n",
    "    df[\"hour\"] = pd.to_datetime(df[\"time\"]).dt.hour\n",
    "    df[\"day\"] = pd.to_datetime(df[\"time\"]).dt.day\n",
    "    df[\"month\"] = pd.to_datetime(df[\"time\"]).dt.month\n",
    "    df[\"year\"] = pd.to_datetime(df[\"time\"]).dt.year\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.date\n",
    "\n",
    "    return df  # , MultiIndex, attrs, var_attrs, era_qc_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "def qaqc_ds_to_df(ds, verbose=False):\n",
    "    \"\"\"Converts xarray ds for a station to pandas df in the format needed for the pipeline\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        input data from the clean step\n",
    "    verbose : bool, optional\n",
    "        if True, provides runtime output to the terminal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        converted xr.Dataset into dataframe\n",
    "    MultiIndex : pd.Index\n",
    "        multi-index of station and time\n",
    "    attrs : list of str\n",
    "        attributes from xr.Dataset\n",
    "    var_attrs : list of str\n",
    "        variable attributes from xr.Dataset\n",
    "    era_qc_vars : list of str\n",
    "        QAQC variables\n",
    "    \"\"\"\n",
    "\n",
    "    ## Add qc_flag variable for all variables, including elevation;\n",
    "    ## defaulting to nan for fill value that will be replaced with qc flag\n",
    "\n",
    "    for key, val in ds.variables.items():\n",
    "        if val.dtype == object:\n",
    "            if key == \"station\":\n",
    "                if str in [type(v) for v in ds[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "            else:\n",
    "                if str in [type(v) for v in ds.isel(station=0)[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "\n",
    "    exclude_qaqc = [\n",
    "        \"time\",\n",
    "        \"station\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"qaqc_process\",\n",
    "        \"sfcWind_method\",\n",
    "        \"pr_duration\",\n",
    "        \"pr_depth\",\n",
    "        \"PREC_flag\",\n",
    "        \"rsds_duration\",\n",
    "        \"rsds_flag\",\n",
    "        \"anemometer_height_m\",\n",
    "        \"thermometer_height_m\",\n",
    "    ]  # lat, lon have different qc check\n",
    "\n",
    "    raw_qc_vars = []  # qc_variable for each data variable, will vary station to station\n",
    "    era_qc_vars = []  # our ERA qc variable\n",
    "    # old_era_qc_vars = []  # our ERA qc variable\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if \"q_code\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variable, need to keep for comparison, then drop\n",
    "        if \"_qc\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variables, need to keep for comparison, then drop\n",
    "\n",
    "    logger.info(\"Existing era_qc variables: {}\".format(era_qc_vars))\n",
    "\n",
    "    # only in-fill nans for valid variables\n",
    "    for var in ds.data_vars:\n",
    "        if var not in exclude_qaqc and var not in raw_qc_vars and \"_eraqc\" not in var:\n",
    "            qc_var = var + \"_eraqc\"  # variable/column label\n",
    "\n",
    "            # if qaqc var does not exist, adds new variable in shape of original variable with designated nan fill value\n",
    "            if qc_var not in era_qc_vars:\n",
    "                ds = ds.assign({qc_var: xr.ones_like(ds[var]) * np.nan})\n",
    "                era_qc_vars.append(qc_var)\n",
    "                logger.info(\n",
    "                    \"nans created for {}\".format(qc_var),\n",
    "                )\n",
    "                ds = ds.assign({qc_var: xr.ones_like(ds[var]) * np.nan})\n",
    "\n",
    "    n_qc = len(era_qc_vars)  # determine length of eraqc variables per station\n",
    "    logger.info(\"Created {0} era_qc variables: {1}\".format(n_qc, era_qc_vars))\n",
    "\n",
    "    # Save attributes to inheret them to the QAQC'ed file\n",
    "    attrs = ds.attrs\n",
    "    var_attrs = {var: ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        df = ds.to_dataframe()\n",
    "\n",
    "    # instrumentation heights\n",
    "    if \"anemometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"anemometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.anemometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling anemometer_height_m with NaN.\")\n",
    "            df[\"anemometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "\n",
    "    if \"thermometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"thermometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.thermometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            logger.info(\"Filling thermometer_height_m with NaN.\")\n",
    "            df[\"thermometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "\n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df[\"station\"] = station\n",
    "\n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "\n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    # Add time variables needed by multiple functions\n",
    "    df[\"hour\"] = pd.to_datetime(df[\"time\"]).dt.hour\n",
    "    df[\"day\"] = pd.to_datetime(df[\"time\"]).dt.day\n",
    "    df[\"month\"] = pd.to_datetime(df[\"time\"]).dt.month\n",
    "    df[\"year\"] = pd.to_datetime(df[\"time\"]).dt.year\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.date\n",
    "\n",
    "    return df, MultiIndex, attrs, var_attrs, era_qc_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataframe\n",
    "ds_bhcc1 = read_nc_from_s3_clean(\"CNRFC\", \"CNRFC_BHCC1\", temp_dir)\n",
    "\n",
    "# convert to formatted pandas dataframe\n",
    "df_bhcc1 = qaqc_ds_to_df(ds_bhcc1, verbose=False) #TODO: using ds to df in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataframe\n",
    "ds_sapc1 = read_nc_from_s3_clean(\"CNRFC\", \"CNRFC_SAPC1\", temp_dir)\n",
    "\n",
    "# convert to formatted pandas dataframe\n",
    "df_sapc1 = qaqc_ds_to_df_other(ds_sapc1, verbose=False) #TODO\" using ds to df that I have modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_bhcc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "local=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_to_qaqc = df.copy()  # Need to define before qaqc_pipeline, in case\n",
    "new_df = qaqc_missing_vals(stn_to_qaqc, verbose=verbose)\n",
    "new_df = qaqc_missing_latlon(stn_to_qaqc, verbose=verbose)\n",
    "new_df = qaqc_within_wecc(stn_to_qaqc, verbose=verbose)\n",
    "new_df = qaqc_elev_infill(\n",
    "    stn_to_qaqc, verbose=verbose\n",
    ")  # nan infilling must be before range check\n",
    "new_df = qaqc_elev_range(stn_to_qaqc, verbose=verbose)\n",
    "new_df = qaqc_pressure_units_fix(stn_to_qaqc, verbose=verbose)\n",
    "new_df = qaqc_deaccumulate_precip(stn_to_qaqc, local=local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaqc_world_record(df, verbose=False):\n",
    "    \"\"\"\n",
    "    Checks if variables are outside North American world records.\n",
    "    If outside minimum or maximum records, flags values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        station dataset converted to dataframe through QAQC pipeline\n",
    "    verbose : bool, optional\n",
    "        if True, returns runtime output to terminal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    If QAQC is successful, returns a dataframe with flagged values (see below for flag meaning)\n",
    "    If QAQC fails, returns None\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "    Flag meaning : 11,qaqc_world_record,Value outside of world record range\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] World records from HadISD protocol, cross-checked with WMO database\n",
    "    [2] https://wmo.asu.edu/content/world-meteorological-organization-global-weather-climate-extremes-archive\n",
    "    [3] Solar radiation specific: Rupp et al. 2022, Slater 2016\n",
    "    [4] https://www.ncei.noaa.gov/access/monitoring/scec/records\n",
    "    [5] https://www.weather.gov/media/owp/oh/hdsc/docs/TP2.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Running: qaqc_world_record\")\n",
    "\n",
    "    try:\n",
    "        T_X = {\"North_America\": 329.92}  # temperature, K\n",
    "        T_N = {\"North_America\": 210.15}  # temperature, K\n",
    "        D_X = {\"North_America\": 329.85}  # dewpoint temperature, K\n",
    "        D_N = {\"North_America\": 173.15}  # dewpoint temperature, K\n",
    "        W_X = {\"North_America\": 113.2}  # wind speed, m/s\n",
    "        W_N = {\"North_America\": 0.0}  # wind speed, m/s\n",
    "        R_X = {\"North_America\": 1500}  # solar radiation, W/m2\n",
    "        R_N = {\"North_America\": -5}  # solar radiation, W/m2\n",
    "\n",
    "        # for other non-record variables (wind direction, humidity)\n",
    "        N_X = {\"North_America\": 360}  # wind direction, degrees\n",
    "        N_N = {\"North_America\": 0}  # wind direction, degrees\n",
    "        H_X = {\"North_America\": 100}  # humidity, max\n",
    "        H_N = {\"North_America\": 0}  # humidity, min\n",
    "        E_X = {\"North_America\": 6210.0}  # elevation, m\n",
    "        E_N = {\"North_America\": -100}  # elevation, m\n",
    "\n",
    "        # pressure, with elevation options\n",
    "        S_X = {\"North_America\": 108330}  # pressure, Pa\n",
    "        S_N = {\"North_America\": 87000}  # sea level pressure only, Pa\n",
    "        SALT_N = {\n",
    "            \"North_America\": 45960\n",
    "        }  # non-sea level pressure, Pa, reduced min based on max elevation (6190 m)\n",
    "\n",
    "        # precipitation, with variations depending on reporting interval\n",
    "        P_X = {\"North_America\": 656}  # precipitation, mm, 24-hr rainfall\n",
    "        PALT5_X = {\n",
    "            \"North_America\": 31.8\n",
    "        }  # precipitation, mm, 5-min rainfall, WECC-wide\n",
    "        PALT15_X = {\n",
    "            \"North_America\": 25.4\n",
    "        }  # precipitation, mm, 15-min rainfall, specific to VALLEYWATER\n",
    "        PACC_X = {\n",
    "            \"North_America\": 10000\n",
    "        }  # accumulated precipitation, mm, arbirtarily set to a high max value\n",
    "        P_N = {\"North_America\": 0}  # precipitaiton, mm\n",
    "\n",
    "        maxes = {\n",
    "            \"tas\": T_X,\n",
    "            \"tdps\": D_X,\n",
    "            \"tdps_derived\": D_X,\n",
    "            \"sfcWind\": W_X,\n",
    "            \"sfcWind_dir\": N_X,\n",
    "            \"psl\": S_X,\n",
    "            \"ps\": S_X,\n",
    "            \"ps_derived\": S_X,\n",
    "            \"ps_altimeter\": S_X,\n",
    "            \"rsds\": R_X,\n",
    "            \"pr\": P_X,\n",
    "            \"pr_5min\": PALT5_X,\n",
    "            \"pr_15min\": PALT15_X,\n",
    "            \"pr_1h\": P_X,\n",
    "            \"pr_24h\": P_X,\n",
    "            \"pr_localmid\": P_X,\n",
    "            \"accum_pr\": PACC_X,\n",
    "            \"hurs\": H_X,\n",
    "            \"elevation\": E_X,\n",
    "        }\n",
    "        mins = {\n",
    "            \"tas\": T_N,\n",
    "            \"tdps\": D_N,\n",
    "            \"tdps_derived\": D_N,\n",
    "            \"sfcWind\": W_N,\n",
    "            \"sfcWind_dir\": N_N,\n",
    "            \"psl\": S_N,\n",
    "            \"ps\": SALT_N,\n",
    "            \"ps_derived\": SALT_N,\n",
    "            \"ps_altimeter\": SALT_N,\n",
    "            \"rsds\": R_N,\n",
    "            \"pr\": P_N,\n",
    "            \"pr_5min\": P_N,\n",
    "            \"pr_15min\": P_N,\n",
    "            \"pr_1h\": P_N,\n",
    "            \"pr_24h\": P_N,\n",
    "            \"pr_localmid\": P_N,\n",
    "            \"accum_pr\": P_N,\n",
    "            \"hurs\": H_N,\n",
    "            \"elevation\": E_N,\n",
    "        }\n",
    "\n",
    "        # variable names to check against world record limits\n",
    "        wr_vars = [\n",
    "            \"tas\",\n",
    "            \"tdps\",\n",
    "            \"tdps_derived\",\n",
    "            \"sfcWind\",\n",
    "            \"sfcWind_dir\",\n",
    "            \"ps\",\n",
    "            \"psl\",\n",
    "            \"ps_altimeter\",\n",
    "            \"ps_derived\",\n",
    "            \"rsds\",\n",
    "            \"pr\",\n",
    "            \"pr_5min\",\n",
    "            \"pr_15min\",\n",
    "            \"pr_1h\",\n",
    "            \"pr_24h\",\n",
    "            \"pr_localmid\",\n",
    "            \"accum_pr\",\n",
    "            \"hurs\",\n",
    "            \"elevation\",\n",
    "        ]\n",
    "        for var in wr_vars:\n",
    "            if var in list(df.columns):\n",
    "                df_valid = grab_valid_obs(df, var)  # subset for valid obs\n",
    "                isOffRecord = np.logical_or(\n",
    "                    df_valid[var] < mins[var][\"North_America\"],\n",
    "                    df_valid[var] > maxes[var][\"North_America\"],\n",
    "                )\n",
    "                if isOffRecord.any():\n",
    "                    isOffRecord_true = isOffRecord[isOffRecord]\n",
    "                    df.loc[df.index.isin(isOffRecord_true.index), var + \"_eraqc\"] = (\n",
    "                        11  # see era_qaqc_flag_meanings.csv\n",
    "                    )\n",
    "                    print(\n",
    "                        \"Flagging {} observations exceeding world/regional records: {}\".format(\n",
    "                            sum(isOffRecord_true), var\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            \"qaqc_world_record failed with Exception: {}\".format(e),\n",
    "        )\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sapc1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: qaqc_world_record\n",
      "Flagging 619 observations exceeding world/regional records: tas\n",
      "Flagging 1307 observations exceeding world/regional records: tdps_derived\n",
      "Flagging 11 observations exceeding world/regional records: sfcWind_dir\n",
      "Flagging 491 observations exceeding world/regional records: pr\n"
     ]
    }
   ],
   "source": [
    "test_df = qaqc_world_record(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tas</th>\n",
       "      <th>tas_eraqc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>349.26</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37546</th>\n",
       "      <td>349.26</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43930</th>\n",
       "      <td>332.59</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47450</th>\n",
       "      <td>351.48</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48940</th>\n",
       "      <td>344.26</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338738</th>\n",
       "      <td>522.04</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338739</th>\n",
       "      <td>338.15</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338741</th>\n",
       "      <td>1368.15</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338743</th>\n",
       "      <td>472.04</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338746</th>\n",
       "      <td>952.04</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tas  tas_eraqc\n",
       "3794     349.26       11.0\n",
       "37546    349.26       11.0\n",
       "43930    332.59       11.0\n",
       "47450    351.48       11.0\n",
       "48940    344.26       11.0\n",
       "...         ...        ...\n",
       "338738   522.04       11.0\n",
       "338739   338.15       11.0\n",
       "338741  1368.15       11.0\n",
       "338743   472.04       11.0\n",
       "338746   952.04       11.0\n",
       "\n",
       "[619 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tas range: 210.15 - 329.92\n",
    "\n",
    "check = test_df[test_df[\"tas_eraqc\"]==11]\n",
    "check[[\"tas\", \"tas_eraqc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331.47999999999996"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[\"tas\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tas</th>\n",
       "      <th>tas_eraqc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297.040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297.590</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559082</th>\n",
       "      <td>310.150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559083</th>\n",
       "      <td>310.706</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559084</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559085</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559086</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559087 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tas  tas_eraqc\n",
       "0       297.040        NaN\n",
       "1       297.590        NaN\n",
       "2       298.150        NaN\n",
       "3       299.820        NaN\n",
       "4       300.370        NaN\n",
       "...         ...        ...\n",
       "559082  310.150        NaN\n",
       "559083  310.706        NaN\n",
       "559084      NaN        NaN\n",
       "559085      NaN        NaN\n",
       "559086      NaN        NaN\n",
       "\n",
       "[559087 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[\"tas\", \"tas_eraqc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tas</th>\n",
       "      <th>tas_eraqc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297.040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297.590</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559082</th>\n",
       "      <td>310.150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559083</th>\n",
       "      <td>310.706</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559084</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559085</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559086</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559087 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tas  tas_eraqc\n",
       "0       297.040        NaN\n",
       "1       297.590        NaN\n",
       "2       298.150        NaN\n",
       "3       299.820        NaN\n",
       "4       300.370        NaN\n",
       "...         ...        ...\n",
       "559082  310.150        NaN\n",
       "559083  310.706        NaN\n",
       "559084      NaN        NaN\n",
       "559085      NaN        NaN\n",
       "559086      NaN        NaN\n",
       "\n",
       "[559087 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sapc1[['tas','tas_eraqc']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
