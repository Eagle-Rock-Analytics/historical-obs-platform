{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station Matching\n",
    "\n",
    "The goal of this notebook is to identify stations that changed IDs. This has been known to occur for Maritime and ASOSOAWOS stations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from functools import reduce\n",
    "import datetime\n",
    "from pandas import *\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "import tempfile  # Used for downloading (and then deleting) netcdfs to local drive from s3 bucket\n",
    "\n",
    "import s3fs\n",
    "\n",
    "# import tempfile  # Used for downloading (and then deleting) netcdfs to local drive from s3 bucket\n",
    "import os\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=ShapelyDeprecationWarning\n",
    ")  # Warning is raised when creating Point object from coords. Can't figure out why.\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "#s3 = s3fs.S3FileSystem  # must be set to this to use such commands as ls\n",
    "# s3 = boto3.resource('s3')\n",
    "# s3_client = boto3.client(\"s3\")\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")\n",
    "\n",
    "## AWS buckets\n",
    "bucket = \"wecc-historical-wx\"\n",
    "qaqcdir = \"3_qaqc_wx/\"\n",
    "mergedir = \"4_merge_wx/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define temporary directory in local drive for downloading data from S3 bucket\n",
    "# If the directory doesn't exist, it will be created\n",
    "# If we used zarr, this wouldn't be neccessary\n",
    "temp_dir = \"./tmp\"\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.mkdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nc_from_s3_clean(network_name, station_id, temp_dir):\n",
    "    \"\"\"Read netcdf file containing station data for a single station of interest from AWS s3 bucket\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network_name: str\n",
    "        Name of network (i.e. \"ASOSAWOS\")\n",
    "        Must correspond with a valid directory in the s3 bucket (i.e. \"CAHYDRO\", \"CDEC\", \"ASOSAWOS\")\n",
    "    station_id: str\n",
    "        Station identifier; i.e. the name of the netcdf file in the bucket (i.e. \"ASOSAWOS_72012200114.nc\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    station_data: xr.Dataset\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The data is first downloaded from AWS into a tempfile, which is then deleted after xarray reads in the file\n",
    "    I'd like to see us use a zarr workflow if possible to avoid this.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Temp file for downloading from s3\n",
    "    temp_file = tempfile.NamedTemporaryFile(\n",
    "        dir=temp_dir, prefix=\"\", suffix=\".nc\", delete=True\n",
    "    )\n",
    "\n",
    "    # Create s3 file system\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "    # Get URL to netcdf in S3\n",
    "    s3_url = \"s3://wecc-historical-wx/2_clean_wx/{}/{}.nc\".format(\n",
    "        network_name, station_id\n",
    "    )\n",
    "\n",
    "    # Read in the data using xarray\n",
    "    s3_file_obj = s3.get(s3_url, temp_file.name)\n",
    "    station_data = xr.open_dataset(temp_file.name, engine=\"h5netcdf\").load()\n",
    "\n",
    "    # Close temporary file\n",
    "    temp_file.close()\n",
    "\n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zarr_from_s3(station_id, temp_dir):\n",
    "    \"\"\"Read zarr file containing station data for a single station of interest from AWS s3 bucket\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network_name: str\n",
    "        Name of network (i.e. \"ASOSAWOS\")\n",
    "        Must correspond with a valid directory in the s3 bucket (i.e. \"CAHYDRO\", \"CDEC\", \"ASOSAWOS\")\n",
    "    station_id: str\n",
    "        Station identifier; i.e. the name of the netcdf file in the bucket (i.e. \"ASOSAWOS_72012200114.nc\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    station_data: xr.Dataset\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The data is first downloaded from AWS into a tempfile, which is then deleted after xarray reads in the file\n",
    "    \"\"\"\n",
    "\n",
    "    # Temp file for downloading from s3\n",
    "    temp_file = tempfile.NamedTemporaryFile(\n",
    "        dir=temp_dir, prefix=\"\", suffix=\".zarr\", delete=True\n",
    "    )\n",
    "\n",
    "    # Create s3 file system\n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "    # Get URL to netcdf in S3\n",
    "    s3_url = \"s3://wecc-historical-wx/3_qaqc_wx/VALLEYWATER/VALLEYWATER_{}.zarr\".format(\n",
    "        station_id\n",
    "    )\n",
    "    print(s3_url)\n",
    "\n",
    "    # Read in the data using xarray\n",
    "    s3_file_obj = s3.get(s3_url, temp_file.name)\n",
    "    station_data = xr.open_dataset(temp_file.name, engine=\"zarr\").load()\n",
    "\n",
    "    # Close temporary file\n",
    "    temp_file.close()\n",
    "\n",
    "    return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaqc_ds_to_df(ds, verbose=False):\n",
    "    \"\"\"Converts xarray ds for a station to pandas df in the format needed for the pipeline\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        input data from the clean step\n",
    "    verbose : bool, optional\n",
    "        if True, provides runtime output to the terminal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        converted xr.Dataset into dataframe\n",
    "    MultiIndex : pd.Index\n",
    "        multi-index of station and time\n",
    "    attrs : list of str\n",
    "        attributes from xr.Dataset\n",
    "    var_attrs : list of str\n",
    "        variable attributes from xr.Dataset\n",
    "    era_qc_vars : list of str\n",
    "        QAQC variables\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is the notebook friendly version (no logger statements).\n",
    "    \"\"\"\n",
    "    ## Add qc_flag variable for all variables, including elevation;\n",
    "    ## defaulting to nan for fill value that will be replaced with qc flag\n",
    "\n",
    "    for key, val in ds.variables.items():\n",
    "        if val.dtype == object:\n",
    "            if key == \"station\":\n",
    "                if str in [type(v) for v in ds[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "            else:\n",
    "                if str in [type(v) for v in ds.isel(station=0)[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "\n",
    "    exclude_qaqc = [\n",
    "        \"time\",\n",
    "        \"station\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"qaqc_process\",\n",
    "        \"sfcWind_method\",\n",
    "        \"pr_duration\",\n",
    "        \"pr_depth\",\n",
    "        \"PREC_flag\",\n",
    "        \"rsds_duration\",\n",
    "        \"rsds_flag\",\n",
    "        \"anemometer_height_m\",\n",
    "        \"thermometer_height_m\",\n",
    "    ]  # lat, lon have different qc check\n",
    "\n",
    "    raw_qc_vars = []  # qc_variable for each data variable, will vary station to station\n",
    "    era_qc_vars = []  # our ERA qc variable\n",
    "    old_era_qc_vars = []  # our ERA qc variable\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if \"q_code\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variable, need to keep for comparison, then drop\n",
    "        if \"_qc\" in var:\n",
    "            raw_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variables, need to keep for comparison, then drop\n",
    "        if \"_eraqc\" in var:\n",
    "            era_qc_vars.append(\n",
    "                var\n",
    "            )  # raw qc variables, need to keep for comparison, then drop\n",
    "            old_era_qc_vars.append(var)\n",
    "\n",
    "    print(f\"era_qc existing variables:\\n{era_qc_vars}\")\n",
    "    n_qc = len(era_qc_vars)\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if var not in exclude_qaqc and var not in raw_qc_vars and \"_eraqc\" not in var:\n",
    "            qc_var = var + \"_eraqc\"  # variable/column label\n",
    "\n",
    "            # if qaqc var does not exist, adds new variable in shape of original variable with designated nan fill value\n",
    "            if qc_var not in era_qc_vars:\n",
    "                print(f\"nans created for {qc_var}\")\n",
    "                ds = ds.assign({qc_var: xr.ones_like(ds[var]) * np.nan})\n",
    "                era_qc_vars.append(qc_var)\n",
    "\n",
    "    print(\"{} created era_qc variables\".format(len(era_qc_vars) - len(old_era_qc_vars)))\n",
    "    if len(era_qc_vars) != n_qc:\n",
    "        print(\"{}\".format(np.setdiff1d(old_era_qc_vars, era_qc_vars)))\n",
    "\n",
    "    # Save attributes to inheret them to the QAQC'ed file\n",
    "    attrs = ds.attrs\n",
    "    # var_attrs = {var: ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        df = ds.to_dataframe()\n",
    "\n",
    "    # instrumentation heights\n",
    "    if \"anemometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"anemometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.anemometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            print(\"Filling anemometer_height_m with NaN.\", flush=True)\n",
    "            df[\"anemometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "    if \"thermometer_height_m\" not in df.columns:\n",
    "        try:\n",
    "            df[\"thermometer_height_m\"] = (\n",
    "                np.ones(ds[\"time\"].shape) * ds.thermometer_height_m\n",
    "            )\n",
    "        except:\n",
    "            print(\"Filling thermometer_height_m with NaN.\", flush=True)\n",
    "            df[\"thermometer_height_m\"] = np.ones(len(df)) * np.nan\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "\n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df[\"station\"] = station\n",
    "\n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "\n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    # Add time variables needed by multiple functions\n",
    "    df[\"hour\"] = pd.to_datetime(df[\"time\"]).dt.hour\n",
    "    df[\"day\"] = pd.to_datetime(df[\"time\"]).dt.day\n",
    "    df[\"month\"] = pd.to_datetime(df[\"time\"]).dt.month\n",
    "    df[\"year\"] = pd.to_datetime(df[\"time\"]).dt.year\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.date\n",
    "\n",
    "    return df  # , MultiIndex, attrs, var_attrs, era_qc_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load station lists for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in ASOSAWOS stations\n",
    "\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "asosawos = s3_cl.get_object(\n",
    "    Bucket=\"wecc-historical-wx\",\n",
    "    Key=\"2_clean_wx/ASOSAWOS/stationlist_ASOSAWOS_cleaned.csv\",\n",
    ")\n",
    "asosawos_list = pd.read_csv(BytesIO(asosawos[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valleywater = s3_cl.get_object(\n",
    "    Bucket=\"wecc-historical-wx\",\n",
    "    Key=\"2_clean_wx/VALLEYWATER/stationlist_VALLEYWATER_cleaned.csv\",\n",
    ")\n",
    "valleywater_list = pd.read_csv(BytesIO(valleywater[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "maritime = s3_cl.get_object(\n",
    "    Bucket=\"wecc-historical-wx\",\n",
    "    Key=\"2_clean_wx/MARITIME/stationlist_MARITIME_cleaned.csv\",\n",
    ")\n",
    "maritime_list = pd.read_csv(BytesIO(maritime[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Identify candidates for concatenation and upload to AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do so by identifying stations with exactly matching latitudes and longitudes.\n",
    "\n",
    "Some additional methods to use:\n",
    "1. matching IDs, for stations in which those exist (NOT currently used)\n",
    "2. stations within a certain distance of each other (I've investigated this some, but would take consideraly more time to fully develop and may not be necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of networks to be checked for concatenation\n",
    "target_networks = [\"VALLEYWATER\"]  # , \"ASOSAWOS\", \"MARITIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenation_check(station_list):\n",
    "    \"\"\"\n",
    "    This function flags stations that need to be concatenated.\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) Stations are flagged if they have identical latitudes and longitudes\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        station_list: pd.DataFrame\n",
    "            list of station information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            new_station_list: pd.DataFrame\n",
    "                input station list with a flag column assigning an integer to each group of repeat latitudes and longitudes\n",
    "\n",
    "        if failure:\n",
    "            None\n",
    "\n",
    "    \"\"\"\n",
    "    ##### Flag stations with identical latitudes and longitudes, then assign each group a unique integer\n",
    "\n",
    "    # List of possible variable names for longitudes and latitudes\n",
    "    lat_lon_list = [\"LAT\", \"LON\", \"latitude\", \"longitude\", \"LATITUDE\", \"LONGITUDE\", 'lat','lon']\n",
    "    # Extract the latitude and longitude variable names from the input dataframe\n",
    "    lat_lon_cols = [col for col in station_list.columns if col in lat_lon_list]\n",
    "\n",
    "    # Generate column flagging duplicate latitudes and longitudes\n",
    "    station_list[\"concat_subset\"] = station_list.duplicated(\n",
    "        subset=lat_lon_cols, keep=False\n",
    "    )\n",
    "    # within each group of identical latitudes and longitudes, assign a unique integer\n",
    "    station_list[\"concat_subset\"] = (\n",
    "        station_list[station_list[\"concat_subset\"] == True].groupby(lat_lon_cols).ngroup()\n",
    "    )\n",
    "\n",
    "    ##### Order station list by flag\n",
    "    concat_station_list = station_list.sort_values(\"concat_subset\")\n",
    "\n",
    "    ##### Keep only flagged stations\n",
    "    concat_station_list = concat_station_list[~concat_station_list[\"concat_subset\"].isna()]\n",
    "\n",
    "    ##### Format final list\n",
    "    # Convert flags to integers - this is necessary for the final concatenation step\n",
    "    concat_station_list[\"concat_subset\"] = concat_station_list[\"concat_subset\"].astype(\n",
    "        \"int32\"\n",
    "    )\n",
    "    # Now keep only the ERA-ID and flag column\n",
    "    era_id_list = ['ERA-ID','era-id']\n",
    "    era_id_col = [col for col in station_list.columns if col in era_id_list]\n",
    "    concat_station_list = concat_station_list[era_id_col + [\"concat_subset\"]]\n",
    "\n",
    "    # Standardize ERA id to \"ERA-ID\" (this is specific to Valleywater stations)\n",
    "    if 'era-id' in era_id_col:\n",
    "        concat_station_list.rename(columns={\"era-id\": \"ERA-ID\"}, inplace=True)\n",
    "\n",
    "    return concat_station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_concat_check(station_names_list):\n",
    "    \"\"\"\n",
    "    This function applies the conatenation check to a list of target stations. \n",
    "    It then upload a csv containing the ERA IDs and concatenation subset ID for \n",
    "    all identified stations in a network.\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        station__names_list: pd.DataFrame\n",
    "            list of target station names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            uploads list of stations to be concatenated to AWS\n",
    "        if failure:\n",
    "            None\n",
    "\n",
    "    \"\"\"\n",
    "    final_list = pd.DataFrame([])\n",
    "    for station in station_names_list:\n",
    "\n",
    "        ##### Import station list of target station\n",
    "        key = \"2_clean_wx/{}/stationlist_{}_cleaned.csv\".format(station,station)\n",
    "        bucket_name = \"wecc-historical-wx\"\n",
    "        list_import = s3_cl.get_object(\n",
    "            Bucket=bucket,\n",
    "            Key=key,\n",
    "        )\n",
    "        station_list = pd.read_csv(BytesIO(list_import[\"Body\"].read()))\n",
    "\n",
    "        ##### Apply concatenation check\n",
    "        concat_list = concatenation_check(station_list)\n",
    "\n",
    "        ##### Rename the flags for each subset to <station>_<subset number>\n",
    "        concat_list[\"concat_subset\"] = station + '_' + concat_list[\"concat_subset\"].astype(str)\n",
    "\n",
    "        ##### Append to final list of stations to concatenate\n",
    "        final_list = pd.concat([final_list,concat_list])\n",
    "\n",
    "        ##### Upload to QAQC directory in AWS\n",
    "        new_buffer = StringIO()\n",
    "        final_list.to_csv(new_buffer, index = False)\n",
    "        content = new_buffer.getvalue()\n",
    "\n",
    "        s3_cl.put_object(\n",
    "            Bucket = bucket_name,\n",
    "            Body = content,\n",
    "            Key = qaqcdir + station + \"_copy\" \"/\"+ station + \"/\" + station + \"_concat_list_TEST.csv\"\n",
    "            #Key = qaqcdir + station + \"/{}_concat_list_TEST.csv\".format(station)\n",
    "        )\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = apply_concat_check(target_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that stations already indentified for concatenation are flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maritime station:\n",
    "\n",
    "- MTYC1 and MEYC1\n",
    "\n",
    "- SMOC1 and ICAC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERA-ID</th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>OWNER</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>in_terr_wecc</th>\n",
       "      <th>in_mar_wecc</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>...</th>\n",
       "      <th>hurs</th>\n",
       "      <th>hurs_nobs</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>sfcWind_nobs</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind_dir_nobs</th>\n",
       "      <th>rsds</th>\n",
       "      <th>rsds_nobs</th>\n",
       "      <th>total_nobs</th>\n",
       "      <th>concat_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MARITIME_LJAC1</td>\n",
       "      <td>ljac1</td>\n",
       "      <td>O</td>\n",
       "      <td>9410230 - La Jolla, CA</td>\n",
       "      <td>32.867 N 117.257 W (32&amp;#176;52'1\" N 117&amp;#176;1...</td>\n",
       "      <td>32.867</td>\n",
       "      <td>-117.257</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1098253</td>\n",
       "      <td>Y</td>\n",
       "      <td>1099588</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1409901</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MARITIME_LJPC1</td>\n",
       "      <td>ljpc1</td>\n",
       "      <td>R</td>\n",
       "      <td>La Jolla, CA (073)</td>\n",
       "      <td>32.867 N 117.257 W (32&amp;#176;52'0\" N 117&amp;#176;1...</td>\n",
       "      <td>32.867</td>\n",
       "      <td>-117.257</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>105188</td>\n",
       "      <td>Y</td>\n",
       "      <td>104295</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>135209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MARITIME_ICAC1</td>\n",
       "      <td>icac1</td>\n",
       "      <td>O</td>\n",
       "      <td>9410840 - Santa Monica Pier</td>\n",
       "      <td>34.008 N 118.500 W (34&amp;#176;0'28\" N 118&amp;#176;2...</td>\n",
       "      <td>34.008</td>\n",
       "      <td>-118.500</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>997061</td>\n",
       "      <td>Y</td>\n",
       "      <td>996677</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1084742</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>MARITIME_SMOC1</td>\n",
       "      <td>smoc1</td>\n",
       "      <td>O</td>\n",
       "      <td>9410840 - Santa Monica, CA</td>\n",
       "      <td>34.008 N 118.500 W (34&amp;#176;0'30\" N 118&amp;#176;3...</td>\n",
       "      <td>34.008</td>\n",
       "      <td>-118.500</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>52823</td>\n",
       "      <td>Y</td>\n",
       "      <td>53110</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>282368</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MARITIME_MEYC1</td>\n",
       "      <td>meyc1</td>\n",
       "      <td>O</td>\n",
       "      <td>9413450 - Monterey, CA</td>\n",
       "      <td>36.605 N 121.889 W (36&amp;#176;36'18\" N 121&amp;#176;...</td>\n",
       "      <td>36.605</td>\n",
       "      <td>-121.889</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>415573</td>\n",
       "      <td>Y</td>\n",
       "      <td>415191</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>538763</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MARITIME_MTYC1</td>\n",
       "      <td>mtyc1</td>\n",
       "      <td>O</td>\n",
       "      <td>9413450 - Monterey, CA</td>\n",
       "      <td>36.605 N 121.889 W (36&amp;#176;36'18\" N 121&amp;#176;...</td>\n",
       "      <td>36.605</td>\n",
       "      <td>-121.889</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>237168</td>\n",
       "      <td>Y</td>\n",
       "      <td>236901</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>874261</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MARITIME_MYXC1</td>\n",
       "      <td>myxc1</td>\n",
       "      <td>CN</td>\n",
       "      <td>Monterrey, CA</td>\n",
       "      <td>36.605 N 121.889 W (36&amp;#176;36'18\" N 121&amp;#176;...</td>\n",
       "      <td>36.605</td>\n",
       "      <td>-121.889</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ERA-ID STATION_ID OWNER                         NAME  \\\n",
       "18  MARITIME_LJAC1      ljac1     O       9410230 - La Jolla, CA   \n",
       "19  MARITIME_LJPC1      ljpc1     R           La Jolla, CA (073)   \n",
       "17  MARITIME_ICAC1      icac1     O  9410840 - Santa Monica Pier   \n",
       "42  MARITIME_SMOC1      smoc1     O   9410840 - Santa Monica, CA   \n",
       "23  MARITIME_MEYC1      meyc1     O       9413450 - Monterey, CA   \n",
       "24  MARITIME_MTYC1      mtyc1     O       9413450 - Monterey, CA   \n",
       "25  MARITIME_MYXC1      myxc1    CN                Monterrey, CA   \n",
       "\n",
       "                                             LOCATION  LATITUDE  LONGITUDE  \\\n",
       "18  32.867 N 117.257 W (32&#176;52'1\" N 117&#176;1...    32.867   -117.257   \n",
       "19  32.867 N 117.257 W (32&#176;52'0\" N 117&#176;1...    32.867   -117.257   \n",
       "17  34.008 N 118.500 W (34&#176;0'28\" N 118&#176;2...    34.008   -118.500   \n",
       "42  34.008 N 118.500 W (34&#176;0'30\" N 118&#176;3...    34.008   -118.500   \n",
       "23  36.605 N 121.889 W (36&#176;36'18\" N 121&#176;...    36.605   -121.889   \n",
       "24  36.605 N 121.889 W (36&#176;36'18\" N 121&#176;...    36.605   -121.889   \n",
       "25  36.605 N 121.889 W (36&#176;36'18\" N 121&#176;...    36.605   -121.889   \n",
       "\n",
       "   in_terr_wecc in_mar_wecc   NETWORK  ... hurs hurs_nobs sfcWind  \\\n",
       "18            Y         NaN  MARITIME  ...    N         0       Y   \n",
       "19            Y         NaN  MARITIME  ...    N         0       Y   \n",
       "17            Y         NaN  MARITIME  ...    N         0       Y   \n",
       "42            Y         NaN  MARITIME  ...    N         0       Y   \n",
       "23            Y         NaN  MARITIME  ...    N         0       Y   \n",
       "24            Y         NaN  MARITIME  ...    N         0       Y   \n",
       "25            Y         NaN  MARITIME  ...    N         0       N   \n",
       "\n",
       "   sfcWind_nobs sfcWind_dir  sfcWind_dir_nobs rsds  rsds_nobs total_nobs  \\\n",
       "18      1098253           Y           1099588    N          0    1409901   \n",
       "19       105188           Y            104295    N          0     135209   \n",
       "17       997061           Y            996677    N          0    1084742   \n",
       "42        52823           Y             53110    N          0     282368   \n",
       "23       415573           Y            415191    N          0     538763   \n",
       "24       237168           Y            236901    N          0     874261   \n",
       "25            0           N                 0    N          0          0   \n",
       "\n",
       "    concat_flag  \n",
       "18          0.0  \n",
       "19          0.0  \n",
       "17          1.0  \n",
       "42          1.0  \n",
       "23          2.0  \n",
       "24          2.0  \n",
       "25          2.0  \n",
       "\n",
       "[7 rows x 50 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maritime_out\n",
    "\n",
    "# Flagged Stations:\n",
    "# MARITIME_LJAC1 <=> MARITIME_LJPC1\n",
    "# MARITIME_ICAC1 <=> MARITIME_SMOC1\n",
    "# MARITIME_MEYC1 <=> MARITIME_MTYC1 <=> MARITIME_MYXC1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previously identified stations are indeed flagged. Along with an additional pair: MARITIME_LJAC1 and MARITIME_LJPC1. And a third station included with MARITIME_MEYC1 abd MARITIME_MTYC1: MARITIME_MYXC1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using ICAO values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "ERA-ID              6\n",
      "USAF                6\n",
      "WBAN                6\n",
      "STATION NAME        6\n",
      "CTRY                6\n",
      "                   ..\n",
      "sfcWind_dir         6\n",
      "sfcWind_dir_nobs    6\n",
      "rsds                6\n",
      "rsds_nobs           6\n",
      "total_nobs          6\n",
      "Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "repeat_list = asosawos_list[asosawos_list.duplicated(subset=[\"ICAO\"], keep=False)]\n",
    "\n",
    "# how many unique ICAO duplicates are there?\n",
    "print(len(repeat_list[\"ICAO\"].unique()))\n",
    "\n",
    "print(repeat_list.groupby(\"ICAO\").count().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(repeat_list[\"ICAO\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate problem station KMLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmlf = repeat_list[repeat_list[\"ICAO\"] == \"KMLF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>MILFORD MUNICIPAL AP</td>\n",
       "      <td>38.417</td>\n",
       "      <td>-113.017</td>\n",
       "      <td>1948-07-23</td>\n",
       "      <td>1996-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>MILFORD MUNICIPAL AP</td>\n",
       "      <td>38.417</td>\n",
       "      <td>-113.017</td>\n",
       "      <td>1977-01-01</td>\n",
       "      <td>1983-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>MILFORD MUNICIPAL AP</td>\n",
       "      <td>38.417</td>\n",
       "      <td>-113.017</td>\n",
       "      <td>1983-05-01</td>\n",
       "      <td>1985-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>MILFORD MUNICIPAL AP</td>\n",
       "      <td>38.417</td>\n",
       "      <td>-113.017</td>\n",
       "      <td>1985-06-01</td>\n",
       "      <td>1989-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>MILFORD MUNI BRISCOE</td>\n",
       "      <td>38.417</td>\n",
       "      <td>-113.017</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>MILFORD MUNICIPAL AIRPORT</td>\n",
       "      <td>38.423</td>\n",
       "      <td>-113.011</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  STATION NAME     LAT      LON  start_time    end_time\n",
       "61        MILFORD MUNICIPAL AP  38.417 -113.017  1948-07-23  1996-12-31\n",
       "154       MILFORD MUNICIPAL AP  38.417 -113.017  1977-01-01  1983-04-30\n",
       "166       MILFORD MUNICIPAL AP  38.417 -113.017  1983-05-01  1985-05-31\n",
       "170       MILFORD MUNICIPAL AP  38.417 -113.017  1985-06-01  1989-05-01\n",
       "185       MILFORD MUNI BRISCOE  38.417 -113.017  1997-01-01  2022-12-31\n",
       "226  MILFORD MUNICIPAL AIRPORT  38.423 -113.011  2005-01-01  2022-12-31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmlf[[\"STATION NAME\", \"LAT\", \"LON\", \"start_time\", \"end_time\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using station locations (lat, lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataframe\n",
    "\n",
    "test = asosawos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_list = [\"LAT\", \"LON\", \"latitude\", \"longitude\", \"LATITUDE\", \"LONGITUDE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_cols = [col for col in test.columns if col in lat_lon_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAT', 'LON']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_lon_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"concat_flag\"] = asosawos_list.duplicated(subset=lat_lon_cols, keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"concat_flag\"] = test[test[\"concat_flag\"] == True].groupby(lat_lon_cols).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_var_list = [\"end_time\", \"end-date\"]\n",
    "end_time_col = [col for col in test.columns if col in time_var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end_time']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(\"concat_flag\")\n",
    "test = (\n",
    "    test.groupby([\"concat_flag\"])\n",
    "    .apply(lambda x: x.sort_values(end_time_col))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing ICAO identification and lat lon identification for ASOSAWOS stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Carry Out Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the order of operations:\n",
    "\n",
    "1. Read in target stations, for each concat_flag\n",
    "2. Check if there is overlap in time ranges\n",
    "    1. IF so:  \n",
    "\n",
    "        split overall time range\n",
    "\n",
    "        construct dataset by grabbing newest station for each time range subset\n",
    "\n",
    "    \n",
    "    2. ELSE:\n",
    "\n",
    "        concatenate, with NAs in the gap\n",
    "\n",
    "\n",
    "Another option: pairwise concetenation\n",
    "\n",
    "For each subset of matching stations, first concatenate the two newest stations. Then, the next oldest, etc.\n",
    "\n",
    "\n",
    "Issues to address:\n",
    "\n",
    "1. when the time range of one station completely includes that of another in a subset (this occures a few times with ASOSAWOS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate pairs of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'VALLEYWATER'\n",
    "network_list = s3_cl.get_object(\n",
    "    Bucket=bucket,\n",
    "    # Key=\"3_qaqc_wx/{}/concat_list_{}.csv\".format(network_name,network_name)\n",
    "    Key=\"3_qaqc_wx/{}_copy/{}/{}_concat_list_TEST.csv\".format(network_name, network_name, network_name),\n",
    ")\n",
    "concat_list = pd.read_csv(BytesIO(network_list[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERA-ID</th>\n",
       "      <th>concat_subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VALLEYWATER_6053</td>\n",
       "      <td>VALLEYWATER_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VALLEYWATER_6144</td>\n",
       "      <td>VALLEYWATER_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ERA-ID  concat_subset\n",
       "0  VALLEYWATER_6053  VALLEYWATER_0\n",
       "1  VALLEYWATER_6144  VALLEYWATER_0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_1 = concat_list['ERA-ID'].iloc[0]\n",
    "station_2 = concat_list[\"ERA-ID\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era_qc existing variables:\n",
      "[]\n",
      "nans created for ps_eraqc\n",
      "nans created for tas_eraqc\n",
      "nans created for tdps_eraqc\n",
      "nans created for pr_eraqc\n",
      "nans created for sfcWind_eraqc\n",
      "nans created for sfcWind_dir_eraqc\n",
      "nans created for elevation_eraqc\n",
      "nans created for ps_altimeter_eraqc\n",
      "8 created era_qc variables\n",
      "[]\n",
      "era_qc existing variables:\n",
      "[]\n",
      "nans created for tas_eraqc\n",
      "nans created for sfcWind_eraqc\n",
      "nans created for sfcWind_dir_eraqc\n",
      "nans created for elevation_eraqc\n",
      "4 created era_qc variables\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# # load in single dc file from AWS\n",
    "ds_a = read_nc_from_s3_clean(\"ASOSAWOS\", \"ASOSAWOS_72053700163\", temp_dir)\n",
    "ds_m = read_nc_from_s3_clean(\"MARITIME\", \"MARITIME_CPMW1\", temp_dir)\n",
    "\n",
    "\n",
    "# convert to formatted pandas dataframe\n",
    "df_a = qaqc_ds_to_df(ds_a, verbose=False)\n",
    "df_m = qaqc_ds_to_df(ds_m, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import this subset of datasets and convert to dataframe\n",
    "url_1 = \"s3://wecc-historical-wx/3_qaqc_wx/{}_copy/{}/{}.zarr\".format(\n",
    "    network_name, network_name, station_1\n",
    ")\n",
    "url_2 = \"s3://wecc-historical-wx/3_qaqc_wx/{}_copy/{}/{}.zarr\".format(\n",
    "    network_name,network_name, station_2\n",
    ")\n",
    "\n",
    "# TODO: open_zarr will be used for QAQC'd datasets\n",
    "ds_1 = xr.open_zarr(url_1)\n",
    "ds_2 = xr.open_zarr(url_2)\n",
    "\n",
    "df_1 = ds_1.to_dataframe()\n",
    "df_2 = ds_2.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import this subset of datasets and convert to dataframe\n",
    "url_1 = \"s3://wecc-historical-wx/3_qaqc_wx/{}_copy/{}/{}.zarr\".format(\n",
    "    network_name, network_name, station_1\n",
    ")\n",
    "url_2 = \"s3://wecc-historical-wx/3_qaqc_wx/{}_copy/{}/{}.zarr\".format(\n",
    "    network_name, network_name, station_2\n",
    ")\n",
    "\n",
    "# TODO: open_zarr will be used for QAQC'd datasets\n",
    "ds_1 = xr.open_zarr(url_1)\n",
    "ds_2 = xr.open_zarr(url_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = ds_1.to_dataframe()\n",
    "df_2 = ds_2.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.reset_index()\n",
    "df_2 = df_2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which dataset is older\n",
    "if df_1[\"time\"].max() < df_2[\"time\"].max(): \n",
    "    # if df_1 has an earlier end tiem than df_2, then d_2 is newer\n",
    "    # we also grab the name of the newer station in this step, for use later\n",
    "    df_new = df_2\n",
    "    ds_new = ds_2\n",
    "\n",
    "    df_old = df_1\n",
    "    ds_old = ds_1\n",
    "else:\n",
    "    df_new = df_1\n",
    "    ds_new = ds_1\n",
    "\n",
    "    df_old = df_2\n",
    "    ds_old = ds_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is overlap between the two time series\n",
    "if len(df_overlap) == 0:\n",
    "    ##### Split datframes into subsets #####\n",
    "\n",
    "    # Remove data in time overlap between old and new\n",
    "    df_old_cleaned = df_old[~df_old[\"time\"].isin(df_new[\"time\"])]\n",
    "    df_new_cleaned = df_new[~df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    ##### Concatenate subsets #####\n",
    "    df_concat = concat([df_old_cleaned, df_overlap, df_new_cleaned])\n",
    "# if not, concatenate\n",
    "else: \n",
    "    df_concat = concat([df_new, df_overlap, df_old])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now prepare the final concatenated dataframe for export\n",
    "\n",
    "# Modify index for df_old_cleaned\n",
    "# We want the final dataset to show up as the new station, not the old\n",
    "station_name_new = ds_new.coords[\"station\"].values[0]\n",
    "final_station_name = \"{}_{}\".format(network_name, station_name_new)\n",
    "new_index = [final_station_name] * len(df_concat)\n",
    "\n",
    "df_concat[\"station\"] = new_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>anemometer_height_m</th>\n",
       "      <th>elevation</th>\n",
       "      <th>elevation_eraqc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pr_15min</th>\n",
       "      <th>pr_15min_eraqc</th>\n",
       "      <th>raw_qc</th>\n",
       "      <th>thermometer_height_m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">VALLEYWATER_VALLEYWATER_6144</th>\n",
       "      <th>2013-08-04 07:15:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2013-08-04 07:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-04 07:30:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2013-08-04 07:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-04 07:45:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2013-08-04 07:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-04 08:00:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2013-08-04 08:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-04 08:15:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2013-08-04 08:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-25 01:15:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2017-07-25 01:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-25 01:30:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2017-07-25 01:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-25 01:45:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2017-07-25 01:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-25 02:00:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2017-07-25 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-25 02:15:00</th>\n",
       "      <td>VALLEYWATER_VALLEYWATER_6144</td>\n",
       "      <td>2017-07-25 02:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.3322</td>\n",
       "      <td>-122.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051327 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       station  \\\n",
       "station                      time                                                \n",
       "VALLEYWATER_VALLEYWATER_6144 2013-08-04 07:15:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2013-08-04 07:30:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2013-08-04 07:45:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2013-08-04 08:00:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2013-08-04 08:15:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "...                                                                        ...   \n",
       "                             2017-07-25 01:15:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2017-07-25 01:30:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2017-07-25 01:45:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2017-07-25 02:00:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "                             2017-07-25 02:15:00  VALLEYWATER_VALLEYWATER_6144   \n",
       "\n",
       "                                                                time  \\\n",
       "station                      time                                      \n",
       "VALLEYWATER_VALLEYWATER_6144 2013-08-04 07:15:00 2013-08-04 07:15:00   \n",
       "                             2013-08-04 07:30:00 2013-08-04 07:30:00   \n",
       "                             2013-08-04 07:45:00 2013-08-04 07:45:00   \n",
       "                             2013-08-04 08:00:00 2013-08-04 08:00:00   \n",
       "                             2013-08-04 08:15:00 2013-08-04 08:15:00   \n",
       "...                                                              ...   \n",
       "                             2017-07-25 01:15:00 2017-07-25 01:15:00   \n",
       "                             2017-07-25 01:30:00 2017-07-25 01:30:00   \n",
       "                             2017-07-25 01:45:00 2017-07-25 01:45:00   \n",
       "                             2017-07-25 02:00:00 2017-07-25 02:00:00   \n",
       "                             2017-07-25 02:15:00 2017-07-25 02:15:00   \n",
       "\n",
       "                                                  anemometer_height_m  \\\n",
       "station                      time                                       \n",
       "VALLEYWATER_VALLEYWATER_6144 2013-08-04 07:15:00                  NaN   \n",
       "                             2013-08-04 07:30:00                  NaN   \n",
       "                             2013-08-04 07:45:00                  NaN   \n",
       "                             2013-08-04 08:00:00                  NaN   \n",
       "                             2013-08-04 08:15:00                  NaN   \n",
       "...                                                               ...   \n",
       "                             2017-07-25 01:15:00                  NaN   \n",
       "                             2017-07-25 01:30:00                  NaN   \n",
       "                             2017-07-25 01:45:00                  NaN   \n",
       "                             2017-07-25 02:00:00                  NaN   \n",
       "                             2017-07-25 02:15:00                  NaN   \n",
       "\n",
       "                                                  elevation  elevation_eraqc  \\\n",
       "station                      time                                              \n",
       "VALLEYWATER_VALLEYWATER_6144 2013-08-04 07:15:00     130.35              3.0   \n",
       "                             2013-08-04 07:30:00     130.35              3.0   \n",
       "                             2013-08-04 07:45:00     130.35              3.0   \n",
       "                             2013-08-04 08:00:00     130.35              3.0   \n",
       "                             2013-08-04 08:15:00     130.35              3.0   \n",
       "...                                                     ...              ...   \n",
       "                             2017-07-25 01:15:00     130.35              3.0   \n",
       "                             2017-07-25 01:30:00     130.35              3.0   \n",
       "                             2017-07-25 01:45:00     130.35              3.0   \n",
       "                             2017-07-25 02:00:00     130.35              3.0   \n",
       "                             2017-07-25 02:15:00     130.35              3.0   \n",
       "\n",
       "                                                      lat      lon  pr_15min  \\\n",
       "station                      time                                              \n",
       "VALLEYWATER_VALLEYWATER_6144 2013-08-04 07:15:00  37.3322 -122.081       0.0   \n",
       "                             2013-08-04 07:30:00  37.3322 -122.081       0.0   \n",
       "                             2013-08-04 07:45:00  37.3322 -122.081       0.0   \n",
       "                             2013-08-04 08:00:00  37.3322 -122.081       0.0   \n",
       "                             2013-08-04 08:15:00  37.3322 -122.081       0.0   \n",
       "...                                                   ...      ...       ...   \n",
       "                             2017-07-25 01:15:00  37.3322 -122.081       0.0   \n",
       "                             2017-07-25 01:30:00  37.3322 -122.081       0.0   \n",
       "                             2017-07-25 01:45:00  37.3322 -122.081       0.0   \n",
       "                             2017-07-25 02:00:00  37.3322 -122.081       0.0   \n",
       "                             2017-07-25 02:15:00  37.3322 -122.081       0.0   \n",
       "\n",
       "                                                  pr_15min_eraqc    raw_qc  \\\n",
       "station                      time                                            \n",
       "VALLEYWATER_VALLEYWATER_6144 2013-08-04 07:15:00             NaN  Approved   \n",
       "                             2013-08-04 07:30:00             NaN  Approved   \n",
       "                             2013-08-04 07:45:00             NaN  Approved   \n",
       "                             2013-08-04 08:00:00             NaN  Approved   \n",
       "                             2013-08-04 08:15:00             NaN  Approved   \n",
       "...                                                          ...       ...   \n",
       "                             2017-07-25 01:15:00             NaN  Approved   \n",
       "                             2017-07-25 01:30:00             NaN  Approved   \n",
       "                             2017-07-25 01:45:00             NaN  Approved   \n",
       "                             2017-07-25 02:00:00             NaN  Approved   \n",
       "                             2017-07-25 02:15:00             NaN  Approved   \n",
       "\n",
       "                                                  thermometer_height_m  \n",
       "station                      time                                       \n",
       "VALLEYWATER_VALLEYWATER_6144 2013-08-04 07:15:00                   NaN  \n",
       "                             2013-08-04 07:30:00                   NaN  \n",
       "                             2013-08-04 07:45:00                   NaN  \n",
       "                             2013-08-04 08:00:00                   NaN  \n",
       "                             2013-08-04 08:15:00                   NaN  \n",
       "...                                                                ...  \n",
       "                             2017-07-25 01:15:00                   NaN  \n",
       "                             2017-07-25 01:30:00                   NaN  \n",
       "                             2017-07-25 01:45:00                   NaN  \n",
       "                             2017-07-25 02:00:00                   NaN  \n",
       "                             2017-07-25 02:15:00                   NaN  \n",
       "\n",
       "[2051327 rows x 11 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert a DataFrame with a non-unique MultiIndex into xarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[189], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert concatenated dataframe to dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ds_test \u001b[38;5;241m=\u001b[39m \u001b[43mdf_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_xarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/pandas/core/generic.py:3226\u001b[0m, in \u001b[0;36mNDFrame.to_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xarray\u001b[38;5;241m.\u001b[39mDataArray\u001b[38;5;241m.\u001b[39mfrom_series(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   3225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/xarray/core/dataset.py:5510\u001b[0m, in \u001b[0;36mDataset.from_dataframe\u001b[0;34m(cls, dataframe, sparse)\u001b[0m\n\u001b[1;32m   5507\u001b[0m idx \u001b[38;5;241m=\u001b[39m remove_unused_levels_categories(dataframe\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, pd\u001b[38;5;241m.\u001b[39mMultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m-> 5510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert a DataFrame with a non-unique MultiIndex into xarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5512\u001b[0m     )\n\u001b[1;32m   5514\u001b[0m \u001b[38;5;66;03m# Cast to a NumPy array first, in case the Series is a pandas Extension\u001b[39;00m\n\u001b[1;32m   5515\u001b[0m \u001b[38;5;66;03m# array (which doesn't have a valid NumPy dtype)\u001b[39;00m\n\u001b[1;32m   5516\u001b[0m \u001b[38;5;66;03m# TODO: allow users to control how this casting happens, e.g., by\u001b[39;00m\n\u001b[1;32m   5517\u001b[0m \u001b[38;5;66;03m# forwarding arguments to pandas.Series.to_numpy?\u001b[39;00m\n\u001b[1;32m   5518\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [(k, np\u001b[38;5;241m.\u001b[39masarray(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39mitems()]\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert a DataFrame with a non-unique MultiIndex into xarray"
     ]
    }
   ],
   "source": [
    "# Convert concatenated dataframe to dataset\n",
    "ds_test = df_test.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Update attributes and datatypes #####\n",
    "\n",
    "# Include past attributes\n",
    "ds_concat.attrs = ds_new.attrs\n",
    "\n",
    "# Update 'history' attribute\n",
    "timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "ds_concat.attrs[\"history\"] = ds_new.attrs[\n",
    "    \"history\"\n",
    "] + \" \\n maritime_merge.ipynb run on {} UTC\".format(timestamp)\n",
    "\n",
    "# Update 'comment' attribute\n",
    "ds_concat.attrs[\"comment\"] = (\n",
    "    \"Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new qaqc_files_merged attribute\n",
    "station_name_old = ds_old.coords[\"station\"].values[0]\n",
    "ds_concat.attrs[\"qaqc_files_merged\"] = (\n",
    "    \"{}_{}, {}_{} merged. Overlap retained from newer station data.\".format(\n",
    "        network_name, station_name_old, network_name, station_name_new\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of variables to be assigned\n",
    "\n",
    "float32_variables = [\n",
    "    \"anemometer_height_m\",\n",
    "    \"elevation\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"pr_15min\",\n",
    "    \"pr_15min_eraqc\",\n",
    "    \"thermometer_height_m\",\n",
    "    \"ps\",\n",
    "    \"tas\",\n",
    "    \"tdps\",\n",
    "    \"pr\",\n",
    "    \"sfcWind\",\n",
    "    \"sfcWind_dir\",\n",
    "    \"ps_altimeter\",\n",
    "    \"pr_duration\",\n",
    "]\n",
    "U16_variables = [\n",
    "    \"elevation_eraqc\",\n",
    "    \"pr_15min_eraqc\",\n",
    "    \"raw_qc\",\n",
    "    \"qaqc_process\",\n",
    "    \"ps_qc\",\n",
    "    \"ps_altimeter_qc\",\n",
    "    \"ps_eraqc\",\n",
    "    \"tas_eraqc\",\n",
    "    \"tdps_eraqc\",\n",
    "    \"pr_eraqc\",\n",
    "    \"sfcWind_eraqc\",\n",
    "    \"sfcWind_dir_eraqc\",\n",
    "    \"elevation_eraqc\",\n",
    "    \"ps_altimeter_eraqc\",\n",
    "    \"psl_qc\",\n",
    "    \"tas_qc\",\n",
    "    \"tdps_qc\",\n",
    "    \"pr_qc\",\n",
    "    \"pr_depth_qc\",\n",
    "    \"sfcWind_qc\",\n",
    "    \"sfcWind_method\",\n",
    "    \"sfcWind_dir_qc\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all datatypes, to enable export\n",
    "existing_float32 = [col for col in float32_variables if col in df_concat.columns]\n",
    "existing_U16 = [col for col in U16_variables if col in df_concat.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:               (station: 1, time: 1511017)\n",
       "Coordinates:\n",
       "  * station               (station) object &#x27;VALLEYWATER_6053&#x27;\n",
       "  * time                  (time) datetime64[ns] 1974-06-21T08:15:00 ... 2017-...\n",
       "Data variables:\n",
       "    anemometer_height_m   (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    elevation             (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    elevation_eraqc       (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    lat                   (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    lon                   (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    pr_15min              (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    pr_15min_eraqc        (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    raw_qc                (station, time) object dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "    thermometer_height_m  (station, time) float64 dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Networks:          VALLEYWATER\n",
       "    comment:           Intermediate data product: may not have been subject t...\n",
       "    disclaimer:        This document was prepared as a result of work funded ...\n",
       "    history:           VALLEYWATER_clean.py script run on 01-28-2025, 01:32:0...\n",
       "    institution:       Eagle Rock Analytics\n",
       "    license:           \n",
       "    raw_files_merged:  1\n",
       "    sensor_height_m:   nan\n",
       "    source:            \n",
       "    station_name:      Maryknoll Fields\n",
       "    title:             VALLEYWATER quality controlled\n",
       "    watershed:         Lower Peninsula</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-65dc6f5b-8e2e-438e-8921-25f8e6609d3f' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-65dc6f5b-8e2e-438e-8921-25f8e6609d3f' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>station</span>: 1</li><li><span class='xr-has-index'>time</span>: 1511017</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-466ab71d-0a40-4f76-b9d8-e835152839c0' class='xr-section-summary-in' type='checkbox'  checked><label for='section-466ab71d-0a40-4f76-b9d8-e835152839c0' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>station</span></div><div class='xr-var-dims'>(station)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;VALLEYWATER_6053&#x27;</div><input id='attrs-0808160c-7714-4188-8793-8b8c59936d69' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0808160c-7714-4188-8793-8b8c59936d69' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e5c81516-c61e-49e9-8eb5-1e378a5e2bf1' class='xr-var-data-in' type='checkbox'><label for='data-e5c81516-c61e-49e9-8eb5-1e378a5e2bf1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;VALLEYWATER_6053&#x27;], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1974-06-21T08:15:00 ... 2017-07-...</div><input id='attrs-d35fd2f9-d38e-4b32-b1ad-80ed7c02b9d9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d35fd2f9-d38e-4b32-b1ad-80ed7c02b9d9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-df412223-442b-4936-afc7-28b6123b7c65' class='xr-var-data-in' type='checkbox'><label for='data-df412223-442b-4936-afc7-28b6123b7c65' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;1974-06-21T08:15:00.000000000&#x27;, &#x27;1974-06-21T08:30:00.000000000&#x27;,\n",
       "       &#x27;1974-06-21T08:45:00.000000000&#x27;, ..., &#x27;2017-07-25T01:45:00.000000000&#x27;,\n",
       "       &#x27;2017-07-25T02:00:00.000000000&#x27;, &#x27;2017-07-25T02:15:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-51ff4ea8-b1f0-43e2-9893-afb7ac051265' class='xr-section-summary-in' type='checkbox'  checked><label for='section-51ff4ea8-b1f0-43e2-9893-afb7ac051265' class='xr-section-summary' >Data variables: <span>(9)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>anemometer_height_m</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-80e55967-ee98-4f79-9896-a5b6eefa0213' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-80e55967-ee98-4f79-9896-a5b6eefa0213' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e34eca6d-38cb-450d-a65b-b266c485382b' class='xr-var-data-in' type='checkbox'><label for='data-e34eca6d-38cb-450d-a65b-b266c485382b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-ecae78d9-63bb-4221-88d9-2d429e212570' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ecae78d9-63bb-4221-88d9-2d429e212570' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-580ae5f2-526e-4af7-b652-90ac65dbf8d4' class='xr-var-data-in' type='checkbox'><label for='data-580ae5f2-526e-4af7-b652-90ac65dbf8d4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-76341f78-2b35-4bab-be75-0588a6a2d2e2' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-76341f78-2b35-4bab-be75-0588a6a2d2e2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bff05137-2b27-48cf-a8e2-65c54f2bdc30' class='xr-var-data-in' type='checkbox'><label for='data-bff05137-2b27-48cf-a8e2-65c54f2bdc30' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-f2277363-c961-43fc-9b05-6d03e13d64ed' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f2277363-c961-43fc-9b05-6d03e13d64ed' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a6460e70-3ad7-4f14-a4d2-42e2c60b1bd0' class='xr-var-data-in' type='checkbox'><label for='data-a6460e70-3ad7-4f14-a4d2-42e2c60b1bd0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-2ec97f3e-cd95-45b6-a48b-e1129baecf4c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2ec97f3e-cd95-45b6-a48b-e1129baecf4c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7d216f04-eb40-4e41-a3b7-55049ce90774' class='xr-var-data-in' type='checkbox'><label for='data-7d216f04-eb40-4e41-a3b7-55049ce90774' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pr_15min</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-544c6a35-9279-43a4-bf2c-cced6cc987df' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-544c6a35-9279-43a4-bf2c-cced6cc987df' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f9a403ca-48ca-480d-95eb-d1265d874e75' class='xr-var-data-in' type='checkbox'><label for='data-f9a403ca-48ca-480d-95eb-d1265d874e75' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pr_15min_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-c34b762b-505b-46b8-8f92-a4580bb457d8' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c34b762b-505b-46b8-8f92-a4580bb457d8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c2b75c6a-e940-4295-911b-326cceefc2a8' class='xr-var-data-in' type='checkbox'><label for='data-c2b75c6a-e940-4295-911b-326cceefc2a8' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>raw_qc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-06df2176-2545-438a-90d1-951d00e572d4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-06df2176-2545-438a-90d1-951d00e572d4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-331f7dee-3b5b-413c-8101-178f80d92765' class='xr-var-data-in' type='checkbox'><label for='data-331f7dee-3b5b-413c-8101-178f80d92765' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> object </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>thermometer_height_m</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 94439), meta=np.ndarray&gt;</div><input id='attrs-afa94408-260e-4622-a8b6-ced76f75aae8' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-afa94408-260e-4622-a8b6-ced76f75aae8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-31d99794-6a1b-4266-9b27-6562ae661fa2' class='xr-var-data-in' type='checkbox'><label for='data-31d99794-6a1b-4266-9b27-6562ae661fa2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.53 MiB </td>\n",
       "                        <td> 737.80 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1511017) </td>\n",
       "                        <td> (1, 94439) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2 Graph Layers </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1511017</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-aa43762a-cd1c-4430-91ac-772641074103' class='xr-section-summary-in' type='checkbox'  ><label for='section-aa43762a-cd1c-4430-91ac-772641074103' class='xr-section-summary' >Attributes: <span>(12)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Networks :</span></dt><dd>VALLEYWATER</dd><dt><span>comment :</span></dt><dd>Intermediate data product: may not have been subject to any cleaning or QA/QC processing \n",
       "An intermediate data product: subject to cleaning but may not be subject to full QA/QC processing.</dd><dt><span>disclaimer :</span></dt><dd>This document was prepared as a result of work funded by the Santa Clara Valley Water District. It does not necessarily represent the views of the Santa Clara Valley Water District or its employees. Neither the Santa Clara Valley Water District, nor it&#x27;s employees, contractors, or subcontractors makes any warranty, express or implied, or assumes any legal liability for the information in this document; nor does any party represent that the use of this information will not infringe upon privately owned rights. This document has not been approved or disapproved by Santa Clara Valley Water District, nor has the Santa Clara Valley Water District passed upon the accuracy of the information in this document.</dd><dt><span>history :</span></dt><dd>VALLEYWATER_clean.py script run on 01-28-2025, 01:32:09 UTC \n",
       "ALLNETWORKS_qaqc.py script run on 03-21-2025, 17:07:47 UTC \n",
       "VALLEYWATER_qaqc_custom.ipynb run on 04-02-2025, 16:39:21 UTC</dd><dt><span>institution :</span></dt><dd>Eagle Rock Analytics</dd><dt><span>license :</span></dt><dd></dd><dt><span>raw_files_merged :</span></dt><dd>1</dd><dt><span>sensor_height_m :</span></dt><dd>nan</dd><dt><span>source :</span></dt><dd></dd><dt><span>station_name :</span></dt><dd>Maryknoll Fields</dd><dt><span>title :</span></dt><dd>VALLEYWATER quality controlled</dd><dt><span>watershed :</span></dt><dd>Lower Peninsula</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:               (station: 1, time: 1511017)\n",
       "Coordinates:\n",
       "  * station               (station) object 'VALLEYWATER_6053'\n",
       "  * time                  (time) datetime64[ns] 1974-06-21T08:15:00 ... 2017-...\n",
       "Data variables:\n",
       "    anemometer_height_m   (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    elevation             (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    elevation_eraqc       (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    lat                   (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    lon                   (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    pr_15min              (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    pr_15min_eraqc        (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    raw_qc                (station, time) object dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "    thermometer_height_m  (station, time) float64 dask.array<chunksize=(1, 94439), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Networks:          VALLEYWATER\n",
       "    comment:           Intermediate data product: may not have been subject t...\n",
       "    disclaimer:        This document was prepared as a result of work funded ...\n",
       "    history:           VALLEYWATER_clean.py script run on 01-28-2025, 01:32:0...\n",
       "    institution:       Eagle Rock Analytics\n",
       "    license:           \n",
       "    raw_files_merged:  1\n",
       "    sensor_height_m:   nan\n",
       "    source:            \n",
       "    station_name:      Maryknoll Fields\n",
       "    title:             VALLEYWATER quality controlled\n",
       "    watershed:         Lower Peninsula"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:               (index: 2051327)\n",
       "Coordinates:\n",
       "  * index                 (index) int64 0 1 2 3 ... 1511014 1511015 1511016\n",
       "Data variables:\n",
       "    anemometer_height_m   (index) float32 nan nan nan nan ... nan nan nan nan\n",
       "    elevation             (index) float32 130.4 130.4 130.4 ... 130.4 130.4\n",
       "    lat                   (index) float32 37.33 37.33 37.33 ... 37.33 37.33\n",
       "    lon                   (index) float32 -122.1 -122.1 -122.1 ... -122.1 -122.1\n",
       "    pr_15min              (index) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    pr_15min_eraqc        (index) float32 nan nan nan nan ... nan nan nan nan\n",
       "    thermometer_height_m  (index) float32 nan nan nan nan ... nan nan nan nan\n",
       "Attributes: (12/13)\n",
       "    Networks:           VALLEYWATER\n",
       "    comment:            Final v1 data product. This data has been subjected t...\n",
       "    disclaimer:         This document was prepared as a result of work funded...\n",
       "    history:            VALLEYWATER_clean.py script run on 01-28-2025, 01:32:...\n",
       "    institution:        Eagle Rock Analytics\n",
       "    license:            \n",
       "    ...                 ...\n",
       "    sensor_height_m:    nan\n",
       "    source:             \n",
       "    station_name:       Maryknoll Fields\n",
       "    title:              VALLEYWATER quality controlled\n",
       "    watershed:          Lower Peninsula\n",
       "    qaqc_files_merged:  VALLEYWATER_VALLEYWATER_6053, VALLEYWATER_VALLEYWATER...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-2d62af02-8bb2-413a-a628-38f5e77b5ab4' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-2d62af02-8bb2-413a-a628-38f5e77b5ab4' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>index</span>: 2051327</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-d4357b87-a3da-4d02-827b-3c650e252584' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d4357b87-a3da-4d02-827b-3c650e252584' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>index</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 ... 1511014 1511015 1511016</div><input id='attrs-c8a264a8-1fee-4800-a268-4bf9bb631f10' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c8a264a8-1fee-4800-a268-4bf9bb631f10' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c464cf9a-c6e6-463b-ac57-0103dfb7648f' class='xr-var-data-in' type='checkbox'><label for='data-c464cf9a-c6e6-463b-ac57-0103dfb7648f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([      0,       1,       2, ..., 1511014, 1511015, 1511016])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b6bb15da-6a3d-4582-ad52-9e2afecbee66' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b6bb15da-6a3d-4582-ad52-9e2afecbee66' class='xr-section-summary' >Data variables: <span>(7)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>anemometer_height_m</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-789946c0-6b1e-4123-8fa3-300a73866b6d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-789946c0-6b1e-4123-8fa3-300a73866b6d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fb132220-e457-4526-abe8-b0215cb901ec' class='xr-var-data-in' type='checkbox'><label for='data-fb132220-e457-4526-abe8-b0215cb901ec' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>130.4 130.4 130.4 ... 130.4 130.4</div><input id='attrs-6739328d-d12e-4efd-9078-8fa1e9820389' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6739328d-d12e-4efd-9078-8fa1e9820389' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-440b4db6-22c6-47d5-a8bf-66f8c66a88b1' class='xr-var-data-in' type='checkbox'><label for='data-440b4db6-22c6-47d5-a8bf-66f8c66a88b1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([130.35, 130.35, 130.35, ..., 130.35, 130.35, 130.35], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>37.33 37.33 37.33 ... 37.33 37.33</div><input id='attrs-7eb861d7-5023-4ee7-af7f-248a470ad781' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7eb861d7-5023-4ee7-af7f-248a470ad781' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-995c1623-fdde-44ec-9551-34e7fd18f92f' class='xr-var-data-in' type='checkbox'><label for='data-995c1623-fdde-44ec-9551-34e7fd18f92f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([37.3322, 37.3322, 37.3322, ..., 37.3322, 37.3322, 37.3322],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-122.1 -122.1 ... -122.1 -122.1</div><input id='attrs-b956186a-a9d1-4bba-bb63-f89b6fdb1f87' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b956186a-a9d1-4bba-bb63-f89b6fdb1f87' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bff41f55-2e48-41f1-9d56-d0e1ba408cb0' class='xr-var-data-in' type='checkbox'><label for='data-bff41f55-2e48-41f1-9d56-d0e1ba408cb0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-122.081, -122.081, -122.081, ..., -122.081, -122.081, -122.081],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pr_15min</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0</div><input id='attrs-ff8cde40-1a1a-45e8-b1be-5790aadcea5f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ff8cde40-1a1a-45e8-b1be-5790aadcea5f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1d5901cd-ecee-4b00-9de0-5659a298641f' class='xr-var-data-in' type='checkbox'><label for='data-1d5901cd-ecee-4b00-9de0-5659a298641f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pr_15min_eraqc</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-bf87b521-2723-4e0b-852b-2305ca41ad7e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-bf87b521-2723-4e0b-852b-2305ca41ad7e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3ce1e3bf-6daa-49f7-9b54-2774d70a7e88' class='xr-var-data-in' type='checkbox'><label for='data-3ce1e3bf-6daa-49f7-9b54-2774d70a7e88' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>thermometer_height_m</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-3c918493-3fd7-4e74-818e-01539dd44ce7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3c918493-3fd7-4e74-818e-01539dd44ce7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d4a2276b-5ca8-4738-bfa3-075d0f8331ae' class='xr-var-data-in' type='checkbox'><label for='data-d4a2276b-5ca8-4738-bfa3-075d0f8331ae' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-bf62553e-ebe5-43b7-aa35-853fe7a440c8' class='xr-section-summary-in' type='checkbox'  ><label for='section-bf62553e-ebe5-43b7-aa35-853fe7a440c8' class='xr-section-summary' >Attributes: <span>(13)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Networks :</span></dt><dd>VALLEYWATER</dd><dt><span>comment :</span></dt><dd>Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.</dd><dt><span>disclaimer :</span></dt><dd>This document was prepared as a result of work funded by the Santa Clara Valley Water District. It does not necessarily represent the views of the Santa Clara Valley Water District or its employees. Neither the Santa Clara Valley Water District, nor it&#x27;s employees, contractors, or subcontractors makes any warranty, express or implied, or assumes any legal liability for the information in this document; nor does any party represent that the use of this information will not infringe upon privately owned rights. This document has not been approved or disapproved by Santa Clara Valley Water District, nor has the Santa Clara Valley Water District passed upon the accuracy of the information in this document.</dd><dt><span>history :</span></dt><dd>VALLEYWATER_clean.py script run on 01-28-2025, 01:32:09 UTC \n",
       "ALLNETWORKS_qaqc.py script run on 03-21-2025, 16:56:31 UTC \n",
       "VALLEYWATER_qaqc_custom.ipynb run on 04-02-2025, 16:56:11 UTC \n",
       " maritime_merge.ipynb run on 04-04-2025, 17:18:46 UTC</dd><dt><span>institution :</span></dt><dd>Eagle Rock Analytics</dd><dt><span>license :</span></dt><dd></dd><dt><span>raw_files_merged :</span></dt><dd>1</dd><dt><span>sensor_height_m :</span></dt><dd>nan</dd><dt><span>source :</span></dt><dd></dd><dt><span>station_name :</span></dt><dd>Maryknoll Fields</dd><dt><span>title :</span></dt><dd>VALLEYWATER quality controlled</dd><dt><span>watershed :</span></dt><dd>Lower Peninsula</dd><dt><span>qaqc_files_merged :</span></dt><dd>VALLEYWATER_VALLEYWATER_6053, VALLEYWATER_VALLEYWATER_6144 merged. Overlap retained from newer station data.</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:               (index: 2051327)\n",
       "Coordinates:\n",
       "  * index                 (index) int64 0 1 2 3 ... 1511014 1511015 1511016\n",
       "Data variables:\n",
       "    anemometer_height_m   (index) float32 nan nan nan nan ... nan nan nan nan\n",
       "    elevation             (index) float32 130.4 130.4 130.4 ... 130.4 130.4\n",
       "    lat                   (index) float32 37.33 37.33 37.33 ... 37.33 37.33\n",
       "    lon                   (index) float32 -122.1 -122.1 -122.1 ... -122.1 -122.1\n",
       "    pr_15min              (index) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    pr_15min_eraqc        (index) float32 nan nan nan nan ... nan nan nan nan\n",
       "    thermometer_height_m  (index) float32 nan nan nan nan ... nan nan nan nan\n",
       "Attributes: (12/13)\n",
       "    Networks:           VALLEYWATER\n",
       "    comment:            Final v1 data product. This data has been subjected t...\n",
       "    disclaimer:         This document was prepared as a result of work funded...\n",
       "    history:            VALLEYWATER_clean.py script run on 01-28-2025, 01:32:...\n",
       "    institution:        Eagle Rock Analytics\n",
       "    license:            \n",
       "    ...                 ...\n",
       "    sensor_height_m:    nan\n",
       "    source:             \n",
       "    station_name:       Maryknoll Fields\n",
       "    title:              VALLEYWATER quality controlled\n",
       "    watershed:          Lower Peninsula\n",
       "    qaqc_files_merged:  VALLEYWATER_VALLEYWATER_6053, VALLEYWATER_VALLEYWATER..."
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_concat[existing_float32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:          (index: 2051327)\n",
       "Coordinates:\n",
       "  * index            (index) int64 0 1 2 3 4 ... 1511013 1511014 1511015 1511016\n",
       "Data variables:\n",
       "    elevation_eraqc  (index) float64 3.0 3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 3.0 3.0\n",
       "    pr_15min_eraqc   (index) float32 nan nan nan nan nan ... nan nan nan nan nan\n",
       "    raw_qc           (index) object &#x27;Approved&#x27; &#x27;Approved&#x27; ... &#x27;Approved&#x27;\n",
       "Attributes: (12/13)\n",
       "    Networks:           VALLEYWATER\n",
       "    comment:            Final v1 data product. This data has been subjected t...\n",
       "    disclaimer:         This document was prepared as a result of work funded...\n",
       "    history:            VALLEYWATER_clean.py script run on 01-28-2025, 01:32:...\n",
       "    institution:        Eagle Rock Analytics\n",
       "    license:            \n",
       "    ...                 ...\n",
       "    sensor_height_m:    nan\n",
       "    source:             \n",
       "    station_name:       Maryknoll Fields\n",
       "    title:              VALLEYWATER quality controlled\n",
       "    watershed:          Lower Peninsula\n",
       "    qaqc_files_merged:  VALLEYWATER_VALLEYWATER_6053, VALLEYWATER_VALLEYWATER...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-3fa201df-8fd9-4e72-a32d-9e356b770a2b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-3fa201df-8fd9-4e72-a32d-9e356b770a2b' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>index</span>: 2051327</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-4a69caea-fcd3-4b24-893d-853fe9c88c94' class='xr-section-summary-in' type='checkbox'  checked><label for='section-4a69caea-fcd3-4b24-893d-853fe9c88c94' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>index</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 ... 1511014 1511015 1511016</div><input id='attrs-86bcc992-eba7-4552-b350-f18692fcec04' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-86bcc992-eba7-4552-b350-f18692fcec04' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-005c3e94-0fbe-42de-a8cb-1eb700d2b366' class='xr-var-data-in' type='checkbox'><label for='data-005c3e94-0fbe-42de-a8cb-1eb700d2b366' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([      0,       1,       2, ..., 1511014, 1511015, 1511016])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c034b7db-7ada-45a3-ade2-ce1c08ec9a10' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c034b7db-7ada-45a3-ade2-ce1c08ec9a10' class='xr-section-summary' >Data variables: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>elevation_eraqc</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 3.0</div><input id='attrs-f6667286-4a47-4d71-870f-36fa16a3c488' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f6667286-4a47-4d71-870f-36fa16a3c488' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c05b930d-11c0-4a95-8e90-2c8ff0f16370' class='xr-var-data-in' type='checkbox'><label for='data-c05b930d-11c0-4a95-8e90-2c8ff0f16370' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([3., 3., 3., ..., 3., 3., 3.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pr_15min_eraqc</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-9450f778-a557-43ca-9b34-ea5336e0ae38' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9450f778-a557-43ca-9b34-ea5336e0ae38' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a08a4d28-90a3-4b94-8ec8-8405153376e8' class='xr-var-data-in' type='checkbox'><label for='data-a08a4d28-90a3-4b94-8ec8-8405153376e8' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>raw_qc</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;Approved&#x27; ... &#x27;Approved&#x27;</div><input id='attrs-730aeb20-e390-4ad9-8be0-720583cbf412' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-730aeb20-e390-4ad9-8be0-720583cbf412' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a9f773f1-c63a-4ba4-b395-3295e67e4ceb' class='xr-var-data-in' type='checkbox'><label for='data-a9f773f1-c63a-4ba4-b395-3295e67e4ceb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;Approved&#x27;, &#x27;Approved&#x27;, &#x27;Approved&#x27;, ..., &#x27;Approved&#x27;, &#x27;Approved&#x27;,\n",
       "       &#x27;Approved&#x27;], dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-e60c5c60-672c-4ad5-98ea-3272802241c5' class='xr-section-summary-in' type='checkbox'  ><label for='section-e60c5c60-672c-4ad5-98ea-3272802241c5' class='xr-section-summary' >Attributes: <span>(13)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Networks :</span></dt><dd>VALLEYWATER</dd><dt><span>comment :</span></dt><dd>Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.</dd><dt><span>disclaimer :</span></dt><dd>This document was prepared as a result of work funded by the Santa Clara Valley Water District. It does not necessarily represent the views of the Santa Clara Valley Water District or its employees. Neither the Santa Clara Valley Water District, nor it&#x27;s employees, contractors, or subcontractors makes any warranty, express or implied, or assumes any legal liability for the information in this document; nor does any party represent that the use of this information will not infringe upon privately owned rights. This document has not been approved or disapproved by Santa Clara Valley Water District, nor has the Santa Clara Valley Water District passed upon the accuracy of the information in this document.</dd><dt><span>history :</span></dt><dd>VALLEYWATER_clean.py script run on 01-28-2025, 01:32:09 UTC \n",
       "ALLNETWORKS_qaqc.py script run on 03-21-2025, 16:56:31 UTC \n",
       "VALLEYWATER_qaqc_custom.ipynb run on 04-02-2025, 16:56:11 UTC \n",
       " maritime_merge.ipynb run on 04-04-2025, 17:18:46 UTC</dd><dt><span>institution :</span></dt><dd>Eagle Rock Analytics</dd><dt><span>license :</span></dt><dd></dd><dt><span>raw_files_merged :</span></dt><dd>1</dd><dt><span>sensor_height_m :</span></dt><dd>nan</dd><dt><span>source :</span></dt><dd></dd><dt><span>station_name :</span></dt><dd>Maryknoll Fields</dd><dt><span>title :</span></dt><dd>VALLEYWATER quality controlled</dd><dt><span>watershed :</span></dt><dd>Lower Peninsula</dd><dt><span>qaqc_files_merged :</span></dt><dd>VALLEYWATER_VALLEYWATER_6053, VALLEYWATER_VALLEYWATER_6144 merged. Overlap retained from newer station data.</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:          (index: 2051327)\n",
       "Coordinates:\n",
       "  * index            (index) int64 0 1 2 3 4 ... 1511013 1511014 1511015 1511016\n",
       "Data variables:\n",
       "    elevation_eraqc  (index) float64 3.0 3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 3.0 3.0\n",
       "    pr_15min_eraqc   (index) float32 nan nan nan nan nan ... nan nan nan nan nan\n",
       "    raw_qc           (index) object 'Approved' 'Approved' ... 'Approved'\n",
       "Attributes: (12/13)\n",
       "    Networks:           VALLEYWATER\n",
       "    comment:            Final v1 data product. This data has been subjected t...\n",
       "    disclaimer:         This document was prepared as a result of work funded...\n",
       "    history:            VALLEYWATER_clean.py script run on 01-28-2025, 01:32:...\n",
       "    institution:        Eagle Rock Analytics\n",
       "    license:            \n",
       "    ...                 ...\n",
       "    sensor_height_m:    nan\n",
       "    source:             \n",
       "    station_name:       Maryknoll Fields\n",
       "    title:              VALLEYWATER quality controlled\n",
       "    watershed:          Lower Peninsula\n",
       "    qaqc_files_merged:  VALLEYWATER_VALLEYWATER_6053, VALLEYWATER_VALLEYWATER..."
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_concat[existing_U16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_concat[existing_float32] = ds_concat[existing_float32].astype(\"float32\")\n",
    "ds_concat[existing_U16] = ds_concat[existing_U16].astype(\"U16\")\n",
    "\n",
    "ds_concat.coords[\"station\"] = ds_concat.coords[\"station\"].astype(\"<U16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_station_pairs(network_name):\n",
    "    \"\"\"\n",
    "    Concatenates two input datasets, deletes the originals, and exports the final concatenated dataset\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "        station_old: string\n",
    "            name of the older weather station\n",
    "        station_new: string\n",
    "            name of the newer weather station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "    ##### Read in concatenation list of input network\n",
    "    network_list = s3_cl.get_object(\n",
    "        Bucket=bucket,\n",
    "        Key=\"3_qaqc_wx/{}_copy/{}/{}_concat_list_TEST.csv\".format(\n",
    "            network_name, network_name, network_name\n",
    "        ),\n",
    "    )\n",
    "    concat_list = pd.read_csv(BytesIO(network_list[\"Body\"].read()))\n",
    "\n",
    "    subset_number = len(concat_list['concat_subset'].unique()\n",
    "                        )\n",
    "    for i in range(0,subset_number):\n",
    "\n",
    "        # count the number of staions in subset i\n",
    "        subset_i = concat_list[\n",
    "            concat_list[\"concat_subset\"].str.contains(\"{}\".format(i))\n",
    "        ]\n",
    "\n",
    "        n = subset_i.count()[0]\n",
    "\n",
    "        # if there are only two stations, proceed with concatenation\n",
    "        if n == 2:\n",
    "            # retrieve ERA IDs in this subset of stations\n",
    "            station_1 = subset_i[\"ERA-ID\"].iloc[0]\n",
    "            station_2 = subset_i[\"ERA-ID\"].iloc[1]\n",
    "\n",
    "            # import this subset of datasets and convert to dataframe\n",
    "            url_1 = \"s3://wecc-historical-wx/3_qaqc_wx/{}_copy/{}/{}.zarr\".format(\n",
    "                network_name, network_name, station_1\n",
    "            )\n",
    "            url_2 = \"s3://wecc-historical-wx/3_qaqc_wx/{}_copy/{}/{}.zarr\".format(\n",
    "                network_name,network_name, station_2\n",
    "            )\n",
    "\n",
    "            # TODO: open_zarr will be used for QAQC'd datasets\n",
    "            ds_1 = xr.open_zarr(url_1)\n",
    "            ds_2 = xr.open_zarr(url_2)\n",
    "\n",
    "            df_1 = ds_1.to_dataframe()\n",
    "            df_2 = ds_2.to_dataframe()\n",
    "\n",
    "            # apply reset index only to 'time', as we will need that for concatenation\n",
    "            # TODO: this may not be necessary\n",
    "            # df_1 = df_1.reset_index(level=\"time\")\n",
    "            # df_2 = df_2.reset_index(level=\"time\")\n",
    "\n",
    "            df_1 = df_1.reset_index()\n",
    "            df_2 = df_2.reset_index()\n",
    "\n",
    "            # determine which dataset is older\n",
    "            if df_1[\"time\"].max() < df_2[\"time\"].max(): \n",
    "                # if df_1 has an earlier end tiem than df_2, then d_2 is newer\n",
    "                # we also grab the name of the newer station in this step, for use later\n",
    "                df_new = df_2\n",
    "                ds_new = ds_2\n",
    "\n",
    "                df_old = df_1\n",
    "                ds_old = ds_1\n",
    "            else:\n",
    "                df_new = df_1\n",
    "                ds_new = ds_1\n",
    "\n",
    "                df_old = df_2\n",
    "                ds_old = ds_2\n",
    "\n",
    "            print('about to time')\n",
    "            # now set things up to determine if there is temporal overlap between df_new and df_old\n",
    "            df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "            # if there is overlap between the two time series\n",
    "            if len(df_overlap) == 0:\n",
    "                ##### Split datframes into subsets #####\n",
    "\n",
    "                # Remove data in time overlap between old and new\n",
    "                df_old_cleaned = df_old[~df_old[\"time\"].isin(df_new[\"time\"])]\n",
    "                df_new_cleaned = df_new[~df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "                # Data in new input that overlaps in time with old input\n",
    "                df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "                ##### Concatenate subsets #####\n",
    "                df_concat = concat([df_old_cleaned, df_overlap, df_new_cleaned])\n",
    "            # if not, concatenate\n",
    "            else: \n",
    "                df_concat = concat([df_new, df_overlap, df_old])\n",
    "\n",
    "            ##### Now prepare the final concatenated dataframe for export\n",
    "\n",
    "            # Modify index for df_old_cleaned\n",
    "            # We want the final dataset to show up as the new station, not the old\n",
    "            station_name_new = ds_new.coords[\"station\"].values[0]\n",
    "            final_station_name = \"{}_{}\".format(network_name, station_name_new)\n",
    "            new_index = [final_station_name] * len(df_concat)\n",
    "\n",
    "            df_concat['station'] = new_index\n",
    "\n",
    "            df_concat.set_index(['time','station'])\n",
    "\n",
    "            ########################## TODO below is the original #########################\n",
    "            # df_concat.index = new_index\n",
    "            # df_concat.index.name = \"station\"\n",
    "\n",
    "            # # Add 'time' back into multi index\n",
    "            # df_concat.set_index(\"time\", append=True, inplace=True)\n",
    "            ########################## TODO above is the original #########################\n",
    "\n",
    "            # Convert concatenated dataframe to dataset\n",
    "            ds_concat = df_concat.to_xarray()\n",
    "\n",
    "            ##### Update attributes and datatypes #####\n",
    "\n",
    "            # Include past attributes\n",
    "            ds_concat.attrs = ds_new.attrs\n",
    "\n",
    "            # Update 'history' attribute\n",
    "            timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "            ds_concat.attrs[\"history\"] = ds_new.attrs[\n",
    "                \"history\"\n",
    "            ] + \" \\n maritime_merge.ipynb run on {} UTC\".format(timestamp)\n",
    "\n",
    "            # Update 'comment' attribute\n",
    "            ds_concat.attrs[\"comment\"] = (\n",
    "                \"Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.\"\n",
    "            )\n",
    "\n",
    "            # Add new qaqc_files_merged attribute\n",
    "            station_name_old = ds_old.coords[\"station\"].values[0]\n",
    "            ds_concat.attrs[\"qaqc_files_merged\"] = (\n",
    "                \"{}_{}, {}_{} merged. Overlap retained from newer station data.\".format(\n",
    "                    network_name, station_name_old, network_name, station_name_new\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Convert all datatypes, to enable export\n",
    "            existing_float32 = [col for col in float32_variables if col in df_concat.columns]\n",
    "            existing_U16 = [col for col in U16_variables if col in df_concat.columns]\n",
    "\n",
    "            ds_concat[existing_float32] = ds_concat[existing_float32].astype(\"float32\")\n",
    "            ds_concat[existing_U16] = ds_concat[existing_U16].astype(\"U16\")\n",
    "\n",
    "            ds_concat.coords[\"station\"] = ds_concat.coords[\"station\"].astype(\"<U16\")\n",
    "\n",
    "            ### Export ###\n",
    "\n",
    "            # # Export final, concatenated dataset\n",
    "            # export_url = \"s3://wecc-historical-wx/3_qaqc_wx/{}_copy/{}/{}_{}.zarr\".format(\n",
    "            #     network_name, network_name, network_name, \"test\"\n",
    "            # )\n",
    "            # ds_concat.to_zarr(export_url, mode=\"w\")\n",
    "\n",
    "        # if there are more than two stations in the subset, continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return ds_concat # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to time\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Different lengths of variables to be set (4) and data used as input for setting (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconcatenate_station_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVALLEYWATER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[123], line 163\u001b[0m, in \u001b[0;36mconcatenate_station_pairs\u001b[0;34m(network_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m     existing_U16 \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m U16_variables \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_concat\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m    162\u001b[0m     ds_concat[existing_float32] \u001b[38;5;241m=\u001b[39m ds_concat[existing_float32]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43mds_concat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexisting_U16\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m ds_concat[existing_U16]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m     ds_concat\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ds_concat\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<U16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m### Export ###\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# # Export final, concatenated dataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# if there are more than two stations in the subset, continue\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/xarray/core/dataset.py:1546\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[0;32m-> 1546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1547\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifferent lengths of variables to be set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1548\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) and data used as input for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetting (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1550\u001b[0m         )\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Dataset):\n\u001b[1;32m   1552\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mdata_vars\u001b[38;5;241m.\u001b[39mvalues())))\n",
      "\u001b[0;31mValueError\u001b[0m: Different lengths of variables to be set (4) and data used as input for setting (3)"
     ]
    }
   ],
   "source": [
    "concatenate_station_pairs('VALLEYWATER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_test(concat_list):\n",
    "    \"\"\"\n",
    "    Performs concatenation for stations in list of stations flagged for concatenation.\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "        station_old: string\n",
    "            name of the older weather station\n",
    "        station_new: string\n",
    "            name of the newer weather station\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "    ##### Import target datasets and convert to dataframe\n",
    "    flag_range = list(\n",
    "        range(concat_list[\"concat_flag\"].min(), concat_list[\"concat_flag\"].max())\n",
    "    )\n",
    "\n",
    "    for i in flag_range:\n",
    "        subset_list = concat_list[concat_list[\"concat_flag\"] == i]\n",
    "        subset_range = list(range(0, len(subset_list)))\n",
    "\n",
    "        url = {}\n",
    "        ds = {}\n",
    "        df = {}\n",
    "\n",
    "        for i in subset_range:\n",
    "\n",
    "            # extract information needed for dataset import\n",
    "            row_i = subset_list.iloc[[i]]\n",
    "            network_name = row_i[\"ERA-ID\"].split(\"_\")[\n",
    "                0\n",
    "            ]  # TODO: this does not work, when it really should\n",
    "            station_name = row_i[\"ERA-ID\"]\n",
    "\n",
    "            url[i] = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}_{}.zarr\".format(\n",
    "                network_name, network_name, station_name\n",
    "            )\n",
    "\n",
    "            ds[i] = xr.open_zarr(url[i])\n",
    "\n",
    "            df[i] = ds[i].to_dataframe()\n",
    "\n",
    "            # Apply reset index only to 'time', as we will need that for concatenation\n",
    "            df[i] = df[i].reset_index(level=\"time\")\n",
    "\n",
    "    ##### Split datframes into subsets #####\n",
    "\n",
    "    # Remove data in time overlap between old and new\n",
    "    df_old_cleaned = df_old[~df_old[\"time\"].isin(df_new[\"time\"])]\n",
    "    df_new_cleaned = df_new[~df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    # Data in new input that overlaps in time with old input\n",
    "    df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    # Set index to new input for df_old_cleaned\n",
    "    # We want the final dataset to show up as the new station, not the old\n",
    "    final_station_name = \"{}_{}\".format(network_name, station_new)\n",
    "    new_index = [final_station_name] * len(df_old_cleaned)\n",
    "\n",
    "    df_old_cleaned.index = new_index\n",
    "    df_old_cleaned.index.name = \"station\"\n",
    "\n",
    "    ##### Concatenate subsets #####\n",
    "\n",
    "    df_concat = concat([df_old_cleaned, df_overlap, df_new_cleaned])\n",
    "\n",
    "    # Add 'time' back into multi index\n",
    "    df_concat.set_index(\"time\", append=True, inplace=True)\n",
    "\n",
    "    # Convert concatenated dataframe to dataset\n",
    "    ds_concat = df_concat.to_xarray()\n",
    "\n",
    "    ##### Update attributes and datatypes #####\n",
    "\n",
    "    # Include past attributes\n",
    "    ds_concat.attrs = ds_new.attrs\n",
    "\n",
    "    # Update 'history' attribute\n",
    "    timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "    ds_concat.attrs[\"history\"] = ds_new.attrs[\n",
    "        \"history\"\n",
    "    ] + \" \\nmaritime_merge.ipynb run on {} UTC\".format(timestamp)\n",
    "\n",
    "    # Update 'comment' attribute\n",
    "    ds_concat.attrs[\"comment\"] = (\n",
    "        \"Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.\"\n",
    "    )\n",
    "\n",
    "    # Add new qaqc_files_merged attribute\n",
    "    ds_concat.attrs[\"qaqc_files_merged\"] = (\n",
    "        \"{}_{}, {}_{} merged. Overlap retained from newer station data.\".format(\n",
    "            network_name, station_old, network_name, station_new\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Convert all datatypes, to enable export\n",
    "    existing_float32 = [col for col in float32_variables if col in df_concat.columns]\n",
    "    existing_U16 = [col for col in U16_variables if col in df_concat.columns]\n",
    "\n",
    "    ds_concat[existing_float32] = ds_concat[existing_float32].astype(\"float32\")\n",
    "    ds_concat[existing_U16] = ds_concat[existing_U16].astype(\"U16\")\n",
    "\n",
    "    ds_concat.coords[\"station\"] = ds_concat.coords[\"station\"].astype(\"<U16\")\n",
    "\n",
    "    ### Export ###\n",
    "\n",
    "    # delete old inputs\n",
    "    bucket = \"wecc-historical-wx\"\n",
    "    key_new = \"4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, station_new\n",
    "    )\n",
    "    key_old = \"4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, station_old\n",
    "    )\n",
    "\n",
    "    delete_folder(bucket, key_new)\n",
    "    delete_folder(bucket, key_old)\n",
    "\n",
    "    # Export final, concatenated dataset\n",
    "    export_url = \"s3://wecc-historical-wx/4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, \"test\"\n",
    "    )\n",
    "    ds_concat.to_zarr(export_url, mode=\"w\")\n",
    "\n",
    "    return None  # ds_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE SCRAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = asosawos_list_concat.groupby([\"ICAO\"]).apply(\n",
    "    lambda x: x.sort_values([\"end_time\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort by end_time or end-date, depending on the station TODO: this is not necessary\n",
    "# time_var_list = ['end_time','end-date']\n",
    "# end_time_or_date = [col for col in station_list.columns if col in time_var_list]\n",
    "# new_station_list = new_station_list.groupby('concat_flag').apply(lambda x: x.sort_values(end_time_or_date)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_target_stations_old(df):\n",
    "    \"\"\"\n",
    "    Concatenates station data that has been flagged for concatenation\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.)\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        df: pd.dataframe\n",
    "            staton data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply reset index only to 'time', as we will need that for concatenation\n",
    "    df_old = df_old.reset_index(level=\"time\")\n",
    "    df_new = df_new.reset_index(level=\"time\")\n",
    "\n",
    "    ##### Split datframes into subsets #####\n",
    "    # if there is overlap, then create subsets\n",
    "\n",
    "    # if no overlap, just concatenate\n",
    "\n",
    "    # Remove data in time overlap between old and new\n",
    "    df_old_cleaned = df_old[~df_old[\"time\"].isin(df_new[\"time\"])]\n",
    "    df_new_cleaned = df_new[~df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    # Data in new input that overlaps in time with old input\n",
    "    df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    # Set index to new input for df_old_cleaned\n",
    "    # We want the final dataset to show up as the new station, not the old\n",
    "    final_station_name = \"{}_{}\".format(network_name, station_new)\n",
    "    new_index = [final_station_name] * len(df_old_cleaned)\n",
    "\n",
    "    df_old_cleaned.index = new_index\n",
    "    df_old_cleaned.index.name = \"station\"\n",
    "\n",
    "    ##### Concatenate subsets #####\n",
    "\n",
    "    df_concat = concat([df_old_cleaned, df_overlap, df_new_cleaned])\n",
    "\n",
    "    # Add 'time' back into multi index\n",
    "    df_concat.set_index(\"time\", append=True, inplace=True)\n",
    "\n",
    "    # Convert concatenated dataframe to dataset\n",
    "    ds_concat = df_concat.to_xarray()\n",
    "\n",
    "    ##### Update attributes and datatypes #####\n",
    "\n",
    "    # Include past attributes\n",
    "    ds_concat.attrs = ds_new.attrs\n",
    "\n",
    "    # Update 'history' attribute\n",
    "    timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "    ds_concat.attrs[\"history\"] = ds_new.attrs[\n",
    "        \"history\"\n",
    "    ] + \" \\nmaritime_merge.ipynb run on {} UTC\".format(timestamp)\n",
    "\n",
    "    # Update 'comment' attribute\n",
    "    ds_concat.attrs[\"comment\"] = (\n",
    "        \"Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.\"\n",
    "    )\n",
    "\n",
    "    # Add new qaqc_files_merged attribute\n",
    "    ds_concat.attrs[\"qaqc_files_merged\"] = (\n",
    "        \"{}_{}, {}_{} merged. Overlap retained from newer station data.\".format(\n",
    "            network_name, station_old, network_name, station_new\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Convert all datatypes, to enable export\n",
    "    existing_float32 = [col for col in float32_variables if col in df_concat.columns]\n",
    "    existing_U16 = [col for col in U16_variables if col in df_concat.columns]\n",
    "\n",
    "    ds_concat[existing_float32] = ds_concat[existing_float32].astype(\"float32\")\n",
    "    ds_concat[existing_U16] = ds_concat[existing_U16].astype(\"U16\")\n",
    "\n",
    "    ds_concat.coords[\"station\"] = ds_concat.coords[\"station\"].astype(\"<U16\")\n",
    "\n",
    "    return None  # ds_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_station_list(station_list, concat_list, duplicate_list):\n",
    "    \"\"\"\n",
    "    Reorders the input station list, necessary for concatenation\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.)\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        station_list: pd.dataframe\n",
    "\n",
    "        concat_list: pd.dataframe\n",
    "\n",
    "        duplicate_list: pd.dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            output station list with stations to be concatenated at top, followed by potential duplicates\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    ##### subsets of station list\n",
    "\n",
    "    # stations that will be concatenated\n",
    "    concat_stations = station_list[station_list[\"ICAO\"].isin(concat_list)]\n",
    "\n",
    "    # potential duplicate stations\n",
    "    duplicate_stations = station_list[station_list[\"ICAO\"].isin(duplicate_list)]\n",
    "\n",
    "    # all remaining stations\n",
    "    remaining_stations = station_list[\n",
    "        ~station_list[\"ICAO\"].isin(duplicate_list + concat_list)\n",
    "    ]\n",
    "\n",
    "    ##### sort concat list alphabetically, to ensure that stations with the same ICAO are grouped together\n",
    "    concat_stations = concat_stations.sort_values(\"ICAO\")\n",
    "    duplicate_stations = duplicate_stations.sort_values(\"ICAO\")\n",
    "\n",
    "    ##### now within each ICAO, order by end time\n",
    "    concat_stations = concat_stations.groupby([\"ICAO\"]).apply(\n",
    "        lambda x: x.sort_values([\"end_time\"])\n",
    "    )\n",
    "\n",
    "    ##### concatenate susbets and reset index\n",
    "    new_list = concat(\n",
    "        [concat_stations, duplicate_stations, remaining_stations]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of null start times:\n",
      "0\n",
      "number of null end times:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for presence of start and end times\n",
    "\n",
    "time_check = repeat_list_subset.groupby(\"ICAO\").apply(lambda x: x.isnull().any())\n",
    "\n",
    "print(\"number of null start times:\")\n",
    "print(time_check[\"start_time\"].sum())\n",
    "\n",
    "print(\"number of null end times:\")\n",
    "print(time_check[\"end_time\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the start and end times are identical\n",
    "\n",
    "start_duplicate_check = (\n",
    "    repeat_list_subset.groupby(\"ICAO\")\n",
    "    .apply(lambda x: x.duplicated(subset=[\"start_time\"]))\n",
    "    .rename(\"check\")\n",
    "    .reset_index()\n",
    ")\n",
    "end_duplicate_check = (\n",
    "    repeat_list_subset.groupby(\"ICAO\")\n",
    "    .apply(lambda x: x.duplicated(subset=[\"end_time\"]))\n",
    "    .rename(\"check\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KBOK', 'KMLF']\n",
      "['K20V']\n"
     ]
    }
   ],
   "source": [
    "end_list = end_duplicate_check[end_duplicate_check[\"check\"] == True][\"ICAO\"].tolist()\n",
    "start_list = start_duplicate_check[start_duplicate_check[\"check\"] == True][\n",
    "    \"ICAO\"\n",
    "].tolist()\n",
    "\n",
    "print(end_list)\n",
    "print(start_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is going on with the stations that have duplicate start and end times? are they true duplicates?\n",
    "\n",
    "repeat_list_subset[repeat_list_subset[\"ICAO\"].isin(start_list + end_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in single dc file from AWS\n",
    "ds_1 = read_nc_from_s3_clean(\"ASOSAWOS\", \"ASOSAWOS_72026294076\", temp_dir)\n",
    "ds_2 = read_nc_from_s3_clean(\"ASOSAWOS\", \"ASOSAWOS_A0000594076\", temp_dir)\n",
    "\n",
    "\n",
    "# convert to formatted pandas dataframe\n",
    "df_1 = qaqc_ds_to_df(ds_1, verbose=False)\n",
    "df_2 = qaqc_ds_to_df(ds_2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = df_1.lon.mean()\n",
    "lat = df_1.lat.mean()\n",
    "# print(\"{}, {:.5f}, {:.5f}\".format(id, lon, lat))\n",
    "\n",
    "\n",
    "# Plot time series of the data\n",
    "fig, ax = plt.subplots(figsize=(9, 3))\n",
    "\n",
    "df_1.plot(ax=ax, x=\"time\", y=\"sfcWind\")\n",
    "df_2.plot(ax=ax, x=\"time\", y=\"sfcWind\")\n",
    "\n",
    "ax.set_title(\"{}  ({:.3f}, {:.3f})\".format(id, lon, lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_check_old(station_list):\n",
    "    \"\"\"\n",
    "    Resamples meteorological variables to hourly timestep according to standard conventions.\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.)\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        df: pd.DataFrame\n",
    "            list of station information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            list\n",
    "                list of ICAO values of stations that need to be concatenated\n",
    "            list\n",
    "                list of ICAO values of potential duplicate stations\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "    # Generate list of repeat ICAOs\n",
    "    repeat_list = station_list[station_list.duplicated(subset=[\"ICAO\"], keep=False)]\n",
    "    repeat_list = repeat_list[\n",
    "        [\"ICAO\", \"ERA-ID\", \"STATION NAME\", \"start_time\", \"end_time\"]\n",
    "    ]\n",
    "\n",
    "    concat_list = repeat_list[\"ICAO\"].unique().tolist()\n",
    "\n",
    "    # And empty list to add potential duplicates to\n",
    "    duplicate_list = []\n",
    "\n",
    "    ##### Generate boolean for whether or not there are null start and/or end times\n",
    "    # TODO: may not be necessary\n",
    "    time_check = repeat_list.groupby(\"ICAO\").apply(lambda x: x.isnull().any())\n",
    "\n",
    "    end_nan_list = time_check[time_check[\"end_time\"] == True][\"ICAO\"].tolist()\n",
    "    start_nan_list = time_check[time_check[\"start_time\"] == True][\"ICAO\"].tolist()\n",
    "\n",
    "    # add ICAOs of stations with nan start or end times to potential duplicates list\n",
    "    duplicate_list = duplicate_list + start_nan_list + end_nan_list\n",
    "\n",
    "    duplicate_list = duplicate_list\n",
    "\n",
    "    ##### Identify ICAOs with duplicate start end times\n",
    "    start_duplicate_check = (\n",
    "        repeat_list.groupby(\"ICAO\")\n",
    "        .apply(lambda x: x.duplicated(subset=[\"start_time\"]))\n",
    "        .rename(\"check\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    end_duplicate_check = (\n",
    "        repeat_list.groupby(\"ICAO\")\n",
    "        .apply(lambda x: x.duplicated(subset=[\"end_time\"]))\n",
    "        .rename(\"check\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    end_dup_list = end_duplicate_check[end_duplicate_check[\"check\"] == True][\n",
    "        \"ICAO\"\n",
    "    ].tolist()\n",
    "    start_dup_list = start_duplicate_check[start_duplicate_check[\"check\"] == True][\n",
    "        \"ICAO\"\n",
    "    ].tolist()\n",
    "\n",
    "    # add ICAOs of stations with nan start or end times to potential duplicates list\n",
    "    duplicate_list = duplicate_list + start_dup_list + end_dup_list\n",
    "\n",
    "    # Generate final list of ICAOs for stations to be concatenated\n",
    "    concat_list = [x for x in concat_list if x not in duplicate_list]\n",
    "\n",
    "    return concat_list, duplicate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1101/3479120207.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  asosawos_list_concat['ICAO'] = pd.Categorical(asosawos_list_concat['ICAO'], categories=concat_list, ordered=True)\n"
     ]
    }
   ],
   "source": [
    "# order the subset with only stations to concatenate\n",
    "\n",
    "asosawos_list_concat[\"ICAO\"] = pd.Categorical(\n",
    "    asosawos_list_concat[\"ICAO\"], categories=concat_list, ordered=True\n",
    ")\n",
    "\n",
    "test_list = asosawos_list_concat.sort_values(\"ICAO\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations within a certain distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into GeoDataFrames\n",
    "# using EPSG 3310\n",
    "\n",
    "gdf_asosawos = gpd.GeoDataFrame(\n",
    "    asosawos_list,\n",
    "    geometry=[\n",
    "        Point(lon, lat) for lon, lat in zip(asosawos_list[\"LON\"], asosawos_list[\"LAT\"])\n",
    "    ],\n",
    "    crs=\"EPSG:4326\",\n",
    ").to_crs(epsg=3310)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approach 3: find the nearest point in the geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert emtpy columns\n",
    "\n",
    "gdf_asosawos[\"nearest_station\"] = pd.Series(dtype=\"U16\")\n",
    "gdf_asosawos[\"distance\"] = pd.Series(dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in gdf_asosawos.iterrows():\n",
    "    # geometry of individual row \n",
    "    point = row.geometry\n",
    "    # returns a multipoint object with the geometries of every row in the gdf\n",
    "    multipoint = gdf_asosawos.drop(index, axis=0).geometry.unary_union\n",
    "    # \n",
    "    queried_geom, nearest_geom = nearest_points(point, multipoint)\n",
    "    dist_from_point = \n",
    "    gdf_asosawos.loc[index, 'nearest_geometry'] = nearest_geom\n",
    "    gdf_asosawos.loc[index, 'distance'] = nearest_geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approach 2: distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to calculate the distance between points\n",
    "\n",
    "\n",
    "def distance_sort_filter(row, df2, buffer=None, id=False):\n",
    "\n",
    "    dist = df2.geometry.distance(row).sort_values()\n",
    "\n",
    "    if buffer:\n",
    "        dist = dist[dist < buffer]\n",
    "\n",
    "    if id:\n",
    "        distances = {\n",
    "            df2.loc[idx][\"WBAN\"]: value for idx, value in zip(dist.index, dist.values)\n",
    "        }\n",
    "    else:\n",
    "        distances = {idx: value for idx, value in zip(dist.index, dist.values)}\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### approach 1: using sjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a buffer around points in gdf1 (e.g., 10 km buffer)\n",
    "gdf_asosawos[\"buffer\"] = gdf_asosawos.geometry.buffer(\n",
    "    0.1\n",
    ")  # Buffer in degrees, 0.1 degrees approx equals 10 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial join using the buffer\n",
    "merged = gpd.sjoin(\n",
    "    gdf_asosawos, gdf_asosawos[[\"geometry\", \"buffer\"]], how=\"inner\", predicate=\"within\"\n",
    ")\n",
    "\n",
    "# The 'merged' GeoDataFrame contains points from gdf_isd that are within the buffer around points in gdf_asosawos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    merged\n",
    ")  # there are not ISD stations within 10km of an ASOSAWOS station missed by the exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Round asosawos down to 3 decimal points of accuracy\n",
    "# asosawos_round = asosawos_list.round({\"LAT\": 3, \"LON\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential ways to check that two stations are duplicates\n",
    "1. identical total_nobs\n",
    "2. identical ERA IDs\n",
    "3. identical end or start times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract flagged stations\n",
    "\n",
    "asosawos_dup = asosawos_out[~asosawos_out[\"concat_flag\"].isna()]\n",
    "valleywater_dup = valleywater_out[~valleywater_out[\"concat_flag\"].isna()]\n",
    "maritime_dup = maritime_out[~maritime_out[\"concat_flag\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_check(station_list):\n",
    "    \"\"\"\n",
    "    This function flags stations that are potentially duplicates\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) Within stations flagged for concatenation, stations are flagged as potential duplicates\n",
    "            if either their start or end times are identical\n",
    "            - TODO: brainstorm alternative approaches\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        station_list: pd.DataFrame\n",
    "            list of station information that has passed through the concatenation check\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            new_station_list: pd.DataFrame\n",
    "\n",
    "\n",
    "        if failure:\n",
    "            None\n",
    "    Notes\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    ##### flag stations with repeat end or start times\n",
    "\n",
    "    time_end_list = [\"end_time\", \"end-date\"]\n",
    "    time_start_list = [\"start_time\", \"start-date\"]\n",
    "\n",
    "    end_time_or_date = [col for col in station_list.columns if col in time_var_list]\n",
    "\n",
    "    new_station_list = (\n",
    "        new_station_list.groupby(\"concat_flag\")\n",
    "        .apply(lambda x: x.sort_values(end_time_or_date))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return new_station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_target_stations_old(network_name, station_old, station_new):\n",
    "    \"\"\"\n",
    "    Concatenates two input datasets, deletes the originals, and exports the final concatenated dataset\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "        station_old: string\n",
    "            name of the older weather station\n",
    "        station_new: string\n",
    "            name of the newer weather station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "    # Import target datasets and convert to dataframe\n",
    "    old_url = \"s3://wecc-historical-wx/4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, station_old\n",
    "    )\n",
    "    new_url = \"s3://wecc-historical-wx/4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, station_new\n",
    "    )\n",
    "\n",
    "    ds_old = xr.open_zarr(old_url)\n",
    "    ds_new = xr.open_zarr(new_url)\n",
    "\n",
    "    df_old = ds_old.to_dataframe()\n",
    "    df_new = ds_new.to_dataframe()\n",
    "\n",
    "    # Apply reset index only to 'time', as we will need that for concatenation\n",
    "    df_old = df_old.reset_index(level=\"time\")\n",
    "    df_new = df_new.reset_index(level=\"time\")\n",
    "\n",
    "    ##### Split datframes into subsets #####\n",
    "\n",
    "    # Remove data in time overlap between old and new\n",
    "    df_old_cleaned = df_old[~df_old[\"time\"].isin(df_new[\"time\"])]\n",
    "    df_new_cleaned = df_new[~df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    # Data in new input that overlaps in time with old input\n",
    "    df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    # Set index to new input for df_old_cleaned\n",
    "    # We want the final dataset to show up as the new station, not the old\n",
    "    final_station_name = \"{}_{}\".format(network_name, station_new)\n",
    "    new_index = [final_station_name] * len(df_old_cleaned)\n",
    "\n",
    "    df_old_cleaned.index = new_index\n",
    "    df_old_cleaned.index.name = \"station\"\n",
    "\n",
    "    ##### Concatenate subsets #####\n",
    "\n",
    "    df_concat = concat([df_old_cleaned, df_overlap, df_new_cleaned])\n",
    "\n",
    "    # Add 'time' back into multi index\n",
    "    df_concat.set_index(\"time\", append=True, inplace=True)\n",
    "\n",
    "    # Convert concatenated dataframe to dataset\n",
    "    ds_concat = df_concat.to_xarray()\n",
    "\n",
    "    ##### Update attributes and datatypes #####\n",
    "\n",
    "    # Include past attributes\n",
    "    ds_concat.attrs = ds_new.attrs\n",
    "\n",
    "    # Update 'history' attribute\n",
    "    timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "    ds_concat.attrs[\"history\"] = ds_new.attrs[\n",
    "        \"history\"\n",
    "    ] + \" \\nmaritime_merge.ipynb run on {} UTC\".format(timestamp)\n",
    "\n",
    "    # Update 'comment' attribute\n",
    "    ds_concat.attrs[\"comment\"] = (\n",
    "        \"Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.\"\n",
    "    )\n",
    "\n",
    "    # Add new qaqc_files_merged attribute\n",
    "    ds_concat.attrs[\"qaqc_files_merged\"] = (\n",
    "        \"{}_{}, {}_{} merged. Overlap retained from newer station data.\".format(\n",
    "            network_name, station_old, network_name, station_new\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Convert all datatypes, to enable export\n",
    "    existing_float32 = [col for col in float32_variables if col in df_concat.columns]\n",
    "    existing_U16 = [col for col in U16_variables if col in df_concat.columns]\n",
    "\n",
    "    ds_concat[existing_float32] = ds_concat[existing_float32].astype(\"float32\")\n",
    "    ds_concat[existing_U16] = ds_concat[existing_U16].astype(\"U16\")\n",
    "\n",
    "    ds_concat.coords[\"station\"] = ds_concat.coords[\"station\"].astype(\"<U16\")\n",
    "\n",
    "    ### Export ###\n",
    "\n",
    "    # delete old inputs\n",
    "    bucket = \"wecc-historical-wx\"\n",
    "    key_new = \"4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, station_new\n",
    "    )\n",
    "    key_old = \"4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, station_old\n",
    "    )\n",
    "\n",
    "    delete_folder(bucket, key_new)\n",
    "    delete_folder(bucket, key_old)\n",
    "\n",
    "    # Export final, concatenated dataset\n",
    "    export_url = \"s3://wecc-historical-wx/4_merge_wx/{}_dev/{}_{}.zarr\".format(\n",
    "        network_name, network_name, \"test\"\n",
    "    )\n",
    "    ds_concat.to_zarr(export_url, mode=\"w\")\n",
    "\n",
    "    return None  # ds_concat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
