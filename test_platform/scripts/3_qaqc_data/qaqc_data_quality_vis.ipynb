{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db21933",
   "metadata": {},
   "source": [
    "# Data Quality Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac418aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "\n",
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "BUCKET_NAME = \"wecc-historical-wx\"\n",
    "QAQC_DIR = \"3_qaqc_wx\"\n",
    "MERGE_DIR = \"4_merge_wx\"\n",
    "stations_csv_path = f\"s3://{BUCKET_NAME}/{QAQC_DIR}/all_network_stationlist_qaqc.csv\"\n",
    "shapepath = \"s3://wecc-historical-wx/0_maps/tl_2021_us_state\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134762f",
   "metadata": {},
   "source": [
    "## Final functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d55c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_rate(flag_df: pd.DataFrame, running_rate_df, station_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates flag rates dataframe for input flag counts dataframe and then adds it to the running flag rate dataframe.\n",
    "    Helper function for network_rate_tables() and station_rate_table().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df: pd.DataFrame\n",
    "        flag rates dataframe for next station\n",
    "    running_rate_df: pd.DataFrame\n",
    "        dataframe of previously added station flag rates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rates_df_merged: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    # Make the eraqc_flag_values column the index\n",
    "    flag_df = flag_df.set_index(\"eraqc_flag_values\")\n",
    "\n",
    "    # Count up the flagged observations - so counts in all but the \"no_flag\" and \"total_obs_count\" rows\n",
    "    subset = flag_df[~flag_df.index.isin([\"no_flag\", \"total_obs_count\"])]\n",
    "    totals = subset.sum(numeric_only=True)\n",
    "    flag_df.loc[\"total_flag\"] = pd.Series(totals)\n",
    "\n",
    "    # And then use those total to calculate the per-variable flag rates\n",
    "    frac = flag_df.loc[\"total_flag\"] / flag_df.loc[\"total_obs_count\"]\n",
    "    flag_df.loc[\"flag_rate\"] = pd.Series(frac)\n",
    "\n",
    "    # Keep only the rate\n",
    "    rates_df = flag_df.loc[[\"flag_rate\"]]\n",
    "    rates_df = rates_df.rename(index={\"flag_rate\": station_name})\n",
    "\n",
    "    rates_df = rates_df.reset_index()\n",
    "\n",
    "    # Finally, append column of total observation count\n",
    "    flag_df = flag_df.reset_index()\n",
    "    total_obs = flag_df[flag_df['eraqc_flag_values']=='total_obs_count'].iloc[0,1]\n",
    "    rates_df['total_obs_count'] = total_obs\n",
    "\n",
    "    if len(running_rate_df) == 0:\n",
    "        return rates_df\n",
    "\n",
    "    else:\n",
    "        rates_df_merged = pd.merge(rates_df, running_rate_df, how=\"outer\")\n",
    "        return rates_df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cc0c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_rate_tables(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Generates a table of flag rates per network and uploads it to AWS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup \n",
    "\n",
    "    # Only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # The function iteratively adds in flag counts to this dataframe\n",
    "    flag_rate_df = []\n",
    "\n",
    "    # Point to folder containing station flag count CSVs\n",
    "    flags_prefix = f\"{MERGE_DIR}/per_network_flag_counts_{timestep}_timestep\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # Loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(BUCKET_NAME).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=BUCKET_NAME, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        station_name = item.key.split(flags_prefix + \"/\")[1].split(\"_flag\")[0]\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # Remove \"QAQC_function\" and \"Flag_meaning\" columns - we don't need these\n",
    "            flags = flags.drop([\"QAQC_function\", \"Flag_meaning\"], axis=1)\n",
    "\n",
    "            # Send current dataframe and dataframe of previously generated rates to helper function\n",
    "            flag_rate_df = _pairwise_rate(flags, flag_rate_df, station_name)\n",
    "\n",
    "    # Change \"eraqc_flag_values\" to \"stations\"\n",
    "    flag_rate_df = flag_rate_df.rename(columns={\"eraqc_flag_values\": \"networks\"})\n",
    "\n",
    "    ## Send final flag rates file to AWS as CSV\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/network_{timestep}_flag_rates.csv\"\n",
    "    flag_rate_df.to_csv(csv_s3_filepath, index=False)\n",
    "    print(f\"Sending station flag rates CSV to: {csv_s3_filepath}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "635ec759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending station flag rates CSV to: s3://wecc-historical-wx/4_merge_wx/network_hourly_flag_rates.csv\n"
     ]
    }
   ],
   "source": [
    "network_rate_tables('hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44ef0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_rate_tables(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Generates a table of flag rates per station.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup \n",
    "    \n",
    "    # Only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # List of networks to iterate over\n",
    "    network_list = ['VCAPCD','CDEC']\n",
    "\n",
    "    # The function iteratively adds in flag counts to this dataframe\n",
    "    flag_rate_df = []\n",
    "\n",
    "    for network in network_list:\n",
    "        # Point to folder containing station flag count CSVs\n",
    "        flags_prefix = f\"{MERGE_DIR}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "\n",
    "        ## Merge flag counts\n",
    "\n",
    "        # Loop through all CSVs at the given level\n",
    "        for item in s3.Bucket(BUCKET_NAME).objects.filter(Prefix=flags_prefix):\n",
    "            obj = s3_cl.get_object(Bucket=BUCKET_NAME, Key=item.key)\n",
    "            flags = pd.read_csv(obj[\"Body\"])\n",
    "            station_name = item.key.split(flags_prefix + \"/\")[1].split(\"_flag\")[0]\n",
    "            # the CSV is empty\n",
    "            if flags.empty:\n",
    "                continue\n",
    "            # the CSV is not empty\n",
    "            else:\n",
    "                # Send current dataframe and dataframe of previously generated rates to helper function\n",
    "                flag_rate_df = _pairwise_rate(flags, flag_rate_df, station_name)\n",
    "\n",
    "        # Change \"eraqc_flag_values\" to \"stations\"\n",
    "        flag_rate_df = flag_rate_df.rename(columns={\"eraqc_flag_values\": \"networks\"})\n",
    "\n",
    "        ## Send final flag rates file to AWS as CSV\n",
    "        csv_s3_filepath = (\n",
    "            f\"s3://wecc-historical-wx/4_merge_wx/station_{timestep}_flag_rates.csv\"\n",
    "        )\n",
    "        flag_rate_df.to_csv(csv_s3_filepath, index=False)\n",
    "        print(f\"Sending network flag rates CSV to: {csv_s3_filepath}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2282d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rate_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15975c6d",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417d101",
   "metadata": {},
   "source": [
    "### Merge with station list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95120f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = pd.read_csv(stations_csv_path)\n",
    "sub_station_list = station_list[station_list['network']==network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a67196",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = sub_station_list.merge(flag_rate_df, on=\"era-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_list = merged_list\n",
    "\n",
    "# Format dates in datetime format (this gets lost in import).\n",
    "map_list[\"start-date\"] = pd.to_datetime(map_list[\"start-date\"], utc=True)\n",
    "map_list[\"end-date\"] = pd.to_datetime(map_list[\"end-date\"], utc=True)\n",
    "\n",
    "# Make a geodataframe.\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    map_list,\n",
    "    geometry=gpd.points_from_xy(map_list.longitude, map_list.latitude),\n",
    ")\n",
    "gdf.set_crs(epsg=4326, inplace=True)  # Set CRS\n",
    "\n",
    "# Project data to match base tiles.\n",
    "gdf_wm = gdf.to_crs(epsg=3857)  # Web mercator\n",
    "\n",
    "# Read in geometry of continental US.\n",
    "us = gpd.read_file(shapepath)\n",
    "\n",
    "# Remove territories, AK, HI\n",
    "rem_list = [\"HI\", \"AK\", \"MP\", \"GU\", \"AS\", \"PR\", \"VI\"]\n",
    "us = us.loc[us.STUSPS.isin(rem_list) == False]\n",
    "\n",
    "# Use to clip stations\n",
    "us = us.to_crs(epsg=3857)\n",
    "gdf_us = gdf_wm.clip(us)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "ax = gdf_us.plot(\n",
    "    \"tas\",\n",
    "    figsize=(15, 15),\n",
    "    alpha=1,\n",
    "    markersize=3,\n",
    "    legend=True,\n",
    "    cmap=\"nipy_spectral\",\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "ax.set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
