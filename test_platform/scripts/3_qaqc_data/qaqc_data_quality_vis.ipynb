{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db21933",
   "metadata": {},
   "source": [
    "# Data Quality Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac418aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "\n",
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "BUCKET_NAME = \"wecc-historical-wx\"\n",
    "QAQC_DIR = \"3_qaqc_wx\"\n",
    "MERGE_DIR = \"4_merge_wx\"\n",
    "stations_csv_path = f\"s3://{BUCKET_NAME}/{QAQC_DIR}/all_network_stationlist_qaqc.csv\"\n",
    "shapepath = \"s3://wecc-historical-wx/0_maps/tl_2021_us_state\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f79065",
   "metadata": {},
   "source": [
    "## Station-wise flag rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_flag_path = f\"s3://{BUCKET_NAME}/{MERGE_DIR}/ASOSAWOS/eraqc_counts_native_timestep/ASOSAWOS_A0705300346_flag_counts_native_timestep.csv\"\n",
    "flag_df_1_hello = pd.read_csv(network_flag_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdafe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_flag_path_2 = f\"s3://{BUCKET_NAME}/{MERGE_DIR}/ASOSAWOS/eraqc_counts_native_timestep/ASOSAWOS_A0685400115_flag_counts_native_timestep.csv\"\n",
    "flag_df_2_hello = pd.read_csv(network_flag_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964788da",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_df_1_hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_df_2_hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_df_1 = flag_df_1_hello.set_index(\"eraqc_flag_values\")\n",
    "subset = flag_df_1[~flag_df_1.index.isin([\"no_flag\", \"total_obs_count\"])]\n",
    "\n",
    "totals = subset.sum(numeric_only=True)\n",
    "flag_df_1.loc[\"total_flag\"] = pd.Series(totals)\n",
    "\n",
    "frac = flag_df_1.loc[\"total_flag\"] / flag_df_1.loc[\"total_obs_count\"]\n",
    "flag_df_1.loc[\"frac\"] = pd.Series(frac)\n",
    "\n",
    "rates_df = flag_df_1.loc[[\"frac\"]]\n",
    "rates_df = rates_df.rename(index={\"frac\": 'station_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d87931",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_df_2 = flag_df_2_hello.set_index(\"eraqc_flag_values\")\n",
    "subset_2 = flag_df_2[~flag_df_2.index.isin([\"no_flag\", \"total_obs_count\"])]\n",
    "\n",
    "totals = subset_2.sum(numeric_only=True)\n",
    "flag_df_2.loc[\"total_flag\"] = pd.Series(totals)\n",
    "\n",
    "frac_2= flag_df_2.loc[\"total_flag\"] / flag_df_2.loc[\"total_obs_count\"]\n",
    "flag_df_2.loc[\"frac\"] = pd.Series(frac_2)\n",
    "\n",
    "rates_df_2 = flag_df_2.loc[[\"frac\"]]\n",
    "rates_df_2 = rates_df_2.rename(index={\"frac\": \"station_name_2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df = rates_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ed8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df_2 = rates_df_2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(rates_df,rates_df_2, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6957fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_flag_path_3 = f\"s3://{BUCKET_NAME}/{MERGE_DIR}/ASOSAWOS/eraqc_counts_native_timestep/ASOSAWOS_99999994176_flag_counts_native_timestep.csv\"\n",
    "flag_df_3_hello = pd.read_csv(network_flag_path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82577523",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_name = network_flag_path.split(f\"s3://{BUCKET_NAME}/{MERGE_DIR}/ASOSAWOS/eraqc_counts_native_timestep\" + \"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5361b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_obs = rates_df_2[flag_df_1_hello['eraqc_flag_values']=='total_obs_count'].iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3222620",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df[\"total_obs_count\"] = total_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47387fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d55c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_rate(flag_df_1: pd.DataFrame, flag_df_2: pd.DataFrame,station_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df_1: pd.DataFrame\n",
    "        dataframe of previously summed station flag counts\n",
    "    flag_df_2: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summed_df: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    flag_df_1 = flag_df_1.set_index(\"eraqc_flag_values\")\n",
    "    subset = flag_df_1[~flag_df_1.index.isin([\"no_flag\", \"total_obs_count\"])]\n",
    "\n",
    "    totals = subset.sum(numeric_only=True)\n",
    "    flag_df_1.loc[\"total_flag\"] = pd.Series(totals)\n",
    "\n",
    "    frac = flag_df_1.loc[\"total_flag\"] / flag_df_1.loc[\"total_obs_count\"]\n",
    "    flag_df_1.loc[\"frac\"] = pd.Series(frac)\n",
    "\n",
    "    rates_df = flag_df_1.loc[[\"frac\"]]\n",
    "    rates_df = rates_df.rename(index={\"frac\": station_name})\n",
    "\n",
    "    rates_df = rates_df.reset_index()\n",
    "\n",
    "    # append column of total observation count\n",
    "    flag_df_1 = flag_df_1.reset_index()\n",
    "    total_obs = flag_df_1[flag_df_1['eraqc_flag_values']=='total_obs_count'].iloc[0,1]\n",
    "    rates_df['total_obs_count'] = total_obs\n",
    "\n",
    "    if len(flag_df_2) == 0:\n",
    "        return rates_df\n",
    "\n",
    "    else:\n",
    "        rates_df_merge = pd.merge(rates_df, flag_df_2, how=\"outer\")\n",
    "        return rates_df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0241285",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"VCAPCD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd74f82",
   "metadata": {},
   "source": [
    "vectorization, column-wise computation\n",
    "\n",
    "include \"total counts\" column, counts for each station (can be referenced later)\n",
    "\n",
    "use append for the station-wise rate tables\n",
    "merge (?) for network-wise rate tables -> will take care of this for you\n",
    "- if use append, would need to be exlicit about how to handle new columns (tell it to fill with NAs) -> perhaps more control\n",
    "\n",
    "=> using merge for a single row should not be necessary\n",
    "\n",
    "2D data may not be sufficient anymore\n",
    "- we'll have x num of different variable names\n",
    "\n",
    "\n",
    "include station type in map (buoy vs land (airport, mountain, etc.)) -> point shape\n",
    "\n",
    "\n",
    "go with sparse dataframe, with total counts included (ie merge)\n",
    "\n",
    "\n",
    "color = flag rate\n",
    "point size = total obs count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function iteratively adds in flag counts to this dataframe\n",
    "flag_rate_df = []\n",
    "\n",
    "# point to folder containing station flag count CSVs\n",
    "flags_prefix = f\"{MERGE_DIR}/{network}/eraqc_counts_native_timestep\"  # /per_network_flag_counts_native_timestep/\"\n",
    "\n",
    "## Merge flag counts\n",
    "\n",
    "# loop through all CSVs are the given level\n",
    "for item in s3.Bucket(BUCKET_NAME).objects.filter(Prefix=flags_prefix):\n",
    "    obj = s3_cl.get_object(Bucket=BUCKET_NAME, Key=item.key)\n",
    "    flags = pd.read_csv(obj[\"Body\"])\n",
    "    station_name = item.key.split(flags_prefix + \"/\")[1].split(\"_flag\")[0]\n",
    "    # the CSV is empty\n",
    "    if flags.empty:\n",
    "        continue\n",
    "    # the CSV is not empty\n",
    "    else:\n",
    "        # send current dataframe and dataframe of previously summed counts to helper function\n",
    "        flag_rate_df = _pairwise_rate(flags, flag_rate_df,station_name)\n",
    "# print(station_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_rate_df = flag_rate_df.rename(columns={\"eraqc_flag_values\": \"era-id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f89f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_rate_df = flag_rate_df.drop(\"elevation\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_rate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417d101",
   "metadata": {},
   "source": [
    "### Merge with station list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95120f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = pd.read_csv(stations_csv_path)\n",
    "sub_station_list = station_list[station_list['network']==network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a67196",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = sub_station_list.merge(flag_rate_df, on=\"era-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d661597",
   "metadata": {},
   "source": [
    "next steps: extract station name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62862de",
   "metadata": {},
   "source": [
    "## Network-wise flag rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ffec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_flag_path_ = f\"s3://{BUCKET_NAME}/{MERGE_DIR}/per_network_flag_counts_native_timestep/VCAPCD_flag_counts_native_timestep.csv\"\n",
    "flag_df = pd.read_csv(network_flag_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function iteratively adds in flag counts to this dataframe\n",
    "flag_rate_df = []\n",
    "\n",
    "# point to folder containing station flag count CSVs\n",
    "flags_prefix = f\"{MERGE_DIR}/per_network_flag_counts_native_timestep\"\n",
    "\n",
    "## Merge flag counts\n",
    "\n",
    "# loop through all CSVs are the given level\n",
    "for item in s3.Bucket(BUCKET_NAME).objects.filter(Prefix=flags_prefix):\n",
    "    obj = s3_cl.get_object(Bucket=BUCKET_NAME, Key=item.key)\n",
    "    flags = pd.read_csv(obj[\"Body\"])\n",
    "    station_name = item.key.split(flags_prefix + \"/\")[1].split(\"_flag\")[0]\n",
    "    # the CSV is empty\n",
    "    if flags.empty:\n",
    "        continue\n",
    "    # the CSV is not empty\n",
    "    else:\n",
    "        # send current dataframe and dataframe of previously summed counts to helper function\n",
    "        flag_rate_df = _pairwise_rate(flags, flag_rate_df, station_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_rate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134762f",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_rate_tables(level:str) -> None:\n",
    "    \"\"\"\n",
    "    Generates flag rates tables at either the station or network level.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df_1: pd.DataFrame\n",
    "        dataframe of previously summed station flag counts\n",
    "    flag_df_2: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summed_df: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    flag_rate_df = []\n",
    "\n",
    "    # point to folder containing station flag count CSVs\n",
    "    flags_prefix = f\"{MERGE_DIR}/per_network_flag_counts_native_timestep\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(BUCKET_NAME).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=BUCKET_NAME, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        station_name = item.key.split(flags_prefix + \"/\")[1].split(\"_flag\")[0]\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            flag_rate_df = _pairwise_rate(flags, flag_rate_df, station_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15975c6d",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_list = merged_list\n",
    "\n",
    "# Format dates in datetime format (this gets lost in import).\n",
    "map_list[\"start-date\"] = pd.to_datetime(map_list[\"start-date\"], utc=True)\n",
    "map_list[\"end-date\"] = pd.to_datetime(map_list[\"end-date\"], utc=True)\n",
    "\n",
    "# Make a geodataframe.\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    map_list,\n",
    "    geometry=gpd.points_from_xy(map_list.longitude, map_list.latitude),\n",
    ")\n",
    "gdf.set_crs(epsg=4326, inplace=True)  # Set CRS\n",
    "\n",
    "# Project data to match base tiles.\n",
    "gdf_wm = gdf.to_crs(epsg=3857)  # Web mercator\n",
    "\n",
    "# Read in geometry of continental US.\n",
    "us = gpd.read_file(shapepath)\n",
    "\n",
    "# Remove territories, AK, HI\n",
    "rem_list = [\"HI\", \"AK\", \"MP\", \"GU\", \"AS\", \"PR\", \"VI\"]\n",
    "us = us.loc[us.STUSPS.isin(rem_list) == False]\n",
    "\n",
    "# Use to clip stations\n",
    "us = us.to_crs(epsg=3857)\n",
    "gdf_us = gdf_wm.clip(us)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "ax = gdf_us.plot(\n",
    "    \"tas\",\n",
    "    figsize=(15, 15),\n",
    "    alpha=1,\n",
    "    markersize=3,\n",
    "    legend=True,\n",
    "    cmap=\"nipy_spectral\",\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "ax.set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
