{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ee035f",
   "metadata": {},
   "source": [
    "Motivation: individual gross outliers from general station distribution are a common error in obs data by random recording, reporting, formatting, or instrumentation errors\n",
    "\n",
    "Process:\n",
    "1. uses individual observation deviations derived from monthly mean climatology calculated for each hour of the day\n",
    "2. climatologies calculated using winsorised data to remove initial effect of outliers\n",
    "    - Winsorising: all values beyond threhsold value from mean are set to that threshold value\n",
    "    - 5 and 95% for hadisd\n",
    "    - number of data values in population remains the same, not trimmed\n",
    "3. raw unwinsorised observations are anomalised using these climatologies\n",
    "4. standardized by IQR for that month and hour\n",
    "    - IQR cannot be less than 1.5degC\n",
    "5. values are low-pass filtered to remove any climate change signal causing overzealous removal at ends of time series\n",
    "6. gaussian is fitted to the histogram of anomalies for each month\n",
    "7. threshold value, rounded outwards where crosses y=0.1 line\n",
    "8. distribution beyond threhsold value is scanned for gap, equal to bin width or more\n",
    "9. all values beyond gap are flagged\n",
    "10. obs that fall between critical threshold value and gap or critical threshold and end of distribution are tentatively flagged\n",
    "    - these may be later reinstated on comparison with good data from neighboring stations\n",
    "\n",
    "Notes:\n",
    "- when applied to SLP, frequently flags storm signals, which may be of high interest, so this test is not applied to pressure data\n",
    "- hadisd only applies to temp and dewpoint temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92465473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e1ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victoriaford/anaconda3/envs/histobs/lib/python3.11/site-packages/pandas/core/arrays/timedeltas.py:908: RuntimeWarning: invalid value encountered in cast\n",
      "  base = data.astype(np.int64)\n",
      "/Users/victoriaford/anaconda3/envs/histobs/lib/python3.11/site-packages/pandas/core/arrays/timedeltas.py:912: RuntimeWarning: invalid value encountered in cast\n",
      "  data = (base * m + (frac * m).astype(np.int64)).view(\"timedelta64[ns]\")\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset('/Users/victoriaford/Desktop/eaglerock/Historical Data Platform/Train_Files/ASOSAWOS_72051724165.nc')\n",
    "\n",
    "df = ds.to_dataframe()\n",
    "# df = df.reset_index()\n",
    "# df['month'] = pd.to_datetime(df['time']).dt.month # sets month to new variable\n",
    "# df['year'] = pd.to_datetime(df['time']).dt.year # sets year to new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48eba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clim_mon_mean_hourly(df, var, month, hour):\n",
    "    '''Calculate the monthly mean climatology for each of the day'''\n",
    "    \n",
    "    df_m_h = df.loc[(df.time.dt.month == month) & (df.time.dt.hour == hour)]\n",
    "    clim_value = df_m_h[var].mean(numeric_only = True)\n",
    "    \n",
    "    # special handling if value is nan? \n",
    "    \n",
    "    return clim_value\n",
    "\n",
    "def iqr_range_monhour(df, var, month, hour):\n",
    "    '''Calculates the monthly interquartile range per hour'''\n",
    "    \n",
    "    q1 = df.loc[(df.time.dt.month == month) & (df.time.dt.hour == hour)].quantile(0.25, numeric_only=True)\n",
    "    q3 = df.loc[(df.time.dt.month == month) & (df.time.dt.hour == hour)].quantile(0.75, numeric_only=True)\n",
    "    \n",
    "    iqr_df = q3 - q1\n",
    "    iqr_df_val = iqr_df[var]\n",
    "    \n",
    "    # iqr cannot be less than 1.5Â°C in order to preserve low variance stations\n",
    "    if iqr_df_val < 1.5:\n",
    "        iqr_df_val = 1.5\n",
    "    else:\n",
    "        iqr_df_val = iqr_df_val\n",
    "            \n",
    "    return iqr_df_val\n",
    "\n",
    "\n",
    "def clim_standardized_anom(df, vars_to_anom):\n",
    "    '''\n",
    "    First anomalizes data by monthly climatology for each hour, then\n",
    "    standardizes by the monthly climatological anomaly IQR for each hour\n",
    "    '''\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for var in vars_to_anom:\n",
    "        for m in range(1,13,1):\n",
    "            for h in range(0,24,1):\n",
    "                # each hour in each month\n",
    "                anom_value = clim_mon_mean_hourly(df, var, month=m, hour=h)\n",
    "                iqr_value = iqr_range_monhour(df, var, month=m, hour=h)\n",
    "                \n",
    "                # locate obs within specific month/hour\n",
    "                df_m_h = df.loc[(df.time.dt.month == m) & (df.time.dt.hour == h)]\n",
    "                \n",
    "                # calculate the monthly climatological anomaly by hour and standardize by iqr\n",
    "                df2.loc[(df.time.dt.month == m) & \n",
    "                        (df.time.dt.hour == h), \n",
    "                        var] = (df_m_h[var] - anom_value) / iqr_value\n",
    "                \n",
    "    return df2\n",
    "\n",
    "def winsorize_temps(df, vars_to_anom, winz_limits):\n",
    "    '''\n",
    "    Replaces potential spurious outliers by limiting the extreme values\n",
    "    using the winz_limits set (default is 5% and 95% percentiles)\n",
    "    '''\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for var in vars_to_anom:\n",
    "        for m in range(1,13,1):\n",
    "            for h in range(0,24,1):\n",
    "                \n",
    "                df_m_h = df.loc[(df.time.dt.month == m) & (df.time.dt.hour == h)]\n",
    "                \n",
    "                # winsorize only vars in vars_to_anom\n",
    "                df_w = winsorize(df_m_h[var], limits=winz_limits, nan_policy='omit')\n",
    "                \n",
    "                df2.loc[(df.time.dt.month == m) & (df.time.dt.hour == h),\n",
    "                       var] = df_w\n",
    "                \n",
    "    return df2\n",
    "\n",
    "def median_yr_anom(df, var):\n",
    "    '''Get median anomaly per year'''\n",
    "    \n",
    "    monthly_anoms = []\n",
    "    \n",
    "    # identify years in data\n",
    "    years = df.time.dt.year.unique()\n",
    "    \n",
    "    for yr in years:\n",
    "        df_yr = df.loc[df.time.dt.year == yr]\n",
    "\n",
    "        ann_anom = df_yr[var].median()\n",
    "        monthly_anoms.append(ann_anom)\n",
    "        \n",
    "    return monthly_anoms\n",
    "\n",
    "def low_pass_filter_weights(median_anoms, month_low, month_high, filter_low, filter_high):\n",
    "    '''Calculates weights for low pass filter'''\n",
    "    \n",
    "    filter_wgts = [1, 2, 3, 2, 1]\n",
    "    \n",
    "    if np.sum(filter_wgts[filter_low:filter_high] * \n",
    "              np.ceil(median_anoms[month_low:month_high] - \n",
    "                      np.floor(median_anoms[month_low:month_high]))) == 0:\n",
    "        weight = 0\n",
    "    \n",
    "    else:\n",
    "        weight = (\n",
    "            np.sum(filter_wgts[filter_low:filter_high] * np.ceil(median_anoms[month_low:month_high])) / \n",
    "            np.sum(filter_wgts[filter_low:filter_high] * np.ceil(median_anoms[month_low:month_high] - \n",
    "                                                                 np.floor(median_anoms[month_low:month_high])))\n",
    "        )\n",
    "        \n",
    "    return weight\n",
    "\n",
    "def low_pass_filter(df, vars_to_anom):\n",
    "    '''\n",
    "    Low pass filtering on observations to remove any climate change signal \n",
    "    causing overzealous removal at ends of time series\n",
    "    '''\n",
    "    # identify years in data\n",
    "    years = df.time.dt.year.unique()\n",
    "    \n",
    "    for var in vars_to_anom:\n",
    "        \n",
    "        median_anoms = median_yr_anom(df, var)\n",
    "    \n",
    "        for yr in range(len(years)):\n",
    "            if yr == 0:\n",
    "                month_low, month_high = 0, 3\n",
    "                filter_low, filter_high = 2, 5\n",
    "                \n",
    "            elif yr == 1:\n",
    "                month_low, month_high = 0, 4\n",
    "                filter_low, filter_high = 1, 5\n",
    "                \n",
    "            elif yr == len(years)-2:\n",
    "                month_low, month_high = -4, -1\n",
    "                filter_low, filter_high = 0, 3\n",
    "\n",
    "            elif yr == len(years)-1:\n",
    "                month_low, month_high = -3, -1\n",
    "                filter_low, filter_high = 0, 2\n",
    "\n",
    "            else:\n",
    "                month_low, month_high = yr-2, yr+3\n",
    "                filter_low, filter_high = 0, 5\n",
    "                            \n",
    "            if np.sum(np.abs(median_anoms[month_low:month_high])) != 0:\n",
    "                weights = low_pass_filter_weights(median_anoms, month_low, month_high, filter_low, filter_high)\n",
    "                      \n",
    "            # want to return specific year of data at a specific variable, the variable minus weight value\n",
    "            df.loc[(df.time.dt.year == years[yr]), var] = df.loc[df.time.dt.year == years[yr]][var] - weights\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "## distribution gap plotting helpers\n",
    "def create_bins(data, bin_size=0.25):\n",
    "    '''Create bins from data covering entire data range'''\n",
    "\n",
    "    # set up bins\n",
    "    b_min = np.floor(np.nanmin(data))\n",
    "    b_max = np.ceil(np.nanmax(data))\n",
    "    bins = np.arange(b_min - bin_size, b_max + (3. * bin_size), bin_size)\n",
    "\n",
    "    return bins\n",
    "\n",
    "def pdf_bounds(df, mu, sigma, bins):\n",
    "    '''Calculate pdf distribution, return pdf and threshold bounds'''\n",
    "\n",
    "    y = stats.norm.pdf(bins, mu, sigma)\n",
    "    \n",
    "    # add vertical lines to indicate thresholds where pdf y=0.1\n",
    "    pdf_bounds = np.argwhere(y > 0.1)\n",
    "\n",
    "    # find first index\n",
    "    left_bnd = round(bins[pdf_bounds[0][0] -1])\n",
    "    right_bnd = round(bins[pdf_bounds[-1][0] + 1])\n",
    "    thresholds = (left_bnd - 1, right_bnd + 1)\n",
    "    \n",
    "    return (y, left_bnd - 1, right_bnd + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbbb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clim_outlier_plot(df, var, month, network):\n",
    "    '''\n",
    "    Produces a histogram of monthly standardized distribution\n",
    "    with PDF overlay and threshold lines where pdf falls below y=0.1.\n",
    "    Any bin that is outside of the threshold is visually flagged.\n",
    "    \n",
    "    Differs from dist_gap_part2_plot for the climatological outlier\n",
    "    as IQR standardization does not occur within plotting\n",
    "    '''\n",
    "    \n",
    "    # select month\n",
    "    df = df.loc[df.time.dt.month == month]\n",
    "    \n",
    "    # determine number of bins\n",
    "    bins = create_bins(df)\n",
    "    \n",
    "    # plot histogram\n",
    "    ax = plt.hist(df, bins=bins, log=False, density=True, alpha=0.3)\n",
    "    xmin, xmax = plt.xlim()\n",
    "    plt.ylim(ymin=0.1)\n",
    "    \n",
    "    # plot pdf\n",
    "    mu = np.nanmean(df)\n",
    "    sigma = np.nanmean(df)\n",
    "    y = stats.norm.pdf(bins, mu, sigma)\n",
    "    l = plt.plot(bins, y, 'k--', linewidth=1)\n",
    "    \n",
    "    # add vertical lines to indicate thresholds where pdf y=0.1\n",
    "    pdf_bounds = np.argwhere(y > 0.1)\n",
    "    \n",
    "    # find first index\n",
    "    left_bnd = round(bins[pdf_bounds[0][0] - 1])\n",
    "    right_bnd = round(bins[pdf_bounds[-1][0] + 1])\n",
    "    thresholds = (left_bnd - 1, right_bnd + 1)\n",
    "    \n",
    "    plt.axvline(thresholds[1], color='r') # right tail\n",
    "    plt.axvline(thresholds[0], color='r') # left tail\n",
    "    \n",
    "    # flag visually obs that are beyond threshold\n",
    "    for bar in ax[2].patches:\n",
    "        x = bar.get_x() + 0.5 * bar.get_width()\n",
    "        if x > thresholds[1]: # right tail\n",
    "            bar.set_color('r')\n",
    "        elif x < thresholds[0]: # left tail\n",
    "            bar.set_color('r')\n",
    "            \n",
    "    # title and useful annotations\n",
    "    plt.title('Climatological outlier check, {0}: {1}'.format(df['station'].unique()[0], var), fontsize=10);\n",
    "    plt.annotate('Month: {}'.format(month), xy=(0.025, 0.95), xycoords='axes fraction', fontsize=8);\n",
    "    plt.annotate('Mean: {}'.format(round(mu,3)), xy=(0.025, 0.9), xycoords='axes fraction', fontsize=8);\n",
    "    plt.annotate('Std.Dev: {}'.format(round(sigma,3)), xy=(0.025, 0.85), xycoords='axes fraction', fontsize=8);\n",
    "    plt.ylabel('Frequency (obs)')\n",
    "    \n",
    "    # save figure to AWS\n",
    "    bucket_name = 'wecc-historical-wx'\n",
    "    directory = '3_qaqc_wx'\n",
    "    img_data = BytesIO()\n",
    "    plt.savefig(img_data, format='png')\n",
    "    img_data.seek(0)\n",
    "    \n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    figname = 'qaqc_climatological_outlier_{0}_{1}_{2}'.format(df['station'].unique()[0], var, month)\n",
    "    bucket.put_object(Body=img_data, ContentType='image/png',\n",
    "                     Key='{0}/{1}/qaqc_figs/{2}.png'.format(\n",
    "                     directory, network, figname))\n",
    "    \n",
    "    # close figures to save memory\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97a5967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaqc_climatological_outlier(df, winsorize=True, winz_limits=[0.05,0.05], plot=True, verbose=True):\n",
    "    '''\n",
    "    Flags individual gross outliers from climatological distribution.\n",
    "    Only applied to air temperature and dew point temperature\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "        df [pd.DataFrame]: station dataset converted to dataframe through QAQC pipeline\n",
    "        plots [bool]: if True, produces plots of any flagged data and saved to AWS\n",
    "        winsorize [bool]: if True, raw observations are winsorized to remove spurious outliers first\n",
    "        winz_limits [list]: if winsorize is True, values represent the low and high percentiles to standardize to\n",
    "            \n",
    "    Returns:\n",
    "    --------\n",
    "        qaqc success:\n",
    "            df [pd.DataFrame]: QAQC dataframe with flagged values (see below for flag meaning)\n",
    "        qaqc failure:\n",
    "            None\n",
    "            \n",
    "    Flag meaning:\n",
    "    -------------\n",
    "        25,qaqc_climatological_outlier,Value flagged as a climatological outlier\n",
    "    '''\n",
    "    \n",
    "    #### ONLY IN NOTEBOOK DEVELOPMENT, REMOVED IN CODE FOR PIPELINE #####\n",
    "    df = df.reset_index()\n",
    "    df['month'] = pd.to_datetime(df['time']).dt.month # sets month to new variable\n",
    "    df['year'] = pd.to_datetime(df['time']).dt.year # sets year to new variable  \n",
    "    \n",
    "    vars_to_check = ['tas', 'tdps', 'tdps_derived']\n",
    "    vars_to_anom = [v for v in vars_to_check if v in df.columns]\n",
    "    \n",
    "    ## ONLY IN NOTEBOOK FOR DEVELOPMENT\n",
    "    for var in vars_to_anom:      \n",
    "        df[var+'_eraqc'] = np.nan\n",
    "    \n",
    "    # TO DO: filter to only use non-flagged data\n",
    "\n",
    "    # winsorize data by percentiles\n",
    "    if winsorize == True:\n",
    "        df_std = winsorize_temps(df, vars_to_anom, winz_limits)\n",
    "    else:\n",
    "        df_std = df\n",
    "        \n",
    "    # standardize data by monthly climatological anomalies by hour\n",
    "    df_std = clim_standardized_anom(df_std, vars_to_anom)\n",
    "\n",
    "    # apply low pass filter\n",
    "    df_std = low_pass_filter(df_std, vars_to_anom)\n",
    "        \n",
    "    # gaussian is fitted to the histogram of anomalies for each month\n",
    "        # threshold value, rounded outwards where crosses y=0.1 line\n",
    "        # distribution beyond threhsold value is scanned for gap, equal to bin width or more\n",
    "        # all values beyond gap are flagged\n",
    "            # HadISD: obs that fall between critical threshold value and gap or \n",
    "            # critical threshold and end of distribution are tentatively flagged\n",
    "            # these may be later reinstated on comparison with good data from neighboring stations\n",
    "            # into v2 of data product\n",
    "            \n",
    "    for var in vars_to_anom:\n",
    "        \n",
    "        for month in range(1,13):\n",
    "            print('Searching for outliers in {0} in month {1}...'.format(var, month))\n",
    "            \n",
    "            df_m = df_std.loc[df_std.time.dt.month == month]\n",
    "            \n",
    "            # determine number of bins\n",
    "            bins = create_bins(df_m[var])\n",
    "\n",
    "            # pdf\n",
    "            mu = np.nanmean(df_m[var])\n",
    "            sigma = np.nanstd(df_m[var])\n",
    "\n",
    "            y, left_bnd, right_bnd = pdf_bounds(df_m[var], mu, sigma, bins)\n",
    "\n",
    "            # identify gaps as below y=0.1 from histogram, not pdf\n",
    "            y_hist, bins = np.histogram(df_m[var], bins=bins, density=True)\n",
    "            \n",
    "            # identify bin indices outside of thresholds and check if bin is above 0.1\n",
    "            bins_to_check = [i for i, n in enumerate(bins) if n <= left_bnd or n >= right_bnd][:-1] # remove last item due to # of bins exceeding hist by 1\n",
    "            if len(bins_to_check) != 0:\n",
    "                for b in bins_to_check:\n",
    "                    if y_hist[b] > 0.1:\n",
    "                        print('Flagging {0} bins in {1}'.format(len(b), var))\n",
    "                        # list of index of full df to flag, not standardized df\n",
    "                        idx_to_flag = [i for i in df_m.loc[(df[var] >= bins[b]) & (df2[var] < bins[b+1])].index]  \n",
    "                        df.loc[df.index == idx_to_flag, var+'_eraqc'] = 25 # see era_qaqc_flag_meanings.csv \n",
    "                \n",
    "    if plot == True:\n",
    "        for var in vars_to_anom:\n",
    "            if 25 in df[var+'_eraqc'].values: # only plot a figure if flag is present\n",
    "                clim_outlier_plot(df, var, network=df['station'].unique()[0])\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e67740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for outliers in tas in month 1...\n",
      "Searching for outliers in tas in month 2...\n",
      "Searching for outliers in tas in month 3...\n",
      "Searching for outliers in tas in month 4...\n",
      "Searching for outliers in tas in month 5...\n",
      "Searching for outliers in tas in month 6...\n",
      "Searching for outliers in tas in month 7...\n",
      "Searching for outliers in tas in month 8...\n",
      "Searching for outliers in tas in month 9...\n",
      "Searching for outliers in tas in month 10...\n",
      "Searching for outliers in tas in month 11...\n",
      "Searching for outliers in tas in month 12...\n",
      "Searching for outliers in tdps in month 1...\n",
      "Searching for outliers in tdps in month 2...\n",
      "Searching for outliers in tdps in month 3...\n",
      "Searching for outliers in tdps in month 4...\n",
      "Searching for outliers in tdps in month 5...\n",
      "Searching for outliers in tdps in month 6...\n",
      "Searching for outliers in tdps in month 7...\n",
      "Searching for outliers in tdps in month 8...\n",
      "Searching for outliers in tdps in month 9...\n",
      "Searching for outliers in tdps in month 10...\n",
      "Searching for outliers in tdps in month 11...\n",
      "Searching for outliers in tdps in month 12...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>ps</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "      <th>pr</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>elevation</th>\n",
       "      <th>qaqc_process</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_depth_qc</th>\n",
       "      <th>sfcWind_qc</th>\n",
       "      <th>sfcWind_method</th>\n",
       "      <th>sfcWind_dir_qc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>tas_eraqc</th>\n",
       "      <th>tdps_eraqc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 12:55:00</td>\n",
       "      <td>78690.0</td>\n",
       "      <td>284.45</td>\n",
       "      <td>277.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 13:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285.65</td>\n",
       "      <td>277.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.557</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 13:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287.05</td>\n",
       "      <td>278.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.557</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 13:55:00</td>\n",
       "      <td>78750.0</td>\n",
       "      <td>289.05</td>\n",
       "      <td>278.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 14:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289.95</td>\n",
       "      <td>278.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.557</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178389</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 20:15:00</td>\n",
       "      <td>78640.0</td>\n",
       "      <td>300.15</td>\n",
       "      <td>276.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178390</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 20:35:00</td>\n",
       "      <td>78580.0</td>\n",
       "      <td>301.15</td>\n",
       "      <td>279.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178391</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 20:55:00</td>\n",
       "      <td>78580.0</td>\n",
       "      <td>301.15</td>\n",
       "      <td>279.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178392</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 21:15:00</td>\n",
       "      <td>78530.0</td>\n",
       "      <td>301.15</td>\n",
       "      <td>279.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.3</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178393</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 21:35:00</td>\n",
       "      <td>78560.0</td>\n",
       "      <td>302.15</td>\n",
       "      <td>279.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>280.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178394 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     station                time       ps     tas    tdps  pr  \\\n",
       "0       ASOSAWOS_72051724165 2013-06-27 12:55:00  78690.0  284.45  277.95 NaN   \n",
       "1       ASOSAWOS_72051724165 2013-06-27 13:15:00      NaN  285.65  277.95 NaN   \n",
       "2       ASOSAWOS_72051724165 2013-06-27 13:35:00      NaN  287.05  278.15 NaN   \n",
       "3       ASOSAWOS_72051724165 2013-06-27 13:55:00  78750.0  289.05  278.65 NaN   \n",
       "4       ASOSAWOS_72051724165 2013-06-27 14:15:00      NaN  289.95  278.85 NaN   \n",
       "...                      ...                 ...      ...     ...     ...  ..   \n",
       "178389  ASOSAWOS_72051724165 2022-08-11 20:15:00  78640.0  300.15  276.15 NaN   \n",
       "178390  ASOSAWOS_72051724165 2022-08-11 20:35:00  78580.0  301.15  279.15 NaN   \n",
       "178391  ASOSAWOS_72051724165 2022-08-11 20:55:00  78580.0  301.15  279.15 NaN   \n",
       "178392  ASOSAWOS_72051724165 2022-08-11 21:15:00  78530.0  301.15  279.15 NaN   \n",
       "178393  ASOSAWOS_72051724165 2022-08-11 21:35:00  78560.0  302.15  279.15 NaN   \n",
       "\n",
       "        sfcWind  sfcWind_dir  elevation qaqc_process  ... pr_depth_qc  \\\n",
       "0           5.7        350.0     2220.0         V020  ...         NaN   \n",
       "1           5.7        350.0     2220.0         V020  ...         NaN   \n",
       "2           4.6        350.0     2220.0         V020  ...         NaN   \n",
       "3           4.6        350.0     2220.0         V020  ...         NaN   \n",
       "4           4.6        360.0     2220.0         V020  ...         NaN   \n",
       "...         ...          ...        ...          ...  ...         ...   \n",
       "178389      7.2        260.0     2220.0         V020  ...         NaN   \n",
       "178390      9.8        240.0     2220.0         V020  ...         NaN   \n",
       "178391      5.7        290.0     2220.0         V020  ...         NaN   \n",
       "178392     10.3        250.0     2220.0         V020  ...         NaN   \n",
       "178393      6.7        280.0     2220.0         V020  ...         NaN   \n",
       "\n",
       "        sfcWind_qc sfcWind_method sfcWind_dir_qc     lat      lon month  year  \\\n",
       "0                5              N              5  41.824 -110.556     6  2013   \n",
       "1                1              N              1  41.824 -110.557     6  2013   \n",
       "2                1              N              1  41.824 -110.557     6  2013   \n",
       "3                5              N              5  41.824 -110.556     6  2013   \n",
       "4                1              N              1  41.824 -110.557     6  2013   \n",
       "...            ...            ...            ...     ...      ...   ...   ...   \n",
       "178389           5              N              5  41.824 -110.556     8  2022   \n",
       "178390           5              N              5  41.824 -110.556     8  2022   \n",
       "178391           5              V              5  41.824 -110.556     8  2022   \n",
       "178392           5              N              5  41.824 -110.556     8  2022   \n",
       "178393           5              N              5  41.824 -110.556     8  2022   \n",
       "\n",
       "        tas_eraqc tdps_eraqc  \n",
       "0             NaN        NaN  \n",
       "1             NaN        NaN  \n",
       "2             NaN        NaN  \n",
       "3             NaN        NaN  \n",
       "4             NaN        NaN  \n",
       "...           ...        ...  \n",
       "178389        NaN        NaN  \n",
       "178390        NaN        NaN  \n",
       "178391        NaN        NaN  \n",
       "178392        NaN        NaN  \n",
       "178393        NaN        NaN  \n",
       "\n",
       "[178394 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = qaqc_climatological_outlier(df, plot=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0195f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>ps</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "      <th>pr</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>elevation</th>\n",
       "      <th>qaqc_process</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_depth_qc</th>\n",
       "      <th>sfcWind_qc</th>\n",
       "      <th>sfcWind_method</th>\n",
       "      <th>sfcWind_dir_qc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>tas_eraqc</th>\n",
       "      <th>tdps_eraqc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [station, time, ps, tas, tdps, pr, sfcWind, sfcWind_dir, elevation, qaqc_process, ps_qc, ps_altimeter, ps_altimeter_qc, psl_qc, tas_qc, tdps_qc, pr_qc, pr_duration, pr_depth_qc, sfcWind_qc, sfcWind_method, sfcWind_dir_qc, lat, lon, month, year, tas_eraqc, tdps_eraqc]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['tdps_eraqc'] == 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f0be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
