{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ee035f",
   "metadata": {},
   "source": [
    "Motivation: individual gross outliers from general station distribution are a common error in obs data by random recording, reporting, formatting, or instrumentation errors\n",
    "\n",
    "Process:\n",
    "1. uses individual observation deviations derived from monthly mean climatology calculated for each hour of the day\n",
    "2. climatologies calculated using winsorised data to remove initial effect of outliers\n",
    "    - Winsorising: all values beyond threhsold value from mean are set to that threshold value\n",
    "    - 5 and 95% for hadisd\n",
    "    - number of data values in population remains the same, not trimmed\n",
    "3. raw unwinsorised observations are anomalised using these climatologies\n",
    "4. standardized by IQR for that month and hour\n",
    "    - IQR cannot be less than 1.5degC\n",
    "5. values are low-pass filtered to remove any climate change signal causing overzealous removal at ends of time series\n",
    "6. gaussian is fitted to the histogram of anomalies for each month\n",
    "7. threshold value, rounded outwards where crosses y=0.1 line\n",
    "8. distribution beyond threhsold value is scanned for gap, equal to bin width or more\n",
    "9. all values beyond gap are flagged\n",
    "10. obs that fall between critical threshold value and gap or critical threshold and end of distribution are tentatively flagged\n",
    "    - these may be later reinstated on comparison with good data from neighboring stations\n",
    "\n",
    "Notes:\n",
    "- when applied to SLP, frequently flags storm signals, which may be of high interest, so this test is not applied to pressure data\n",
    "- hadisd only applies to temp and dewpoint temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92465473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1e1ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victoriaford/anaconda3/envs/histobs/lib/python3.11/site-packages/pandas/core/arrays/timedeltas.py:908: RuntimeWarning: invalid value encountered in cast\n",
      "  base = data.astype(np.int64)\n",
      "/Users/victoriaford/anaconda3/envs/histobs/lib/python3.11/site-packages/pandas/core/arrays/timedeltas.py:912: RuntimeWarning: invalid value encountered in cast\n",
      "  data = (base * m + (frac * m).astype(np.int64)).view(\"timedelta64[ns]\")\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset('/Users/victoriaford/Desktop/eaglerock/Historical Data Platform/Train_Files/ASOSAWOS_72051724165.nc')\n",
    "\n",
    "df = ds.to_dataframe()\n",
    "df = df.reset_index()\n",
    "df['month'] = pd.to_datetime(df['time']).dt.month # sets month to new variable\n",
    "df['year'] = pd.to_datetime(df['time']).dt.year # sets year to new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f48eba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clim_mon_mean_hourly(df, var, month, hour):\n",
    "    '''Calculate the monthly mean climatology for each of the day'''\n",
    "    \n",
    "    df_m_h = df.loc[(df.time.dt.month == month) & (df.time.dt.hour == hour)]\n",
    "    clim_value = df_m_h[var].mean(numeric_only = True)\n",
    "    \n",
    "    # special handling if value is nan? \n",
    "    \n",
    "    return clim_value\n",
    "\n",
    "def iqr_range_monhour(df, var, month, hour):\n",
    "    '''Calculates the monthly interquartile range per hour'''\n",
    "    \n",
    "    q1 = df.loc[(df.time.dt.month == month) & (df.time.dt.hour == hour)].quantile(0.25, numeric_only=True)\n",
    "    q3 = df.loc[(df.time.dt.month == month) & (df.time.dt.hour == hour)].quantile(0.75, numeric_only=True)\n",
    "    \n",
    "    iqr_df = q3 - q1\n",
    "    iqr_df_val = iqr_df[var]\n",
    "    \n",
    "    # iqr cannot be less than 1.5°C in order to preserve low variance stations\n",
    "    if iqr_df_val < 1.5:\n",
    "        iqr_df_val = 1.5\n",
    "    else:\n",
    "        iqr_df_val = iqr_df_val\n",
    "            \n",
    "    return iqr_df_val\n",
    "\n",
    "\n",
    "def clim_standardized_anom(df, vars_to_anom):\n",
    "    '''\n",
    "    First anomalizes data by monthly climatology for each hour, then\n",
    "    standardizes by the monthly climatological anomaly IQR for each hour\n",
    "    '''\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for var in vars_to_anom:\n",
    "        for m in range(1,13,1):\n",
    "            for h in range(0,24,1):\n",
    "                # each hour in each month\n",
    "                anom_value = clim_mon_mean_hourly(df, var, month=m, hour=h)\n",
    "                iqr_value = iqr_range_monhour(df, var, month=m, hour=h)\n",
    "                \n",
    "                # locate obs within specific month/hour\n",
    "                df_m_h = df.loc[(df.time.dt.month == m) & (df.time.dt.hour == h)]\n",
    "                \n",
    "                # calculate the monthly climatological anomaly by hour and standardize by iqr\n",
    "                df2.loc[(df.time.dt.month == m) & \n",
    "                        (df.time.dt.hour == h), \n",
    "                        var] = (df_m_h[var] - anom_value) / iqr_value\n",
    "                \n",
    "    return df2\n",
    "\n",
    "def winsorize_temps(df, vars_to_anom, winz_limits):\n",
    "    '''\n",
    "    Replaces potential spurious outliers by limiting the extreme values\n",
    "    using the winz_limits set (default is 5% and 95% percentiles)\n",
    "    '''\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for var in vars_to_anom:\n",
    "        for m in range(1,13,1):\n",
    "            for h in range(0,24,1):\n",
    "                \n",
    "                df_m_h = df.loc[(df.time.dt.month == m) & (df.time.dt.hour == h)]\n",
    "                \n",
    "                # winsorize only vars in vars_to_anom\n",
    "                df_w = winsorize(df_m_h[var], limits=winz_limits, nan_policy='omit')\n",
    "                \n",
    "                df2.loc[(df.time.dt.month == m) & (df.time.dt.hour == h),\n",
    "                       var] = df_w\n",
    "                \n",
    "    return df2\n",
    "\n",
    "# get average anomaly per year\n",
    "def median_yr_anom(df, var):\n",
    "    '''Get median anomaly per year'''\n",
    "    \n",
    "    monthly_anoms = []\n",
    "    \n",
    "    # identify years in data\n",
    "    years = df.time.dt.year.unique()\n",
    "    \n",
    "    for yr in years:\n",
    "        df_yr = df.loc[df.time.dt.year == yr]\n",
    "\n",
    "        ann_anom = df_yr[var].median()\n",
    "        monthly_anoms.append(ann_anom)\n",
    "        \n",
    "    return monthly_anoms\n",
    "\n",
    "def low_pass_filter_weights(median_anoms, month_low, month_high, filter_low, filter_high):\n",
    "    '''Calculates weights for low pass filter'''\n",
    "    \n",
    "    filter_wgts = [1, 2, 3, 2, 1]\n",
    "    \n",
    "    if np.sum(filter_wgts[filter_low:filter_high] * \n",
    "              np.ceil(median_anoms[month_low:month_high] - \n",
    "                      np.floor(median_anoms[month_low:month_high]))) == 0:\n",
    "        weight = 0\n",
    "    \n",
    "    else:\n",
    "        weight = (\n",
    "            np.sum(filter_wgts[filter_low:filter_high] * np.ceil(median_anoms[month_low:month_high])) / \n",
    "            np.sum(filter_wgts[filter_low:filter_high] * np.ceil(median_anoms[month_low:month_high] - \n",
    "                                                                 np.floor(median_anoms[month_low:month_high])))\n",
    "        )\n",
    "        \n",
    "    return weight\n",
    "\n",
    "def low_pass_filter(df, vars_to_anom):\n",
    "    '''\n",
    "    Low pass filtering on observations to remove any climate change signal \n",
    "    causing overzealous removal at ends of time series\n",
    "    '''\n",
    "    # identify years in data\n",
    "    years = df.time.dt.year.unique()\n",
    "    \n",
    "    for var in vars_to_anom:\n",
    "        \n",
    "        median_anoms = median_yr_anom(df, var)\n",
    "    \n",
    "        for yr in range(len(years)):\n",
    "            if yr == 0:\n",
    "                month_low, month_high = 0, 3\n",
    "                filter_low, filter_high = 2, 5\n",
    "                \n",
    "            elif yr == 1:\n",
    "                month_low, month_high = 0, 4\n",
    "                filter_low, filter_high = 1, 5\n",
    "                \n",
    "            elif yr == len(years)-2:\n",
    "                month_low, month_high = -4, -1\n",
    "                filter_low, filter_high = 0, 3\n",
    "\n",
    "            elif yr == len(years)-1:\n",
    "                month_low, month_high = -3, -1\n",
    "                filter_low, filter_high = 0, 2\n",
    "\n",
    "            else:\n",
    "                month_low, month_high = yr-2, yr+3\n",
    "                filter_low, filter_high = 0, 5\n",
    "                            \n",
    "            print(month_low, month_high, filter_low, filter_high)\n",
    "            if np.sum(np.abs(median_anoms[month_low:month_high])) != 0:\n",
    "                weights = low_pass_filter_weights(median_anoms, month_low, month_high, filter_low, filter_high)\n",
    "                      \n",
    "            # want to return specific year of data at a specific variable, the variable minus weight value\n",
    "            df.loc[(df.time.dt.year == years[yr]), var] = df.loc[df.time.dt.year == years[yr]][var] - weights\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ccf86045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 2 5\n",
      "weights 1.0\n",
      "0 4 1 5\n",
      "weights 1.0\n",
      "0 5 0 5\n",
      "weights 1.0\n",
      "1 6 0 5\n",
      "weights 1.0\n",
      "2 7 0 5\n",
      "weights 0.8888888888888888\n",
      "3 8 0 5\n",
      "weights 0.6666666666666666\n",
      "4 9 0 5\n",
      "weights 0.4444444444444444\n",
      "5 10 0 5\n",
      "weights 0.3333333333333333\n",
      "-4 -1 0 3\n",
      "weights 0.5\n",
      "-3 -1 0 2\n",
      "weights 0.6666666666666666\n",
      "0 3 2 5\n",
      "weights 1.0\n",
      "0 4 1 5\n",
      "weights 1.0\n",
      "0 5 0 5\n",
      "weights 1.0\n",
      "1 6 0 5\n",
      "weights 0.8888888888888888\n",
      "2 7 0 5\n",
      "weights 0.6666666666666666\n",
      "3 8 0 5\n",
      "weights 0.3333333333333333\n",
      "4 9 0 5\n",
      "weights 0.1111111111111111\n",
      "5 10 0 5\n",
      "weights 0.0\n",
      "-4 -1 0 3\n",
      "weights 0.0\n",
      "-3 -1 0 2\n",
      "weights 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>ps</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps</th>\n",
       "      <th>pr</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>elevation</th>\n",
       "      <th>qaqc_process</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_qc</th>\n",
       "      <th>pr_duration</th>\n",
       "      <th>pr_depth_qc</th>\n",
       "      <th>sfcWind_qc</th>\n",
       "      <th>sfcWind_method</th>\n",
       "      <th>sfcWind_dir_qc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 12:55:00</td>\n",
       "      <td>78690.0</td>\n",
       "      <td>-0.026072</td>\n",
       "      <td>-0.269416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 13:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.334985</td>\n",
       "      <td>-0.450441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.557</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 13:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>-0.400441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.557</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 13:55:00</td>\n",
       "      <td>78750.0</td>\n",
       "      <td>0.290015</td>\n",
       "      <td>-0.275441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2013-06-27 14:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.241029</td>\n",
       "      <td>-0.443765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.557</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178389</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 20:15:00</td>\n",
       "      <td>78640.0</td>\n",
       "      <td>-0.158290</td>\n",
       "      <td>0.454748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178390</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 20:35:00</td>\n",
       "      <td>78580.0</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.829748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178391</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 20:55:00</td>\n",
       "      <td>78580.0</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.829748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178392</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 21:15:00</td>\n",
       "      <td>78530.0</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.834145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.3</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178393</th>\n",
       "      <td>ASOSAWOS_72051724165</td>\n",
       "      <td>2022-08-11 21:35:00</td>\n",
       "      <td>78560.0</td>\n",
       "      <td>0.270496</td>\n",
       "      <td>0.834145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>280.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-110.556</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178394 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     station                time       ps       tas      tdps  \\\n",
       "0       ASOSAWOS_72051724165 2013-06-27 12:55:00  78690.0 -0.026072 -0.269416   \n",
       "1       ASOSAWOS_72051724165 2013-06-27 13:15:00      NaN -0.334985 -0.450441   \n",
       "2       ASOSAWOS_72051724165 2013-06-27 13:35:00      NaN  0.015015 -0.400441   \n",
       "3       ASOSAWOS_72051724165 2013-06-27 13:55:00  78750.0  0.290015 -0.275441   \n",
       "4       ASOSAWOS_72051724165 2013-06-27 14:15:00      NaN -0.241029 -0.443765   \n",
       "...                      ...                 ...      ...       ...       ...   \n",
       "178389  ASOSAWOS_72051724165 2022-08-11 20:15:00  78640.0 -0.158290  0.454748   \n",
       "178390  ASOSAWOS_72051724165 2022-08-11 20:35:00  78580.0  0.041710  0.829748   \n",
       "178391  ASOSAWOS_72051724165 2022-08-11 20:55:00  78580.0  0.041710  0.829748   \n",
       "178392  ASOSAWOS_72051724165 2022-08-11 21:15:00  78530.0  0.070496  0.834145   \n",
       "178393  ASOSAWOS_72051724165 2022-08-11 21:35:00  78560.0  0.270496  0.834145   \n",
       "\n",
       "        pr  sfcWind  sfcWind_dir  elevation qaqc_process  ... pr_qc  \\\n",
       "0      NaN      5.7        350.0     2220.0         V020  ...         \n",
       "1      NaN      5.7        350.0     2220.0         V020  ...         \n",
       "2      NaN      4.6        350.0     2220.0         V020  ...         \n",
       "3      NaN      4.6        350.0     2220.0         V020  ...         \n",
       "4      NaN      4.6        360.0     2220.0         V020  ...         \n",
       "...     ..      ...          ...        ...          ...  ...   ...   \n",
       "178389 NaN      7.2        260.0     2220.0         V020  ...         \n",
       "178390 NaN      9.8        240.0     2220.0         V020  ...         \n",
       "178391 NaN      5.7        290.0     2220.0         V020  ...         \n",
       "178392 NaN     10.3        250.0     2220.0         V020  ...         \n",
       "178393 NaN      6.7        280.0     2220.0         V020  ...         \n",
       "\n",
       "        pr_duration pr_depth_qc sfcWind_qc sfcWind_method sfcWind_dir_qc  \\\n",
       "0               NaT         NaN          5              N              5   \n",
       "1               NaT         NaN          1              N              1   \n",
       "2               NaT         NaN          1              N              1   \n",
       "3               NaT         NaN          5              N              5   \n",
       "4               NaT         NaN          1              N              1   \n",
       "...             ...         ...        ...            ...            ...   \n",
       "178389          NaT         NaN          5              N              5   \n",
       "178390          NaT         NaN          5              N              5   \n",
       "178391          NaT         NaN          5              V              5   \n",
       "178392          NaT         NaN          5              N              5   \n",
       "178393          NaT         NaN          5              N              5   \n",
       "\n",
       "           lat      lon  month  year  \n",
       "0       41.824 -110.556      6  2013  \n",
       "1       41.824 -110.557      6  2013  \n",
       "2       41.824 -110.557      6  2013  \n",
       "3       41.824 -110.556      6  2013  \n",
       "4       41.824 -110.557      6  2013  \n",
       "...        ...      ...    ...   ...  \n",
       "178389  41.824 -110.556      8  2022  \n",
       "178390  41.824 -110.556      8  2022  \n",
       "178391  41.824 -110.556      8  2022  \n",
       "178392  41.824 -110.556      8  2022  \n",
       "178393  41.824 -110.556      8  2022  \n",
       "\n",
       "[178394 rows x 26 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_to_check = ['tas', 'tdps', 'tdps_derived']\n",
    "vars_to_anom = [v for v in vars_to_check if v in df.columns]\n",
    "df2 = winsorize_temps(df, vars_to_anom, winz_limits=[0.05,0.05])\n",
    "df2 = clim_standardized_anom(df2, vars_to_anom)\n",
    "df3 = low_pass_filter(df2, vars_to_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaqc_climatological_outlier(df, winsorize=True, winz_limits=[0.05,0.05], plot=True, verbose=True):\n",
    "    '''\n",
    "    Flags individual gross outliers from climatological distribution.\n",
    "    Only applied to air temperature and dew point temperature\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "        df [pd.DataFrame]: station dataset converted to dataframe through QAQC pipeline\n",
    "        plots [bool]: if True, produces plots of any flagged data and saved to AWS\n",
    "            \n",
    "    Returns:\n",
    "    --------\n",
    "        qaqc success:\n",
    "            df [pd.DataFrame]: QAQC dataframe with flagged values (see below for flag meaning)\n",
    "        qaqc failure:\n",
    "            None\n",
    "            \n",
    "    Flag meaning:\n",
    "    -------------\n",
    "        25,qaqc_climatological_outlier,Value flagged as a climatological outlier\n",
    "    '''\n",
    "    \n",
    "    #### ONLY IN NOTEBOOK DEVELOPMENT, REMOVED IN CODE FOR PIPELINE #####\n",
    "    df = df.reset_index()\n",
    "    df['month'] = pd.to_datetime(df['time']).dt.month # sets month to new variable\n",
    "    df['year'] = pd.to_datetime(df['time']).dt.year # sets year to new variable\n",
    "    \n",
    "    vars_to_check = ['tas', 'tdps', 'tdps_derived']\n",
    "    vars_to_anom = [v for v in vars_to_check if v in df.columns]\n",
    "    \n",
    "    # TO DO: filter to only use non-flagged data\n",
    "\n",
    "    \n",
    "    # winsorize data by percentiles\n",
    "    if winsorize == True:\n",
    "        df = winsorize_temps(df, vars_to_anom, winz_limits)\n",
    "    else:\n",
    "        df = df\n",
    "        \n",
    "    # standardize data by monthly climatological anomalies by hour\n",
    "    df = clim_standardized_anom(df, vars_to_anom)\n",
    "\n",
    "    # apply low pass filter\n",
    "    df = low_pass_filter(df, vars_to_anom)\n",
    "        \n",
    "    # gaussian is fitted to the histogram of anomalies for each month\n",
    "        # threshold value, rounded outwards where crosses y=0.1 line\n",
    "        # distribution beyond threhsold value is scanned for gap, equal to bin width or more\n",
    "        # all values beyond gap are flagged\n",
    "            # HadISD: obs that fall between critical threshold value and gap or \n",
    "            # critical threshold and end of distribution are tentatively flagged\n",
    "            # these may be later reinstated on comparison with good data from neighboring stations\n",
    "            # into v2 of data product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def7e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
