{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd57733c-dd34-4c15-a934-9da709dc875c",
   "metadata": {},
   "source": [
    "# Analyze pcluster QAQC run for historical-obs-platform "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332e2fe-4849-4349-a205-ae1523b9d87a",
   "metadata": {},
   "source": [
    "This notebook analyzes the results of the [QAQC](https://github.com/Eagle-Rock-Analytics/historical-obs-platform/tree/main/test_platform/scripts/3_qaqc_data)\n",
    "run for the [historical-obs-platform](https://github.com/Eagle-Rock-Analytics/historical-obs-platform)\n",
    "\n",
    "It reads from the s3 bucket to see how many files each network has in the clean folder, and how many are in the qaqc folder (or how many were processed correctly).\n",
    "\n",
    "Also, it reads the output files from the pcluster runs (`hist-obs_*_output.txt`) to extract the running time of each station. This needs to be run in the pcluster or download the output files locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1798a2-24f7-441a-85c8-a2701208dc06",
   "metadata": {},
   "source": [
    "## Count files in the clean/qaqc folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc5e39-8800-4990-b0db-0e46d1a127e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd739b4-8512-47cf-9540-c91cb392f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the S3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Define the bucket name and base directory\n",
    "bucket_name = \"wecc-historical-wx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ca629-2b32-4de6-b531-5ce44ae52f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to save cleaned and qaqc'ed file counts\n",
    "processed_files = {}\n",
    "\n",
    "# Read network names from the file\n",
    "file_path = \"../networks-input.dat\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    network_names = [line.strip() for line in f if line.strip()]\n",
    "for network in network_names:\n",
    "    processed_files[network] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998c3be-dc37-41fc-9c35-cb7a6d09b195",
   "metadata": {},
   "source": [
    "### Clean folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1bb52-4158-4fef-9755-d16fc8a62f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean base dir\n",
    "base_directory = \"2_clean_wx/\"\n",
    "\n",
    "# Read network names from the file\n",
    "file_path = \"../networks-input.dat\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    network_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Iterate over each network and count the .nc files\n",
    "for network in network_names:\n",
    "    prefix = f\"{base_directory}{network}/\"\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    if \"Contents\" in response:\n",
    "        nc_files = [\n",
    "            obj[\"Key\"] for obj in response[\"Contents\"] if obj[\"Key\"].endswith(\".nc\")\n",
    "        ]\n",
    "        print(f\"Network: {network}, .nc files count: {len(nc_files)}\")\n",
    "        processed_files[network].append(len(nc_files))\n",
    "    else:\n",
    "        print(f\"Network: {network}, No .nc files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7add74-0c0b-498c-ae4b-7c570e7e972c",
   "metadata": {},
   "source": [
    "### QAQC folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca916a6-7d55-4eac-be03-43e1758cea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAQC base dir\n",
    "base_prefix = \"3_qaqc_wx/\"\n",
    "\n",
    "# Read the 23 network names from your file\n",
    "with open(\"../networks-input.dat\", \"r\") as f:\n",
    "    networks = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Count .zarr/ folders for each network\n",
    "for network in networks:\n",
    "    prefix = f\"{base_prefix}{network}/\"\n",
    "    paginator = s3_client.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "    zarr_folders = set()\n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix, Delimiter=\"/\"):\n",
    "        # Hanldes networks with zero zarr files where 'CommonPrefixes' is not found\n",
    "        common_prefixes = page.get(\"CommonPrefixes\", [])\n",
    "        files = [p[\"Prefix\"] for p in common_prefixes if p[\"Prefix\"].endswith(\".zarr/\")]\n",
    "        zarr_folders.update(files)\n",
    "\n",
    "    count = len(zarr_folders)\n",
    "    print(f\"{network}: {count} .zarr folders\")\n",
    "    processed_files[network].append(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270dd47-0de8-4816-99c2-33b032b36723",
   "metadata": {},
   "source": [
    "### Display count\n",
    "\n",
    "Display how many files were in the clean folder vs how many there are in the QAQC folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5542084-5bab-416b-8a5f-a665c7cd1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ceb40-fcdb-4207-9b84-da8a36063c8b",
   "metadata": {},
   "source": [
    "## Analyze pcluster output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d0b60-682a-498d-9b2a-904cf6c47efe",
   "metadata": {},
   "source": [
    "### Read output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bc093-649b-477a-be32-d3ef7f674e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all files matching the pattern\n",
    "files = glob.glob(\"../hist-obs_*_output.txt\")\n",
    "\n",
    "data = []\n",
    "\n",
    "# Regular expressions\n",
    "stations_re = re.compile(r\"Running a sample of (\\d+) files\")\n",
    "network_re = re.compile(r\"Network:\\s+([^\\n\\r]+)\")\n",
    "time_re = re.compile(r\"Job completed in (\\d+) seconds\")\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "        stations_match = stations_re.search(content)\n",
    "        network_match = network_re.search(content)\n",
    "        time_match = time_re.search(content)\n",
    "\n",
    "        if stations_match and network_match and time_match:\n",
    "            stations = int(stations_match.group(1))\n",
    "            network_name = network_match.group(1).strip()\n",
    "            seconds = int(time_match.group(1))\n",
    "            minutes = seconds / 60\n",
    "\n",
    "        # Some files did not record the number of processed stations, not sure why\n",
    "        elif stations_match is None:\n",
    "            stations = np.nan\n",
    "            network_name = network_match.group(1).strip()\n",
    "            seconds = int(time_match.group(1))\n",
    "            minutes = seconds / 60\n",
    "\n",
    "        else:\n",
    "            print(filename)\n",
    "\n",
    "        data.append((network_name, stations, seconds, minutes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fc5ee-f87b-4041-a442-32dd576fd679",
   "metadata": {},
   "source": [
    "### Create pandas dataframe with run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd6f72-a1af-4fae-b921-9b6e98c40360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"Network\",\n",
    "        \"Number of stations\",\n",
    "        \"Elapsed time seconds\",\n",
    "        \"Elapsed time minutes\",\n",
    "    ],\n",
    ")\n",
    "# df.set_index(\"Network\", inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d3364-be88-4f44-8f99-69bab1857f3d",
   "metadata": {},
   "source": [
    "### Sort by network for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49b90d-4fc1-4333-82f9-b62483a4307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"Network\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "hist-obs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
