{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASOSAWOS Jumps Invgestigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: could use this as an alternative to multiple merges, for combining the subsets into the final output dataframe\n",
    "from functools import reduce\n",
    "\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib\n",
    "import datetime\n",
    "import math\n",
    "import shapely\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "import scipy.stats as stats\n",
    "\n",
    "import s3fs\n",
    "import tempfile # Used for downloading (and then deleting) netcdfs to local drive from s3 bucket\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "import time # Used for progress bar \n",
    "import sys # Used for progress bar \n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) # Warning is raised when creating Point object from coords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client('s3') # for lower-level processes\n",
    "\n",
    "## Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "wecc_terr = \"s3://wecc-historical-wx/0_maps/WECC_Informational_MarineCoastal_Boundary_land.shp\"\n",
    "wecc_mar = \"s3://wecc-historical-wx/0_maps/WECC_Informational_MarineCoastal_Boundary_marine.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define temporary directory in local drive for downloading data from S3 bucket\n",
    "# If the directory doesn't exist, it will be created\n",
    "# If we used zarr, this wouldn't be neccessary \n",
    "temp_dir = \"./tmp\"\n",
    "if not os.path.exists(temp_dir): \n",
    "    os.mkdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressbar(it, prefix=\"\", size=60, out=sys.stdout): # Python3.6+\n",
    "    \"\"\"\n",
    "    Print a progress bar to console \n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    https://stackoverflow.com/questions/3160699/python-progress-bar\n",
    "    \n",
    "    \"\"\"\n",
    "    count = len(it)\n",
    "    start = time.time() # time estimate start\n",
    "    def show(j):\n",
    "        x = int(size*j/count)\n",
    "        # time estimate calculation and string\n",
    "        remaining = ((time.time() - start) / j) * (count - j)        \n",
    "        mins, sec = divmod(remaining, 60) # limited to minutes\n",
    "        time_str = f\"{int(mins):02}:{sec:03.1f}\"\n",
    "        print(f\"{prefix}[{u'â–ˆ'*x}{('.'*(size-x))}] {j}/{count} Est wait {time_str}\", end='\\r', file=out, flush=True)\n",
    "    show(0.1) # avoid div/0 \n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i+1)\n",
    "    print(\"\\n\", flush=True, file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nc_from_s3(network_name, station_id, temp_dir):\n",
    "    \"\"\"Read netcdf file containing station data for a single station of interest from AWS s3 bucket \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network_name: str \n",
    "        Name of network (i.e. \"ASOSAWOS\")\n",
    "        Must correspond with a valid directory in the s3 bucket (i.e. \"CAHYDRO\", \"CDEC\", \"ASOSAWOS\")\n",
    "    station_id: str\n",
    "        Station identifier; i.e. the name of the netcdf file in the bucket (i.e. \"ASOSAWOS_72012200114.nc\")\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    station_data: xr.Dataset \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The data is first downloaded from AWS into a tempfile, which is then deleted after xarray reads in the file \n",
    "    I'd like to see us use a zarr workflow if possible to avoid this. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Temp file for downloading from s3\n",
    "    temp_file = tempfile.NamedTemporaryFile(\n",
    "        dir = temp_dir, \n",
    "        prefix = \"\", \n",
    "        suffix = \".nc\",\n",
    "        delete = True\n",
    "    )\n",
    "\n",
    "    # Create s3 file system \n",
    "    s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "    # Get URL to netcdf in S3\n",
    "    s3_url = 's3://wecc-historical-wx/3_qaqc_wx_dev/{}/{}.nc'.format(network_name, station_id)\n",
    "\n",
    "    # Read in the data using xarray \n",
    "    s3_file_obj = s3.get(s3_url, temp_file.name)\n",
    "    station_data = xr.open_dataset(temp_file.name, engine='h5netcdf').load()\n",
    "\n",
    "    # Close temporary file \n",
    "    temp_file.close()\n",
    "\n",
    "    return station_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qaqc_ds_to_df(ds, verbose=False):\n",
    "    ## Add qc_flag variable for all variables, including elevation; \n",
    "    ## defaulting to nan for fill value that will be replaced with qc flag\n",
    "\n",
    "    for key,val in ds.variables.items():\n",
    "        if val.dtype==object:\n",
    "            if key=='station':\n",
    "                if str in [type(v) for v in ds[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "            else:\n",
    "                if str in [type(v) for v in ds.isel(station=0)[key].values]:\n",
    "                    ds[key] = ds[key].astype(str)\n",
    "                \n",
    "    exclude_qaqc = [\"time\", \"station\", \"lat\", \"lon\", \n",
    "                    \"qaqc_process\", \"sfcWind_method\", \n",
    "                    \"pr_duration\", \"pr_depth\", \"PREC_flag\",\n",
    "                    \"rsds_duration\", \"rsds_flag\", \n",
    "                    \"anemometer_height_m\",\n",
    "                    \"thermometer_height_m\"\n",
    "                   ] # lat, lon have different qc check\n",
    "\n",
    "    raw_qc_vars = [] # qc_variable for each data variable, will vary station to station\n",
    "    era_qc_vars = [] # our ERA qc variable\n",
    "    old_era_qc_vars = [] # our ERA qc variable\n",
    "\n",
    "    for var in ds.data_vars:\n",
    "        if 'q_code' in var: \n",
    "            raw_qc_vars.append(var) # raw qc variable, need to keep for comparison, then drop\n",
    "        if '_qc' in var: \n",
    "            raw_qc_vars.append(var) # raw qc variables, need to keep for comparison, then drop\n",
    "        if '_eraqc' in var:\n",
    "            era_qc_vars.append(var) # raw qc variables, need to keep for comparison, then drop\n",
    "            old_era_qc_vars.append(var)\n",
    "\n",
    "    print(f\"era_qc existing variables:\\n{era_qc_vars}\")\n",
    "    n_qc = len(era_qc_vars)\n",
    "    \n",
    "    for var in ds.data_vars:\n",
    "        if var not in exclude_qaqc and var not in raw_qc_vars and \"_eraqc\" not in var:\n",
    "            qc_var = var + \"_eraqc\" # variable/column label\n",
    "\n",
    "            # if qaqc var does not exist, adds new variable in shape of original variable with designated nan fill value\n",
    "            if qc_var not in era_qc_vars:\n",
    "                print(f\"nans created for {qc_var}\")\n",
    "                ds = ds.assign({qc_var: xr.ones_like(ds[var])*np.nan})\n",
    "                era_qc_vars.append(qc_var)\n",
    "    \n",
    "    print(\"{} created era_qc variables\".format(len(era_qc_vars)-len(old_era_qc_vars)))\n",
    "    if len(era_qc_vars)!=n_qc:    \n",
    "        print(\"{}\".format(np.setdiff1d(old_era_qc_vars, era_qc_vars)))\n",
    "    \n",
    "    # Save attributes to inheret them to the QAQC'ed file\n",
    "    attrs = ds.attrs\n",
    "    var_attrs = {var:ds[var].attrs for var in list(ds.data_vars.keys())}\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        df = ds.to_dataframe()\n",
    "\n",
    "    # instrumentation heights\n",
    "    if 'anemometer_height_m' not in df.columns:\n",
    "        try:\n",
    "            df['anemometer_height_m'] = np.ones(ds['time'].shape)*ds.anemometer_height_m\n",
    "        except:\n",
    "            print(\"Filling anemometer_height_m with NaN.\", flush=True)\n",
    "            df['anemometer_height_m'] = np.ones(len(df))*np.nan\n",
    "        finally:\n",
    "            pass\n",
    "    if 'thermometer_height_m' not in df.columns:\n",
    "        try:\n",
    "            df['thermometer_height_m'] = np.ones(ds['time'].shape)*ds.thermometer_height_m\n",
    "        except:\n",
    "            print(\"Filling thermometer_height_m with NaN.\", flush=True)\n",
    "            df['thermometer_height_m'] = np.ones(len(df))*np.nan\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    # De-duplicate time axis\n",
    "    df = df[~df.index.duplicated()].sort_index()\n",
    "           \n",
    "    # Save station/time multiindex\n",
    "    MultiIndex = df.index\n",
    "    station = df.index.get_level_values(0)\n",
    "    df['station'] = station\n",
    "    \n",
    "    # Station pd.Series to str\n",
    "    station = station.unique().values[0]\n",
    "    \n",
    "    # Convert time/station index to columns and reset index\n",
    "    df = df.droplevel(0).reset_index()\n",
    "\n",
    "    # Add time variables needed by multiple functions\n",
    "    df['hour'] = pd.to_datetime(df['time']).dt.hour\n",
    "    df['day'] = pd.to_datetime(df['time']).dt.day \n",
    "    df['month'] = pd.to_datetime(df['time']).dt.month \n",
    "    df['year'] = pd.to_datetime(df['time']).dt.year \n",
    "    df['date']  = pd.to_datetime(df['time']).dt.date\n",
    "    \n",
    "    return df#, MultiIndex, attrs, var_attrs, era_qc_vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The specified key does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/s3fs/core.py:113\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/aiobotocore/client.py:408\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    407\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load in single dc file from AWS\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ds_1 \u001b[38;5;241m=\u001b[39m \u001b[43mread_nc_from_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mASOSAWOS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mASOSAWOS_74948400395\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      3\u001b[0m ds_2 \u001b[38;5;241m=\u001b[39m read_nc_from_s3(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASOSAWOS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASOSAWOS_74509023244\u001b[39m\u001b[38;5;124m'\u001b[39m, temp_dir) \n\u001b[1;32m      4\u001b[0m ds_3 \u001b[38;5;241m=\u001b[39m read_nc_from_s3(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASOSAWOS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASOSAWOS_72494523293\u001b[39m\u001b[38;5;124m'\u001b[39m, temp_dir) \n",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m, in \u001b[0;36mread_nc_from_s3\u001b[0;34m(network_name, station_id, temp_dir)\u001b[0m\n\u001b[1;32m     35\u001b[0m s3_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3://wecc-historical-wx/3_qaqc_wx_dev/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(network_name, station_id)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Read in the data using xarray \u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m s3_file_obj \u001b[38;5;241m=\u001b[39m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms3_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m station_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(temp_file\u001b[38;5;241m.\u001b[39mname, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Close temporary file \u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/fsspec/asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/fsspec/asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     58\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/fsspec/asyn.py:665\u001b[0m, in \u001b[0;36mAsyncFileSystem._get\u001b[0;34m(self, rpath, lpath, recursive, callback, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     get_file \u001b[38;5;241m=\u001b[39m callback\u001b[38;5;241m.\u001b[39mbranch_coro(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file)\n\u001b[1;32m    664\u001b[0m     coros\u001b[38;5;241m.\u001b[39mappend(get_file(rpath, lpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _run_coros_in_chunks(\n\u001b[1;32m    666\u001b[0m     coros, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, callback\u001b[38;5;241m=\u001b[39mcallback\n\u001b[1;32m    667\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/fsspec/asyn.py:268\u001b[0m, in \u001b[0;36m_run_coros_in_chunks\u001b[0;34m(coros, batch_size, callback, timeout, return_exceptions, nofiles)\u001b[0m\n\u001b[1;32m    266\u001b[0m     done, pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(pending, return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_COMPLETED)\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m done:\n\u001b[0;32m--> 268\u001b[0m         result, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m done\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    269\u001b[0m         results[k] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/fsspec/asyn.py:245\u001b[0m, in \u001b[0;36m_run_coros_in_chunks.<locals>._run_coro\u001b[0;34m(coro, i)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_coro\u001b[39m(coro, i):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout), i\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_exceptions:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/asyncio/tasks.py:442\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout, loop)\u001b[0m\n\u001b[1;32m    437\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe loop argument is deprecated since Python 3.8, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand scheduled for removal in Python 3.10.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    439\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    445\u001b[0m     fut \u001b[38;5;241m=\u001b[39m ensure_future(fut, loop\u001b[38;5;241m=\u001b[39mloop)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/fsspec/callbacks.py:81\u001b[0m, in \u001b[0;36mCallback.branch_coro.<locals>.func\u001b[0;34m(path1, path2, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(path1, path2: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranched(path1, path2, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m child:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(path1, path2, callback\u001b[38;5;241m=\u001b[39mchild, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/s3fs/core.py:1296\u001b[0m, in \u001b[0;36mS3FileSystem._get_file\u001b[0;34m(self, rpath, lpath, callback, version_id, **kwargs)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1289\u001b[0m         Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw,\n\u001b[1;32m   1293\u001b[0m     )\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m\"\u001b[39m], resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentLength\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1296\u001b[0m body, content_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _open_file(\u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1297\u001b[0m callback\u001b[38;5;241m.\u001b[39mset_size(content_length)\n\u001b[1;32m   1299\u001b[0m failed_reads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/s3fs/core.py:1287\u001b[0m, in \u001b[0;36mS3FileSystem._get_file.<locals>._open_file\u001b[0;34m(range)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mrange\u001b[39m:\n\u001b[1;32m   1286\u001b[0m     kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrange\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1287\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1289\u001b[0m     Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m   1290\u001b[0m     Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id \u001b[38;5;129;01mor\u001b[39;00m vers),\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw,\n\u001b[1;32m   1293\u001b[0m )\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m\"\u001b[39m], resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentLength\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/s3fs/core.py:365\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[0;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, akwarglist, kw2)\n\u001b[1;32m    364\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[1;32m    366\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[1;32m    367\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hist-obs/lib/python3.9/site-packages/s3fs/core.py:145\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    143\u001b[0m         err \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    144\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: The specified key does not exist."
     ]
    }
   ],
   "source": [
    "# load in single dc file from AWS\n",
    "ds_1 = read_nc_from_s3('ASOSAWOS', 'ASOSAWOS_74948400395', temp_dir) \n",
    "ds_2 = read_nc_from_s3('ASOSAWOS', 'ASOSAWOS_74509023244', temp_dir) \n",
    "ds_3 = read_nc_from_s3('ASOSAWOS', 'ASOSAWOS_72494523293', temp_dir) \n",
    "\n",
    "#convert to formatted pandas dataframe\n",
    "df_1 = qaqc_ds_to_df(ds_1, verbose=False)\n",
    "df_2 = qaqc_ds_to_df(ds_2, verbose=False)\n",
    "df_3 = qaqc_ds_to_df(ds_3, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
