{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station Matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from functools import reduce\n",
    "import datetime\n",
    "from pandas import *\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "## New logger function\n",
    "from log_config import logger\n",
    "\n",
    "# Import qaqc stage calc functions\n",
    "try:\n",
    "    from QAQC_pipeline import *\n",
    "except:\n",
    "    print(\"Error importing QAQC_pipeline.py\")\n",
    "\n",
    "# import tempfile  # Used for downloading (and then deleting) netcdfs to local drive from s3 bucket\n",
    "import os\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=ShapelyDeprecationWarning\n",
    ")  # Warning is raised when creating Point object from coords. Can't figure out why.\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")\n",
    "\n",
    "## AWS buckets\n",
    "bucket = \"wecc-historical-wx\"\n",
    "qaqcdir = \"3_qaqc_wx/\"\n",
    "mergedir = \"4_merge_wx/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identify candidates for concatenation and upload to AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do so by identifying stations with exactly matching latitudes and longitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of networks to be checked for concatenation\n",
    "target_networks = [\n",
    "    \"VALLEYWATER\"\n",
    "]  # [\"ASOSAWOS\",\"VALLEYWATER\", \"MARITIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenation_check(station_list):\n",
    "    \"\"\"\n",
    "    This function flags stations that need to be concatenated.\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) Stations are flagged if they have identical latitudes and longitudes\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        station_list: pd.DataFrame\n",
    "            list of station information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            new_station_list: pd.DataFrame\n",
    "                input station list with a flag column assigning an integer to each group of repeat latitudes and longitudes\n",
    "\n",
    "        if failure:\n",
    "            None\n",
    "\n",
    "    \"\"\"\n",
    "    ##### Flag stations with identical latitudes and longitudes, then assign each group a unique integer\n",
    "\n",
    "    # List of possible variable names for longitudes and latitudes\n",
    "    lat_lon_list = [\"LAT\", \"LON\", \"latitude\", \"longitude\", \"LATITUDE\", \"LONGITUDE\", 'lat','lon']\n",
    "    # Extract the latitude and longitude variable names from the input dataframe\n",
    "    lat_lon_cols = [col for col in station_list.columns if col in lat_lon_list]\n",
    "\n",
    "    # Generate column flagging duplicate latitudes and longitudes\n",
    "    station_list[\"concat_subset\"] = station_list.duplicated(\n",
    "        subset=lat_lon_cols, keep=False\n",
    "    )\n",
    "    # within each group of identical latitudes and longitudes, assign a unique integer\n",
    "    station_list[\"concat_subset\"] = (\n",
    "        station_list[station_list[\"concat_subset\"] == True].groupby(lat_lon_cols).ngroup()\n",
    "    )\n",
    "\n",
    "    ##### Order station list by flag\n",
    "    concat_station_list = station_list.sort_values(\"concat_subset\")\n",
    "\n",
    "    ##### Keep only flagged stations\n",
    "    concat_station_list = concat_station_list[~concat_station_list[\"concat_subset\"].isna()]\n",
    "\n",
    "    ##### Format final list\n",
    "    # Convert flags to integers - this is necessary for the final concatenation step\n",
    "    concat_station_list[\"concat_subset\"] = concat_station_list[\"concat_subset\"].astype(\n",
    "        \"int32\"\n",
    "    )\n",
    "    # Now keep only the ERA-ID and flag column\n",
    "    era_id_list = ['ERA-ID','era-id']\n",
    "    era_id_col = [col for col in station_list.columns if col in era_id_list]\n",
    "    concat_station_list = concat_station_list[era_id_col + [\"concat_subset\"]]\n",
    "\n",
    "    # Standardize ERA id to \"ERA-ID\" (this is specific to Valleywater stations)\n",
    "    if 'era-id' in era_id_col:\n",
    "        concat_station_list.rename(columns={\"era-id\": \"ERA-ID\"}, inplace=True)\n",
    "\n",
    "    return concat_station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_concat_check(station_names_list):\n",
    "    \"\"\"\n",
    "    This function applies the conatenation check to a list of target stations. \n",
    "    It then upload a csv containing the ERA IDs and concatenation subset ID for \n",
    "    all identified stations in a network.\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        station__names_list: pd.DataFrame\n",
    "            list of target station names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            uploads list of stations to be concatenated to AWS\n",
    "        if failure:\n",
    "            None\n",
    "\n",
    "    \"\"\"\n",
    "    final_list = pd.DataFrame([])\n",
    "    for station in station_names_list:\n",
    "\n",
    "        ##### Import station list of target station\n",
    "        key = \"2_clean_wx/{}/stationlist_{}_cleaned.csv\".format(station,station)\n",
    "        bucket_name = \"wecc-historical-wx\"\n",
    "        list_import = s3_cl.get_object(\n",
    "            Bucket=bucket,\n",
    "            Key=key,\n",
    "        )\n",
    "        station_list = pd.read_csv(BytesIO(list_import[\"Body\"].read()))\n",
    "\n",
    "        ##### Apply concatenation check\n",
    "        concat_list = concatenation_check(station_list)\n",
    "\n",
    "        ##### Rename the flags for each subset to <station>_<subset number>\n",
    "        concat_list[\"concat_subset\"] = station + '_' + concat_list[\"concat_subset\"].astype(str)\n",
    "\n",
    "        ##### Append to final list of stations to concatenate\n",
    "        final_list = pd.concat([final_list,concat_list])\n",
    "\n",
    "        ##### Upload to QAQC directory in AWS\n",
    "        new_buffer = StringIO()\n",
    "        final_list.to_csv(new_buffer, index = False)\n",
    "        content = new_buffer.getvalue()\n",
    "\n",
    "        # the csv is stored in each station folder within 3_qaqc_wx\n",
    "        s3_cl.put_object(\n",
    "            Bucket = bucket_name,\n",
    "            Body = content,\n",
    "            Key = qaqcdir + station + \"/concat_list_{}.csv\".format(station)\n",
    "        )\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapply_concat_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_networks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 20\u001b[0m, in \u001b[0;36mapply_concat_check\u001b[0;34m(station_names_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_concat_check\u001b[39m(station_names_list):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    This function applies the conatenation check to a list of target stations. \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    It then upload a csv containing the ERA IDs and concatenation subset ID for \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     final_list \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame([])\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m station \u001b[38;5;129;01min\u001b[39;00m station_names_list:\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m##### Import station list of target station\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2_clean_wx/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/stationlist_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(station,station)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "apply_concat_check(target_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Concatenate Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _multiindex_concat_nooverlap(m_old, m_new, name):\n",
    "    \"\"\"\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            return list of ERA-IDs are stations that are concatenated\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    # combine time indices of two multiindexes\n",
    "    tidx = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.Series(m_old.get_level_values(\"time\").values),\n",
    "                pd.Series(m_new.get_level_values(\"time\").values),\n",
    "            ]\n",
    "        )\n",
    "        .reset_index()\n",
    "        .drop(columns=\"index\")\n",
    "    )\n",
    "\n",
    "    # idenitify if there are duplicate times\n",
    "    tidx = tidx.rename(columns={0: \"time\"})\n",
    "    tidx = tidx.sort_values(\"time\").drop_duplicates(subset=[\"time\"])\n",
    "\n",
    "    # PULL the station name from m_new and set to the same length\n",
    "    stnidx = (\n",
    "        pd.Series(name, index=np.arange(len(tidx)), name=\"station\")\n",
    "        .reset_index()\n",
    "        .drop(columns=\"index\")\n",
    "    )\n",
    "\n",
    "    # combine into new df (ugh)\n",
    "    df_ugh = pd.concat([stnidx, tidx], axis=1)\n",
    "\n",
    "    return df_ugh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _concat_export_help(\n",
    "    df_concat, network_name, attrs_new, station_names\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares the final concatenated dataset for export by \n",
    "    - updating the attributes and \n",
    "    - converting one of the mulit-index levels to the correct datatype\n",
    "    then export the final dataset to AWS\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) retains the name the newest station\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        df_concat: pd.DataFrame\n",
    "            dataframe of concatenated dataframes\n",
    "        network_name: string\n",
    "            weather station network\n",
    "        attrs_new: pd.Dictionary\n",
    "            attributes of newer dataframe that was input to concatenation\n",
    "        station_name_new: string\n",
    "            name of newer station\n",
    "        station_name_old: string\n",
    "            name of older station\n",
    "        station_names: dictionary\n",
    "            library of station names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            None\n",
    "            export dataset of concatenated dataframes to AWS\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    # Delete unnecessary columns and set index\n",
    "    df_concat = df_concat.drop([\"hour\", \"day\", \"month\", \"year\", \"date\"], axis=1)\n",
    "    df_to_export = df_concat.set_index([\"station\", \"time\"])\n",
    "\n",
    "    ## Convert concatenated dataframe to dataset -- seeing duplicate timestamps here -- the exact same length as df2?\n",
    "    ds_concat = df_to_export.to_xarray()\n",
    "\n",
    "    # Convert datatype of station coordinate\n",
    "    ds_concat.coords[\"station\"] = ds_concat.coords[\"station\"].astype(\"<U20\")\n",
    "\n",
    "    # Include past attributes -- do this manually?\n",
    "    for i in attrs_new:\n",
    "        ds_concat.attrs[i] = attrs_new[i]\n",
    "\n",
    "    # Update 'history' attribute\n",
    "    timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "    ds_concat.attrs[\"history\"] = ds_concat.attrs[\n",
    "        \"history\"\n",
    "    ] + \" \\nstation_matching.ipynb run on {} UTC\".format(timestamp)\n",
    "\n",
    "    # Update 'comment' attribute\n",
    "    ds_concat.attrs[\"comment\"] = (\n",
    "        \"Intermediary data product. This data has been subjected to cleaning, QA/QC, but may not have been standardized.\"\n",
    "    )\n",
    "\n",
    "    station_name_new = station_names['station_name_new']\n",
    "    old_stations = station_names['old_stations'] \n",
    "\n",
    "    # Add new qaqc_files_merged attribute\n",
    "    ds_concat.attrs[\"qaqc_files_merged\"] = (\n",
    "        \"{}, {} merged. Overlap retained from newer station data.\".format(\n",
    "            old_stations, station_name_new\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ## Export ###\n",
    "    # ! a test name is used below\n",
    "    # ! the final name will be that of the newer dataframe\n",
    "    export_url = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}_{}.zarr\".format(\n",
    "        network_name, \"TEST_concat\", station_name_new\n",
    "    )\n",
    "    print(\"Exporting....\", export_url)\n",
    "    # ds_concat.to_zarr(export_url, mode=\"w\") ## WHEN READY TO EXPORT\n",
    "\n",
    "    return ds_concat #None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _overlap_concat(df_new,df_old):\n",
    "    \"\"\"\n",
    "    Handles the cases in which there is overlap between the two input stations\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            return final concatenated dataset\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    ##### Split datframes into subsets #####\n",
    "\n",
    "    # Remove data in time overlap between old and new\n",
    "    df_old_cleaned = df_old[~df_old[\"time\"].isin(df_overlap[\"time\"])]\n",
    "    df_new_cleaned = df_new[~df_new[\"time\"].isin(df_overlap[\"time\"])]\n",
    "\n",
    "    ##### Concatenate subsets #####\n",
    "    df_concat = pd.concat([df_old_cleaned, df_overlap, df_new_cleaned])\n",
    "\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _more_than_2(network_name,stns_to_pair):\n",
    "    \"\"\"\n",
    "    Perform pairwise concatenation on subsets of more than two stations flagged for concatenation\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "        stns_to_pair: pd.DataFrame\n",
    "            dataframe of the input station names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            return final concatenated dataframe\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\", stns_to_pair)\n",
    "\n",
    "    # Step 1: Load datasets\n",
    "    datasets = [\n",
    "        xr.open_zarr(\n",
    "            \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}.zarr\".format(\n",
    "                network_name, stn\n",
    "            ),\n",
    "            consolidated=True,\n",
    "        )\n",
    "        for stn in stns_to_pair['ERA-ID']\n",
    "    ]\n",
    "\n",
    "    # Sort by max time\n",
    "    datasets_sorted = sorted(datasets, key=lambda ds: ds.time.max().item(), reverse=True)\n",
    "\n",
    "    # Progressive combination\n",
    "    result = datasets_sorted[0]\n",
    "\n",
    "    for ds in datasets_sorted[1:]:\n",
    "        start1, end1 = result.time.min().item(), result.time.max().item()\n",
    "        start2, end2 = ds.time.min().item(), ds.time.max().item()\n",
    "\n",
    "        # overlap = not (end1 < start2 or end2 < start1)\n",
    "\n",
    "        # if overlap:\n",
    "        #     df_concat = _overlap_concat(result, ds)\n",
    "        # else:\n",
    "        #     df_concat = xr.concat([result, ds], dim=\"time\").sortby(\"time\")\n",
    "\n",
    "    # Construct station names list, for updating attributes\n",
    "    newest_station = datasets_sorted[\"ERA-ID\"].iloc[0]\n",
    "    older_stations = \", \".join(datasets_sorted.iloc[1:, 0].astype(str))\n",
    "    station_names = {\"station_name_new\": newest_station, \"old_stations\": older_stations}\n",
    "\n",
    "    return df_concat, station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ds_concat(ds_1, ds_2):\n",
    "    \"\"\"\n",
    "    Carry out concatenation \n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            return list of ERA-IDs are stations that are concatenated\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    # convert to dataframes with corresponding information\n",
    "    df_1, MultiIndex_1, attrs_1, var_attrs_1, era_qc_vars_1 = qaqc_ds_to_df(\n",
    "        ds_1, verbose=False\n",
    "    )\n",
    "    df_2, MultiIndex_2, attrs_2, var_attrs_2, era_qc_vars_2 = qaqc_ds_to_df(\n",
    "        ds_2, verbose=False\n",
    "    )\n",
    "\n",
    "    # determine which dataset is older\n",
    "    if df_1[\"time\"].max() < df_2[\"time\"].max():\n",
    "        # if df_1 has an earlier end tiem than df_2, then d_2 is newer\n",
    "        # we also grab the name of the newer station in this step, for use later\n",
    "        df_new = df_2\n",
    "        attrs_new = attrs_2\n",
    "        df_old = df_1\n",
    "\n",
    "    else:\n",
    "        df_new = df_1\n",
    "        attrs_new = attrs_1\n",
    "        df_old = df_2\n",
    "\n",
    "    stn_n_to_keep = df_new[\"station\"].unique()[0]\n",
    "    stn_n_to_drop = df_old[\"station\"].unique()[0]\n",
    "    print(f\"Station will be concatenated and saved as: {stn_n_to_keep}\")\n",
    "\n",
    "    # now set things up to determine if there is temporal overlap between df_new and df_old\n",
    "    df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "    # If there is no overlap between the two time series, just concatenate\n",
    "    if len(df_overlap) == 0:\n",
    "        print(\"No overlap!\")\n",
    "        df_concat = pd.merge(df_old, df_new, how=\"outer\")\n",
    "        df_concat[\"station\"] = stn_n_to_keep\n",
    "\n",
    "    # If overlap exists, split into subsets and concatenate\n",
    "    else:\n",
    "        print(\"There is overlap\")\n",
    "        df_concat = _overlap_concat(df_old, df_new)\n",
    "\n",
    "    return df_concat, stn_n_to_keep, stn_n_to_drop, attrs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_station_pairs2(network_name):\n",
    "    \"\"\"\n",
    "    Coordinates the concatenation of input datasets and exports the final concatenated dataset.\n",
    "    Also returns a list of the ERA-IDs of all stations that are concatenated.\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success:\n",
    "            return list of ERA-IDs are stations that are concatenated\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    Notes\n",
    "    -------\n",
    "    Uses the following helper functions\n",
    "        _ds_concat(): concatenates two datasets\n",
    "        _overlap_concat(): used by _ds_concat() to concatenates two stations with overlapping time ranges\n",
    "        _more_than_2(): handles subsets with more than two stations, passing pairs to _ds_concat() iteratively\n",
    "        _concat_export_help(): formats and exports concatenated dataset\n",
    "\n",
    "    \"\"\"\n",
    "    # Initiate empty list, to which we will iteratively add the ERA-IDs of stations that are concatenated\n",
    "    final_concat_list = []\n",
    "\n",
    "    # Read in full concat station list\n",
    "    print(network_name)\n",
    "    concat_list = pd.read_csv(\n",
    "        f\"s3://wecc-historical-wx/3_qaqc_wx/{network_name}/concat_list_{network_name}.csv\"\n",
    "    )\n",
    "\n",
    "    # Identify stns within designated network\n",
    "    concat_by_network = concat_list.loc[\n",
    "        concat_list.concat_subset.str.contains(network_name)\n",
    "    ]\n",
    "\n",
    "    # For MARITIME, remove these stations becuase they're actually separate stations\n",
    "    if network_name == 'MARITIME':\n",
    "        unique_pair_names = unique_pair_names[1:]\n",
    "        unique_pair_name = unique_pair_name[~unique_pair_name[\"ERA-ID\"].isin['MARITIME_LJPC1','MARITIME_LJAC1']]\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    # ! TESTING\n",
    "    concat_by_network = concat_by_network.head(12)\n",
    "    # ! TESTING\n",
    "\n",
    "    unique_pair_names = concat_by_network.concat_subset.unique()\n",
    "    print(\n",
    "        f\"There are {len(concat_by_network)} stations to be concatenated into {len(unique_pair_names)} station pairs within {network_name}...\"\n",
    "    )\n",
    "\n",
    "    print(unique_pair_names)\n",
    "\n",
    "    # Set up pairs\n",
    "    for pair in unique_pair_names:\n",
    "        print(pair)\n",
    "        # pull out stations corresponding to pair name\n",
    "        stns_to_pair = concat_by_network.loc[concat_by_network.concat_subset == pair]\n",
    "\n",
    "        if len(stns_to_pair) == 2:  # 2 stations to concat together\n",
    "            print(\"\\n\", stns_to_pair)\n",
    "\n",
    "            # import this subset of datasets and convert to dataframe\n",
    "            url_1 = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}.zarr\".format(\n",
    "                network_name, stns_to_pair.iloc[0][\"ERA-ID\"]\n",
    "            )\n",
    "            url_2 = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}.zarr\".format(\n",
    "                network_name, stns_to_pair.iloc[1][\"ERA-ID\"]\n",
    "            )\n",
    "\n",
    "            print(\"Retrieving....\", url_1)\n",
    "            print(\"Retrieving....\", url_2)\n",
    "            ds_1 = xr.open_zarr(url_1)\n",
    "            ds_2 = xr.open_zarr(url_2)\n",
    "\n",
    "            ##### Send to helper function for concatenation\n",
    "            df_concat, stn_n_to_keep, stn_n_to_drop, attrs_new = _ds_concat(\n",
    "                ds_1, ds_2\n",
    "            )\n",
    "\n",
    "            station_names ={\"station_name_new\":stn_n_to_keep, \"old_stations\":stn_n_to_drop}\n",
    "\n",
    "            ds_final = _concat_export_help(\n",
    "                df_concat,\n",
    "                network_name,\n",
    "                attrs_new,\n",
    "                station_names  # stn_n_to_keep, stn_n_to_drop\n",
    "            )\n",
    "\n",
    "            final_concat_list.extend(stns_to_pair[\"ERA-ID\"].tolist())\n",
    "\n",
    "            # return ds_final, final_concat_list\n",
    "\n",
    "        else:\n",
    "            # If there are more than 2 stations in the given subset, pass to _more_than_2()\n",
    "            print(\"More than 2 stations within a subset\")\n",
    "            df_concat, station_names = _more_than_2(\n",
    "                network_name,\n",
    "                stns_to_pair,\n",
    "            )\n",
    "\n",
    "            if df_concat is None: # If the concentation failed\n",
    "                print('Concatenation of >2 stations was unsuccessful')\n",
    "            else: # If it was successful, move on to the next steps\n",
    "                # add station names to station name list\n",
    "                final_concat_list.extend(stns_to_pair[\"ERA-ID\"].tolist())\n",
    "\n",
    "                ds_final = _concat_export_help(\n",
    "                    df_concat,\n",
    "                    network_name,\n",
    "                    attrs_new,\n",
    "                    station_names  # stn_n_to_keep, stn_n_to_drop\n",
    "                )\n",
    "    print(\"Concatenated stations: \", final_concat_list)\n",
    "    return ds_final, final_concat_list\n",
    "    # return final_concat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASOSAWOS\n",
      "There are 12 stations to be concatenated into 5 station pairs within ASOSAWOS...\n",
      "['ASOSAWOS_0' 'ASOSAWOS_1' 'ASOSAWOS_2' 'ASOSAWOS_3' 'ASOSAWOS_4']\n",
      "ASOSAWOS_0\n",
      "\n",
      "                  ERA-ID concat_subset\n",
      "0  ASOSAWOS_99999903053    ASOSAWOS_0\n",
      "1  ASOSAWOS_A0001403053    ASOSAWOS_0\n",
      "Retrieving.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_99999903053.zarr\n",
      "Retrieving.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_A0001403053.zarr\n",
      "Station will be concatenated and saved as: ASOSAWOS_A0001403053\n",
      "No overlap!\n",
      "Exporting.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/TEST_concat_ASOSAWOS_A0001403053.zarr\n",
      "Concatenated stations:  ['ASOSAWOS_99999903053', 'ASOSAWOS_A0001403053']\n",
      "ASOSAWOS_1\n",
      "\n",
      "                  ERA-ID concat_subset\n",
      "2  ASOSAWOS_72269593041    ASOSAWOS_1\n",
      "3  ASOSAWOS_99999993041    ASOSAWOS_1\n",
      "Retrieving.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_72269593041.zarr\n",
      "Retrieving.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_99999993041.zarr\n",
      "Station will be concatenated and saved as: ASOSAWOS_72269593041\n",
      "No overlap!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1137/3097828338.py:54: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  df_concat = pd.merge(df_old, df_new, how=\"outer\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/TEST_concat_ASOSAWOS_72269593041.zarr\n",
      "Concatenated stations:  ['ASOSAWOS_99999903053', 'ASOSAWOS_A0001403053', 'ASOSAWOS_72269593041', 'ASOSAWOS_99999993041']\n",
      "ASOSAWOS_2\n",
      "\n",
      "                  ERA-ID concat_subset\n",
      "4  ASOSAWOS_72272093063    ASOSAWOS_2\n",
      "5  ASOSAWOS_72272193063    ASOSAWOS_2\n",
      "Retrieving.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_72272093063.zarr\n",
      "Retrieving.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/ASOSAWOS_72272193063.zarr\n",
      "Station will be concatenated and saved as: ASOSAWOS_72272193063\n",
      "There is overlap\n",
      "Exporting.... s3://wecc-historical-wx/3_qaqc_wx/ASOSAWOS/TEST_concat_ASOSAWOS_72272193063.zarr\n",
      "Concatenated stations:  ['ASOSAWOS_99999903053', 'ASOSAWOS_A0001403053', 'ASOSAWOS_72269593041', 'ASOSAWOS_99999993041', 'ASOSAWOS_72272093063', 'ASOSAWOS_72272193063']\n",
      "ASOSAWOS_3\n",
      "More than 2 stations within a subset\n",
      "\n",
      "                  ERA-ID concat_subset\n",
      "6  ASOSAWOS_74003503145    ASOSAWOS_3\n",
      "7  ASOSAWOS_72280503145    ASOSAWOS_3\n",
      "8  ASOSAWOS_69960403145    ASOSAWOS_3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DataArray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds_to_export, final_concat_list \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_station_pairs2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mASOSAWOS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 106\u001b[0m, in \u001b[0;36mconcatenate_station_pairs2\u001b[0;34m(network_name)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m#return ds_final, final_concat_list\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# If there are more than 2 stations in the given subset, pass to _more_than_2()\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than 2 stations within a subset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m     df_concat, station_names \u001b[38;5;241m=\u001b[39m \u001b[43m_more_than_2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnetwork_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstns_to_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df_concat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# If the concentation failed\u001b[39;00m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcatenation of >2 stations was unsuccessful\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[47], line 50\u001b[0m, in \u001b[0;36m_more_than_2\u001b[0;34m(network_name, stns_to_pair)\u001b[0m\n\u001b[1;32m     47\u001b[0m overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (end1 \u001b[38;5;241m<\u001b[39m start2 \u001b[38;5;129;01mor\u001b[39;00m end2 \u001b[38;5;241m<\u001b[39m start1)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overlap:\n\u001b[0;32m---> 50\u001b[0m     df_concat \u001b[38;5;241m=\u001b[39m \u001b[43m_overlap_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     df_concat \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat([result, ds], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msortby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[46], line 22\u001b[0m, in \u001b[0;36m_overlap_concat\u001b[0;34m(df_new, df_old)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_overlap_concat\u001b[39m(df_new,df_old):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Handles the cases in which there is overlap between the two input stations\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m            None\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     df_overlap \u001b[38;5;241m=\u001b[39m \u001b[43mdf_new\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_new\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_old\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m##### Split datframes into subsets #####\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Remove data in time overlap between old and new\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     df_old_cleaned \u001b[38;5;241m=\u001b[39m df_old[\u001b[38;5;241m~\u001b[39mdf_old[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(df_overlap[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/xarray/core/dataset.py:1500\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_dataarray(key)\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy_listed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/xarray/core/dataset.py:1359\u001b[0m, in \u001b[0;36mDataset._copy_listed\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1359\u001b[0m         variables[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   1361\u001b[0m         ref_name, var_name, var \u001b[38;5;241m=\u001b[39m _get_virtual_variable(\n\u001b[1;32m   1362\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables, name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_level_coords, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m   1363\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DataArray'"
     ]
    }
   ],
   "source": [
    "ds_to_export, final_concat_list = concatenate_station_pairs2(\"ASOSAWOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:               (station: 2, time: 1772773)\n",
       "Coordinates:\n",
       "  * station               (station) &lt;U20 &#x27;VALLEYWATER_6053&#x27; &#x27;VALLEYWATER_6144&#x27;\n",
       "  * time                  (time) datetime64[ns] 1974-06-21T08:15:00 ... 2025-...\n",
       "Data variables:\n",
       "    anemometer_height_m   (station, time) float64 nan nan nan ... nan nan nan\n",
       "    elevation             (station, time) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    elevation_eraqc       (station, time) float64 nan nan nan ... nan nan nan\n",
       "    lat                   (station, time) float64 37.33 37.33 ... 37.33 37.33\n",
       "    lon                   (station, time) float64 -122.1 -122.1 ... -122.1\n",
       "    pr_15min              (station, time) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    pr_15min_eraqc        (station, time) float64 nan nan nan ... nan nan nan\n",
       "    raw_qc                (station, time) object &#x27;Approved&#x27; ... &#x27;Prelimin&#x27;\n",
       "    thermometer_height_m  (station, time) float64 nan nan nan ... nan nan nan\n",
       "Attributes: (12/13)\n",
       "    Networks:           VALLEYWATER\n",
       "    comment:            Intermediary data product. This data has been subject...\n",
       "    disclaimer:         This document was prepared as a result of work funded...\n",
       "    history:            VALLEYWATER_clean.py script run on 01-28-2025, 01:32:...\n",
       "    institution:        Eagle Rock Analytics\n",
       "    license:            \n",
       "    ...                 ...\n",
       "    sensor_height_m:    nan\n",
       "    source:             \n",
       "    station_name:       Maryknoll Fields\n",
       "    title:              VALLEYWATER quality controlled\n",
       "    watershed:          Lower Peninsula\n",
       "    qaqc_files_merged:  VALLEYWATER_6053, VALLEYWATER_6144 merged. Overlap re...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-7ccde1ba-038f-487e-adb6-389ba9ebdd77' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-7ccde1ba-038f-487e-adb6-389ba9ebdd77' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>station</span>: 2</li><li><span class='xr-has-index'>time</span>: 1772773</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-7e49e4b4-08a1-4a09-b448-bb5211398557' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7e49e4b4-08a1-4a09-b448-bb5211398557' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>station</span></div><div class='xr-var-dims'>(station)</div><div class='xr-var-dtype'>&lt;U20</div><div class='xr-var-preview xr-preview'>&#x27;VALLEYWATER_6053&#x27; &#x27;VALLEYWATER_...</div><input id='attrs-b81f1b14-ff30-4bf6-b7ef-91e002eb043b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b81f1b14-ff30-4bf6-b7ef-91e002eb043b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-77b50c6f-b2c2-46a7-b4a6-166d4765aa04' class='xr-var-data-in' type='checkbox'><label for='data-77b50c6f-b2c2-46a7-b4a6-166d4765aa04' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;VALLEYWATER_6053&#x27;, &#x27;VALLEYWATER_6144&#x27;], dtype=&#x27;&lt;U20&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1974-06-21T08:15:00 ... 2025-01-...</div><input id='attrs-6213cf05-dbdd-422c-a746-81e3946a434f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6213cf05-dbdd-422c-a746-81e3946a434f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1e102575-6714-4425-a637-8e5a51972696' class='xr-var-data-in' type='checkbox'><label for='data-1e102575-6714-4425-a637-8e5a51972696' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;1974-06-21T08:15:00.000000000&#x27;, &#x27;1974-06-21T08:30:00.000000000&#x27;,\n",
       "       &#x27;1974-06-21T08:45:00.000000000&#x27;, ..., &#x27;2025-01-10T16:45:00.000000000&#x27;,\n",
       "       &#x27;2025-01-10T17:00:00.000000000&#x27;, &#x27;2025-01-10T17:15:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-5a581e24-804c-4f9e-83b5-f264e7fbd6c1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-5a581e24-804c-4f9e-83b5-f264e7fbd6c1' class='xr-section-summary' >Data variables: <span>(9)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>anemometer_height_m</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-9514db10-6aa0-43ea-acfb-11b1bbea4c26' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9514db10-6aa0-43ea-acfb-11b1bbea4c26' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f356bf03-3637-41b8-99e7-1d52f6930301' class='xr-var-data-in' type='checkbox'><label for='data-f356bf03-3637-41b8-99e7-1d52f6930301' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0</div><input id='attrs-ccf0059d-b503-432d-8c13-f63357cad478' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ccf0059d-b503-432d-8c13-f63357cad478' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d4f27358-9d7b-4e92-9218-02a3eee4c53c' class='xr-var-data-in' type='checkbox'><label for='data-d4f27358-9d7b-4e92-9218-02a3eee4c53c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[ 0.,  0.,  0., ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ...,  0.,  0.,  0.]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-f21dd682-3369-4686-a249-d4c8a9feddb7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f21dd682-3369-4686-a249-d4c8a9feddb7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e2999010-3e95-4d50-b1db-9ba1e4640382' class='xr-var-data-in' type='checkbox'><label for='data-e2999010-3e95-4d50-b1db-9ba1e4640382' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>37.33 37.33 37.33 ... 37.33 37.33</div><input id='attrs-365b8922-ec86-455f-b127-f5e453a358af' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-365b8922-ec86-455f-b127-f5e453a358af' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-36dd4af3-48e0-447e-9dee-595e5f32f323' class='xr-var-data-in' type='checkbox'><label for='data-36dd4af3-48e0-447e-9dee-595e5f32f323' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[37.3322, 37.3322, 37.3322, ...,     nan,     nan,     nan],\n",
       "       [    nan,     nan,     nan, ..., 37.3322, 37.3322, 37.3322]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-122.1 -122.1 ... -122.1 -122.1</div><input id='attrs-616915ef-ffd3-402e-96a4-eee211c4cbf1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-616915ef-ffd3-402e-96a4-eee211c4cbf1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-82ce41da-9c2c-46f9-98da-a0c45ea09849' class='xr-var-data-in' type='checkbox'><label for='data-82ce41da-9c2c-46f9-98da-a0c45ea09849' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-122.081, -122.081, -122.081, ...,      nan,      nan,      nan],\n",
       "       [     nan,      nan,      nan, ..., -122.081, -122.081, -122.081]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pr_15min</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0</div><input id='attrs-09d7d127-ffe1-406b-a26b-5376ebf0d70e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-09d7d127-ffe1-406b-a26b-5376ebf0d70e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b0264a44-42b4-4451-b787-86027b787bb4' class='xr-var-data-in' type='checkbox'><label for='data-b0264a44-42b4-4451-b787-86027b787bb4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[ 0.,  0.,  0., ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ...,  0.,  0.,  0.]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>pr_15min_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-6dd40d4a-7650-4dae-b3bb-1e9ed86c1141' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6dd40d4a-7650-4dae-b3bb-1e9ed86c1141' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a9039c83-13e6-414c-86c6-f8efce4c9f45' class='xr-var-data-in' type='checkbox'><label for='data-a9039c83-13e6-414c-86c6-f8efce4c9f45' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>raw_qc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;Approved&#x27; ... &#x27;Prelimin&#x27;</div><input id='attrs-d1de1825-5390-41cb-9d38-6f92c18b08ce' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d1de1825-5390-41cb-9d38-6f92c18b08ce' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e6c6ccd2-a55a-43aa-9494-e0c114507602' class='xr-var-data-in' type='checkbox'><label for='data-e6c6ccd2-a55a-43aa-9494-e0c114507602' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[&#x27;Approved&#x27;, &#x27;Approved&#x27;, &#x27;Approved&#x27;, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., &#x27;Prelimin&#x27;, &#x27;Prelimin&#x27;, &#x27;Prelimin&#x27;]],\n",
       "      dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>thermometer_height_m</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-c62c2586-c191-45dc-87c2-7346293d012d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c62c2586-c191-45dc-87c2-7346293d012d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-171d50c3-a69f-4a0c-932a-f8310edaa57c' class='xr-var-data-in' type='checkbox'><label for='data-171d50c3-a69f-4a0c-932a-f8310edaa57c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f0d2fc8b-1556-44b1-bafc-2df61a544c7c' class='xr-section-summary-in' type='checkbox'  ><label for='section-f0d2fc8b-1556-44b1-bafc-2df61a544c7c' class='xr-section-summary' >Attributes: <span>(13)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Networks :</span></dt><dd>VALLEYWATER</dd><dt><span>comment :</span></dt><dd>Intermediary data product. This data has been subjected to cleaning, QA/QC, but may not have been standardized.</dd><dt><span>disclaimer :</span></dt><dd>This document was prepared as a result of work funded by the Santa Clara Valley Water District. It does not necessarily represent the views of the Santa Clara Valley Water District or its employees. Neither the Santa Clara Valley Water District, nor it&#x27;s employees, contractors, or subcontractors makes any warranty, express or implied, or assumes any legal liability for the information in this document; nor does any party represent that the use of this information will not infringe upon privately owned rights. This document has not been approved or disapproved by Santa Clara Valley Water District, nor has the Santa Clara Valley Water District passed upon the accuracy of the information in this document.</dd><dt><span>history :</span></dt><dd>VALLEYWATER_clean.py script run on 01-28-2025, 01:32:09 UTC \n",
       "ALLNETWORKS_qaqc.py script run on 04-07-2025, 22:35:15 UTC \n",
       "station_matching.ipynb run on 04-20-2025, 21:48:06 UTC</dd><dt><span>institution :</span></dt><dd>Eagle Rock Analytics</dd><dt><span>license :</span></dt><dd></dd><dt><span>raw_files_merged :</span></dt><dd>1</dd><dt><span>sensor_height_m :</span></dt><dd>nan</dd><dt><span>source :</span></dt><dd></dd><dt><span>station_name :</span></dt><dd>Maryknoll Fields</dd><dt><span>title :</span></dt><dd>VALLEYWATER quality controlled</dd><dt><span>watershed :</span></dt><dd>Lower Peninsula</dd><dt><span>qaqc_files_merged :</span></dt><dd>VALLEYWATER_6053, VALLEYWATER_6144 merged. Overlap retained from newer station data.</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:               (station: 2, time: 1772773)\n",
       "Coordinates:\n",
       "  * station               (station) <U20 'VALLEYWATER_6053' 'VALLEYWATER_6144'\n",
       "  * time                  (time) datetime64[ns] 1974-06-21T08:15:00 ... 2025-...\n",
       "Data variables:\n",
       "    anemometer_height_m   (station, time) float64 nan nan nan ... nan nan nan\n",
       "    elevation             (station, time) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    elevation_eraqc       (station, time) float64 nan nan nan ... nan nan nan\n",
       "    lat                   (station, time) float64 37.33 37.33 ... 37.33 37.33\n",
       "    lon                   (station, time) float64 -122.1 -122.1 ... -122.1\n",
       "    pr_15min              (station, time) float64 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    pr_15min_eraqc        (station, time) float64 nan nan nan ... nan nan nan\n",
       "    raw_qc                (station, time) object 'Approved' ... 'Prelimin'\n",
       "    thermometer_height_m  (station, time) float64 nan nan nan ... nan nan nan\n",
       "Attributes: (12/13)\n",
       "    Networks:           VALLEYWATER\n",
       "    comment:            Intermediary data product. This data has been subject...\n",
       "    disclaimer:         This document was prepared as a result of work funded...\n",
       "    history:            VALLEYWATER_clean.py script run on 01-28-2025, 01:32:...\n",
       "    institution:        Eagle Rock Analytics\n",
       "    license:            \n",
       "    ...                 ...\n",
       "    sensor_height_m:    nan\n",
       "    source:             \n",
       "    station_name:       Maryknoll Fields\n",
       "    title:              VALLEYWATER quality controlled\n",
       "    watershed:          Lower Peninsula\n",
       "    qaqc_files_merged:  VALLEYWATER_6053, VALLEYWATER_6144 merged. Overlap re..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_to_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_station_pairs(network_name):\n",
    "    \"\"\"\n",
    "    Concatenates two input datasets, deletes the originals, and exports the final concatenated dataset. \n",
    "    Also returns a list of the ERA-IDs of all stations that are concatenated.\n",
    "\n",
    "    Rules\n",
    "    ------\n",
    "        1.) concatenation: keep the newer station data in the time range in which both stations overlap\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        network_name: string\n",
    "            weather station network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        if success: \n",
    "            return list of ERA-IDs are stations that are concatenated\n",
    "            all processed datasets are exported to the merge folder in AWS and the original datasets are deleted\n",
    "        if failure:\n",
    "            None\n",
    "    \"\"\"\n",
    "    ##### Read in concatenation list of input network\n",
    "    network_list = s3_cl.get_object(\n",
    "        Bucket=bucket,\n",
    "        Key=\"3_qaqc_wx/{}/concat_list_{}.csv\".format(\n",
    "            network_name, network_name, network_name\n",
    "        ),\n",
    "    )\n",
    "    concat_list = pd.read_csv(BytesIO(network_list[\"Body\"].read()))\n",
    "\n",
    "    # ! you can truncate the concat list here, for testing\n",
    "    concat_list = concat_list.head(2)\n",
    "    # ! end\n",
    "\n",
    "    subset_number = len(concat_list['concat_subset'].unique())\n",
    "\n",
    "    # initiate empty list, to which we will iteratively add the ERA-IDs of stations that are concatenated\n",
    "    final_concat_list = []\n",
    "\n",
    "    for i in range(0,subset_number):\n",
    "\n",
    "        # count the number of staions in subset i\n",
    "        subset_i = concat_list[\n",
    "            concat_list[\"concat_subset\"].str.contains(\"{}\".format(i))\n",
    "        ]\n",
    "\n",
    "        n = subset_i.count()[0]\n",
    "\n",
    "        # if there are only two stations, proceed with concatenation\n",
    "        if n == 2:\n",
    "            try: \n",
    "                # retrieve ERA IDs in this subset of stations\n",
    "                station_1 = subset_i[\"ERA-ID\"].iloc[0]\n",
    "                station_2 = subset_i[\"ERA-ID\"].iloc[1]\n",
    "\n",
    "                # import this subset of datasets and convert to dataframe\n",
    "                url_1 = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}.zarr\".format(\n",
    "                    network_name, station_1\n",
    "                )\n",
    "                url_2 = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}.zarr\".format(\n",
    "                    network_name, station_2\n",
    "                )\n",
    "\n",
    "                ds_1 = xr.open_zarr(url_1)\n",
    "                ds_2 = xr.open_zarr(url_2)\n",
    "\n",
    "                df_1,MultiIndex_1,attrs_1,var_attrs_1,era_qc_vars_1 = qaqc_ds_to_df(ds_1, verbose=False)\n",
    "                df_2, MultiIndex_2, attrs_2, var_attrs_2, era_qc_vars_2 = qaqc_ds_to_df(ds_2, verbose=False)\n",
    "\n",
    "                # determine which dataset is older\n",
    "                if df_1[\"time\"].max() < df_2[\"time\"].max():\n",
    "                    # if df_1 has an earlier end tiem than df_2, then d_2 is newer\n",
    "                    # we also grab the name of the newer station in this step, for use later\n",
    "                    df_new = df_2\n",
    "                    ds_new = ds_2\n",
    "                    MultiIndex_new = MultiIndex_2\n",
    "                    attrs_new = attrs_2\n",
    "\n",
    "                    df_old = df_1\n",
    "                    ds_old = ds_1\n",
    "                    MultiIndex_old = MultiIndex_1\n",
    "\n",
    "                else:\n",
    "                    df_new = df_1\n",
    "                    ds_new = df_1\n",
    "                    MultiIndex_new = MultiIndex_2\n",
    "                    attrs_new = attrs_2\n",
    "\n",
    "                    df_old = df_2\n",
    "                    ds_old = ds_2\n",
    "                    MultiIndex_old = MultiIndex_2\n",
    "\n",
    "                # now set things up to determine if there is temporal overlap between df_new and df_old\n",
    "                df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]\n",
    "\n",
    "                # if there is no overlap between the two time series, just concatenate\n",
    "                if len(df_overlap) == 0:\n",
    "                    df_concat = concat([df_old, df_new])\n",
    "\n",
    "                # if not, split into subsets and concatenate\n",
    "                else:\n",
    "                    ##### Split datframes into subsets #####\n",
    "\n",
    "                    # Remove data in time overlap between old and new\n",
    "                    df_old_cleaned = df_old[~df_old[\"time\"].isin(df_overlap[\"time\"])]\n",
    "                    df_new_cleaned = df_new[~df_new[\"time\"].isin(df_overlap[\"time\"])]\n",
    "\n",
    "                    ##### Concatenate subsets #####\n",
    "                    df_concat = concat([df_old_cleaned, df_overlap, df_new_cleaned])\n",
    "\n",
    "                # ##### Now prepare the final concatenated dataframe for export\n",
    "                station_name_new = MultiIndex_new.get_level_values(\"station\")[1]\n",
    "                \n",
    "                # ! This is where Neil and I made the change to address the issues\n",
    "                # ! \n",
    "                MultiIndex_old = pd.MultiIndex.from_tuples(\n",
    "                    [(station_name_new, lvl1) for _, lvl1 in MultiIndex_old],\n",
    "                    names=MultiIndex_new.names,\n",
    "                )\n",
    "\n",
    "                MultiIndex_concat = MultiIndex_new.union(MultiIndex_old)\n",
    "\n",
    "                # drop duplicate rows that were potentially generated in the concatenation process\n",
    "                df_concat = df_concat.drop_duplicates(subset=[\"time\"])\n",
    "\n",
    "                # drop 'station' and 'time'columns\n",
    "                df_concat = df_concat.drop([\"station\", \"time\",\"hour\",\"day\",\"month\",\"year\",\"date\"], axis=1)\n",
    "\n",
    "                print('length of MultiIndex_new')\n",
    "                print(len(MultiIndex_new))\n",
    "                print(\"length of MultiIndex_old\")\n",
    "                print(len(MultiIndex_old))\n",
    "                print(\"length of MultiIndex_concat\")\n",
    "                print(len(MultiIndex_concat))\n",
    "\n",
    "                print(\"length of df_new\")\n",
    "                print(len(df_new))\n",
    "                print(\"length of df_old\")\n",
    "                print(len(df_old))\n",
    "                print(\"length of df_concat\")\n",
    "                print(len(df_concat))\n",
    "\n",
    "                # ! This is where the issue! MultiIndex_concat and df_concat have difference lengths\n",
    "                df_concat.index = MultiIndex_concat\n",
    "\n",
    "                # # Convert concatenated dataframe to dataset\n",
    "                # ds_concat = df_concat.to_xarray()\n",
    "\n",
    "                # # #### Prepare for export #####\n",
    "\n",
    "                # # Convert datatype of station coordinate\n",
    "                # ds_concat.coords[\"station\"] = ds_concat.coords[\"station\"].astype(\"<U20\")\n",
    "\n",
    "                # # # Include past attributes\n",
    "                # ds_concat.attrs.update(attrs_new)\n",
    "\n",
    "                # # Update 'history' attribute\n",
    "                # timestamp = datetime.datetime.utcnow().strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "                # ds_concat.attrs[\"history\"] = ds_concat.attrs[\n",
    "                #     \"history\"\n",
    "                # ] + \" \\n maritime_merge.ipynb run on {} UTC\".format(timestamp)\n",
    "\n",
    "                # # Update 'comment' attribute\n",
    "                # ds_concat.attrs[\"comment\"] = (\n",
    "                #     \"Final v1 data product. This data has been subjected to cleaning, QA/QC, and standardization.\"\n",
    "                # )\n",
    "\n",
    "                # # Add new qaqc_files_merged attribute\n",
    "                # station_name_old = MultiIndex_old.get_level_values(\"station\")[1]\n",
    "                # ds_concat.attrs[\"qaqc_files_merged\"] = (\n",
    "                #     \"{}, {} merged. Overlap retained from newer station data.\".format(\n",
    "                #         station_name_old, station_name_new\n",
    "                #     )\n",
    "                # )\n",
    "\n",
    "                # ! this is here the renaming will go\n",
    "\n",
    "                # !\n",
    "\n",
    "                # ## Export ###\n",
    "                # ! a test name is used below\n",
    "                # ! the final name will be that of the newer dataframe\n",
    "                # export_url = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}_{}.zarr\".format(\n",
    "                #     network_name, \"test_concat\", station_name_new\n",
    "                # )\n",
    "                # ds_concat.to_zarr(export_url, mode=\"w\")\n",
    "\n",
    "                # record that the stations were concatenated\n",
    "                final_concat_list.append(station_1)\n",
    "                final_concat_list.append(station_2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Error concatenating subset {}: {}\".format(subset_i, e)\n",
    "                )\n",
    "        # if there are more than two stations in the subset, continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # return final_concat_list # ! this will be the final return statement, below is inlcluded for testing\n",
    "    # return (\n",
    "    #     df_new,\n",
    "    #     df_old,\n",
    "    #     df_concat,\n",
    "    #     ds_concat,\n",
    "    #     final_concat_list,\n",
    "    # )\n",
    "\n",
    "    return df_1, df_2, MultiIndex_1, MultiIndex_2, df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = \"MARITIME\" # \"VALLEYWATER\", \"MARITIME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of MultiIndex_new\n",
      "135209\n",
      "length of MultiIndex_old\n",
      "135209\n",
      "length of MultiIndex_concat\n",
      "135209\n",
      "length of df_new\n",
      "1409901\n",
      "length of df_old\n",
      "135209\n",
      "length of df_concat\n",
      "1509221\n",
      "Error concatenating subset            ERA-ID concat_subset\n",
      "0  MARITIME_LJAC1    MARITIME_0\n",
      "1  MARITIME_LJPC1    MARITIME_0: Length mismatch: Expected axis has 1509221 elements, new values have 135209 elements\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_1, df_2, MultiIndex_1, MultiIndex_2 \u001b[38;5;241m=\u001b[39m concatenate_station_pairs(network_name)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "df_1, df_2, MultiIndex_1, MultiIndex_2 = concatenate_station_pairs(network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-04-01 02:00:00\n",
      "2022-08-31 23:54:00\n"
     ]
    }
   ],
   "source": [
    "# LJAC1 - this should be new\n",
    "print(df_1['time'].min())\n",
    "print(df_1[\"time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-01-01 01:30:00\n",
      "2022-08-31 23:20:00\n"
     ]
    }
   ],
   "source": [
    "# LJPC1\n",
    "print(df_2[\"time\"].min())\n",
    "print(df_2[\"time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which dataset is older\n",
    "if df_2[\"time\"].max() > df_1[\"time\"].max():\n",
    "    # if df_1 has an earlier end tiem than df_2, then d_2 is newer\n",
    "    # we also grab the name of the newer station in this step, for use later\n",
    "    df_new = df_2\n",
    "    MultiIndex_new = MultiIndex_2\n",
    "\n",
    "    df_old = df_1\n",
    "    MultiIndex_old = MultiIndex_1\n",
    "\n",
    "else:\n",
    "    df_new = df_1\n",
    "    ds_new = df_1\n",
    "    MultiIndex_new = MultiIndex_1\n",
    "\n",
    "    df_old = df_2\n",
    "    MultiIndex_old = MultiIndex_2\n",
    "\n",
    "# now set things up to determine if there is temporal overlap between df_new and df_old\n",
    "df_overlap = df_new[df_new[\"time\"].isin(df_old[\"time\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is no overlap between the two time series, just concatenate\n",
    "if len(df_overlap) == 0:\n",
    "    df_concat = concat([df_old, df_new])\n",
    "\n",
    "# if not, split into subsets and concatenate\n",
    "else:\n",
    "    ##### Split datframes into subsets #####\n",
    "\n",
    "    # Remove data in time overlap between old and new\n",
    "    df_old_cleaned = df_old[~df_old[\"time\"].isin(df_overlap[\"time\"])]\n",
    "    df_new_cleaned = df_new[~df_new[\"time\"].isin(df_overlap[\"time\"])]\n",
    "\n",
    "    ##### Concatenate subsets #####\n",
    "    df_concat = concat([df_old_cleaned, df_overlap, df_new_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Now prepare the final concatenated dataframe for export\n",
    "station_name_new = MultiIndex_new.get_level_values(\"station\")[1]\n",
    "\n",
    "MultiIndex_old = pd.MultiIndex.from_tuples(\n",
    "    [(station_name_new, lvl1) for _, lvl1 in MultiIndex_old],\n",
    "    names=MultiIndex_new.names,\n",
    ")\n",
    "\n",
    "MultiIndex_concat = MultiIndex_new.union(MultiIndex_old)\n",
    "\n",
    "\n",
    "# MultiIndex_concat = pd.MultiIndex.from_tuples(\n",
    "#     [(station_name_new, lvl1) for _, lvl1 in MultiIndex_concat],\n",
    "#     names=MultiIndex_concat.names,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows that were potentially generated in the concatenation process\n",
    "df_concat = df_concat.drop_duplicates(subset=[\"time\"])\n",
    "\n",
    "# drop 'station' and 'time'columns\n",
    "df_concat = df_concat.drop([\"station\", \"time\",\"hour\",\"day\",\"month\",\"year\",\"date\"], axis=1)\n",
    "\n",
    "df_concat.index = MultiIndex_concat\n",
    "\n",
    "# Convert concatenated dataframe to dataset\n",
    "ds_concat = df_concat.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:               (station: 1, time: 1509221)\n",
       "Coordinates:\n",
       "  * station               (station) object &#x27;MARITIME_LJAC1&#x27;\n",
       "  * time                  (time) datetime64[ns] 2005-01-01T01:30:00 ... 2022-...\n",
       "Data variables: (12/14)\n",
       "    anemometer_height_m   (station, time) float64 20.2 20.2 20.2 ... 8.2 8.2 8.2\n",
       "    elevation             (station, time) float64 0.0 0.0 0.0 ... 9.3 9.3 9.3\n",
       "    elevation_eraqc       (station, time) float64 nan nan nan ... nan nan nan\n",
       "    lat                   (station, time) float64 32.87 32.87 ... 32.87 32.87\n",
       "    lon                   (station, time) float64 -117.3 -117.3 ... -117.3\n",
       "    sfcWind               (station, time) float64 2.0 2.0 2.0 ... 2.7 2.9 3.1\n",
       "    ...                    ...\n",
       "    sfcWind_eraqc         (station, time) float64 nan nan nan ... nan nan nan\n",
       "    tas                   (station, time) float64 286.3 286.4 ... 296.3 296.4\n",
       "    tas_eraqc             (station, time) float64 nan nan nan ... nan nan nan\n",
       "    thermometer_height_m  (station, time) float64 6.1 6.1 6.1 ... 7.2 7.2 7.2\n",
       "    ps                    (station, time) float64 nan nan ... 1.008e+05\n",
       "    ps_eraqc              (station, time) float64 nan nan nan ... nan nan nan</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-6ff2a933-78f9-4abf-ad95-49e83f20f0fd' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-6ff2a933-78f9-4abf-ad95-49e83f20f0fd' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>station</span>: 1</li><li><span class='xr-has-index'>time</span>: 1509221</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-2ea46e43-85b4-41ed-92cc-a3dcb6aca88d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-2ea46e43-85b4-41ed-92cc-a3dcb6aca88d' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>station</span></div><div class='xr-var-dims'>(station)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;MARITIME_LJAC1&#x27;</div><input id='attrs-0793d75b-2d40-4497-b910-cf8152b599bc' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0793d75b-2d40-4497-b910-cf8152b599bc' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-edbb207f-6491-4152-aa8d-b3caffe63236' class='xr-var-data-in' type='checkbox'><label for='data-edbb207f-6491-4152-aa8d-b3caffe63236' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;MARITIME_LJAC1&#x27;], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2005-01-01T01:30:00 ... 2022-08-...</div><input id='attrs-20828731-6de7-4a35-8caf-c7d92274b326' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-20828731-6de7-4a35-8caf-c7d92274b326' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-078f78ba-d37f-4527-b839-90732bfbdda5' class='xr-var-data-in' type='checkbox'><label for='data-078f78ba-d37f-4527-b839-90732bfbdda5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2005-01-01T01:30:00.000000000&#x27;, &#x27;2005-01-01T02:30:00.000000000&#x27;,\n",
       "       &#x27;2005-01-01T03:30:00.000000000&#x27;, ..., &#x27;2022-08-31T23:42:00.000000000&#x27;,\n",
       "       &#x27;2022-08-31T23:48:00.000000000&#x27;, &#x27;2022-08-31T23:54:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-57b167cb-b220-4427-9147-1e1e590d2a2b' class='xr-section-summary-in' type='checkbox'  checked><label for='section-57b167cb-b220-4427-9147-1e1e590d2a2b' class='xr-section-summary' >Data variables: <span>(14)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>anemometer_height_m</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>20.2 20.2 20.2 20.2 ... 8.2 8.2 8.2</div><input id='attrs-2086609a-6a43-4c9d-91fe-c73cb5c16bdb' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2086609a-6a43-4c9d-91fe-c73cb5c16bdb' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5ee6faf9-bcd6-4bcb-ab0c-7e2e38e3d560' class='xr-var-data-in' type='checkbox'><label for='data-5ee6faf9-bcd6-4bcb-ab0c-7e2e38e3d560' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[20.2, 20.2, 20.2, ...,  8.2,  8.2,  8.2]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 0.0 0.0 0.0 ... 9.3 9.3 9.3 9.3</div><input id='attrs-d155e54b-170b-4f2b-9a57-a18c9601b9ef' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d155e54b-170b-4f2b-9a57-a18c9601b9ef' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-46f5e834-aeb5-47ac-806d-f2cd32f96b6e' class='xr-var-data-in' type='checkbox'><label for='data-46f5e834-aeb5-47ac-806d-f2cd32f96b6e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[0. , 0. , 0. , ..., 9.3, 9.3, 9.3]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>elevation_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-f1f38619-adcd-453f-95b6-8d8f7d925ae3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f1f38619-adcd-453f-95b6-8d8f7d925ae3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6cd767ba-4c1a-4f8b-87dc-1daf21bcf0b2' class='xr-var-data-in' type='checkbox'><label for='data-6cd767ba-4c1a-4f8b-87dc-1daf21bcf0b2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>32.87 32.87 32.87 ... 32.87 32.87</div><input id='attrs-9242f33f-579d-4296-91c2-93d273dbe8f5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9242f33f-579d-4296-91c2-93d273dbe8f5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a90ec21a-f312-488c-8e2a-1562a7fdbac5' class='xr-var-data-in' type='checkbox'><label for='data-a90ec21a-f312-488c-8e2a-1562a7fdbac5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[32.867, 32.867, 32.867, ..., 32.867, 32.867, 32.867]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-117.3 -117.3 ... -117.3 -117.3</div><input id='attrs-d202da07-aab3-43a8-8ecd-b699226fff25' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d202da07-aab3-43a8-8ecd-b699226fff25' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-26b03f22-cba0-44bd-a8a2-05ff7c300d3e' class='xr-var-data-in' type='checkbox'><label for='data-26b03f22-cba0-44bd-a8a2-05ff7c300d3e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-117.257, -117.257, -117.257, ..., -117.257, -117.257, -117.257]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sfcWind</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>2.0 2.0 2.0 3.0 ... 2.9 2.7 2.9 3.1</div><input id='attrs-f1d5c3f1-7fa4-49a6-9f84-d465fedbf6f7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f1d5c3f1-7fa4-49a6-9f84-d465fedbf6f7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2b6ecf4e-03f6-43c8-aceb-ce28c5691455' class='xr-var-data-in' type='checkbox'><label for='data-2b6ecf4e-03f6-43c8-aceb-ce28c5691455' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[2. , 2. , 2. , ..., 2.7, 2.9, 3.1]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sfcWind_dir</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>280.0 310.0 310.0 ... 23.0 24.0</div><input id='attrs-111c09bb-b9dd-4145-aef2-c7582b9ac0b4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-111c09bb-b9dd-4145-aef2-c7582b9ac0b4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-74248b56-4997-4f71-a71f-ac9a5acc5c32' class='xr-var-data-in' type='checkbox'><label for='data-74248b56-4997-4f71-a71f-ac9a5acc5c32' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[280., 310., 310., ...,  17.,  23.,  24.]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sfcWind_dir_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-69b5da10-3dad-4859-98b2-bb77336fa658' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-69b5da10-3dad-4859-98b2-bb77336fa658' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-709da78b-04c3-423e-a9cd-881ee95606b7' class='xr-var-data-in' type='checkbox'><label for='data-709da78b-04c3-423e-a9cd-881ee95606b7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sfcWind_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-3aa8eb8b-b501-4e38-ada1-d1457c8cdb61' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3aa8eb8b-b501-4e38-ada1-d1457c8cdb61' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a196da83-7e26-4382-8605-40155eade267' class='xr-var-data-in' type='checkbox'><label for='data-a196da83-7e26-4382-8605-40155eade267' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tas</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>286.3 286.4 286.5 ... 296.3 296.4</div><input id='attrs-247bdb6e-1fb5-4014-81cb-0096a97ff896' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-247bdb6e-1fb5-4014-81cb-0096a97ff896' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-cd74f786-7eea-4211-8870-bcd6cc5badb0' class='xr-var-data-in' type='checkbox'><label for='data-cd74f786-7eea-4211-8870-bcd6cc5badb0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[286.35, 286.45, 286.55, ..., 296.35, 296.35, 296.45]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tas_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-58a83c20-ee8a-43ef-aac3-d5e0dc744e30' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-58a83c20-ee8a-43ef-aac3-d5e0dc744e30' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3c6f6613-8db2-4a6b-83f6-c3fdd9e2ecaa' class='xr-var-data-in' type='checkbox'><label for='data-3c6f6613-8db2-4a6b-83f6-c3fdd9e2ecaa' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>thermometer_height_m</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>6.1 6.1 6.1 6.1 ... 7.2 7.2 7.2 7.2</div><input id='attrs-8eb82f8f-6872-4930-bc8f-87c8088ac931' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8eb82f8f-6872-4930-bc8f-87c8088ac931' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a1e73dfc-7d31-49cd-972a-9d70745ac039' class='xr-var-data-in' type='checkbox'><label for='data-a1e73dfc-7d31-49cd-972a-9d70745ac039' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[6.1, 6.1, 6.1, ..., 7.2, 7.2, 7.2]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>ps</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan ... 1.008e+05 1.008e+05</div><input id='attrs-dbc680a2-5f5f-42ba-a2d8-0816cc5b3b4c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-dbc680a2-5f5f-42ba-a2d8-0816cc5b3b4c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0b5bccf3-6af7-4aaa-99bc-10a0828e7d52' class='xr-var-data-in' type='checkbox'><label for='data-0b5bccf3-6af7-4aaa-99bc-10a0828e7d52' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[    nan,     nan,     nan, ..., 100800., 100800., 100800.]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>ps_eraqc</span></div><div class='xr-var-dims'>(station, time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-6509941d-b5ad-44b4-8e54-0c610d1764de' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6509941d-b5ad-44b4-8e54-0c610d1764de' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-508930d7-ce8b-46fd-86eb-ad4e41a2621e' class='xr-var-data-in' type='checkbox'><label for='data-508930d7-ce8b-46fd-86eb-ad4e41a2621e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8132017f-5965-4d82-86d7-0003bf794ab2' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-8132017f-5965-4d82-86d7-0003bf794ab2' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:               (station: 1, time: 1509221)\n",
       "Coordinates:\n",
       "  * station               (station) object 'MARITIME_LJAC1'\n",
       "  * time                  (time) datetime64[ns] 2005-01-01T01:30:00 ... 2022-...\n",
       "Data variables: (12/14)\n",
       "    anemometer_height_m   (station, time) float64 20.2 20.2 20.2 ... 8.2 8.2 8.2\n",
       "    elevation             (station, time) float64 0.0 0.0 0.0 ... 9.3 9.3 9.3\n",
       "    elevation_eraqc       (station, time) float64 nan nan nan ... nan nan nan\n",
       "    lat                   (station, time) float64 32.87 32.87 ... 32.87 32.87\n",
       "    lon                   (station, time) float64 -117.3 -117.3 ... -117.3\n",
       "    sfcWind               (station, time) float64 2.0 2.0 2.0 ... 2.7 2.9 3.1\n",
       "    ...                    ...\n",
       "    sfcWind_eraqc         (station, time) float64 nan nan nan ... nan nan nan\n",
       "    tas                   (station, time) float64 286.3 286.4 ... 296.3 296.4\n",
       "    tas_eraqc             (station, time) float64 nan nan nan ... nan nan nan\n",
       "    thermometer_height_m  (station, time) float64 6.1 6.1 6.1 ... 7.2 7.2 7.2\n",
       "    ps                    (station, time) float64 nan nan ... 1.008e+05\n",
       "    ps_eraqc              (station, time) float64 nan nan nan ... nan nan nan"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union is the issue - mismatch in timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-04-01 02:00:00\n",
      "2022-08-31 23:54:00\n"
     ]
    }
   ],
   "source": [
    "print(df_1['time'].min())\n",
    "print(df_1[\"time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-01-01 01:30:00\n",
      "2022-08-31 23:20:00\n"
     ]
    }
   ],
   "source": [
    "print(df_2[\"time\"].min())\n",
    "print(df_2[\"time\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_concat should span 2005-01-01 01:30:00 - 2022-08-31 23:54:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1509221"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MultiIndex_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1509221"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'anemometer_height_m', 'elevation', 'elevation_eraqc', 'lat',\n",
       "       'lon', 'sfcWind', 'sfcWind_dir', 'sfcWind_dir_eraqc', 'sfcWind_eraqc',\n",
       "       'tas', 'tas_eraqc', 'thermometer_height_m', 'station', 'hour', 'day',\n",
       "       'month', 'year', 'date', 'ps', 'ps_eraqc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows that were potentially generated in the concatenation process\n",
    "df_concat_drop_dups = df_concat.drop_duplicates(subset=[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1509221"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_concat_drop_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiIndex_concat and df_concat_drop_dups['time']\n",
    "index_time = list(MultiIndex_1.get_level_values(\"time\"))\n",
    "#df_time = list(df_concat_drop_dups['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-04-01 02:00:00', '2005-04-01 03:00:00',\n",
       "               '2005-04-01 04:00:00', '2005-04-01 05:00:00',\n",
       "               '2005-04-01 06:00:00', '2005-04-01 07:00:00',\n",
       "               '2005-04-01 08:00:00', '2005-04-01 09:00:00',\n",
       "               '2005-04-01 10:00:00', '2005-04-01 11:00:00',\n",
       "               ...\n",
       "               '2022-08-31 23:00:00', '2022-08-31 23:06:00',\n",
       "               '2022-08-31 23:12:00', '2022-08-31 23:18:00',\n",
       "               '2022-08-31 23:24:00', '2022-08-31 23:30:00',\n",
       "               '2022-08-31 23:36:00', '2022-08-31 23:42:00',\n",
       "               '2022-08-31 23:48:00', '2022-08-31 23:54:00'],\n",
       "              dtype='datetime64[ns]', name='time', length=1409901, freq=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiIndex_1.get_level_values(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2005-04-01 02:00:00\n",
       "1         2005-04-01 03:00:00\n",
       "2         2005-04-01 04:00:00\n",
       "3         2005-04-01 05:00:00\n",
       "4         2005-04-01 06:00:00\n",
       "                  ...        \n",
       "1409896   2022-08-31 23:30:00\n",
       "1409897   2022-08-31 23:36:00\n",
       "1409898   2022-08-31 23:42:00\n",
       "1409899   2022-08-31 23:48:00\n",
       "1409900   2022-08-31 23:54:00\n",
       "Name: time, Length: 1409901, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2005-01-01 01:30:00\n",
       "1         2005-01-01 02:30:00\n",
       "2         2005-01-01 03:30:00\n",
       "3         2005-01-01 04:30:00\n",
       "4         2005-01-01 05:30:00\n",
       "                  ...        \n",
       "1409896   2022-08-31 23:30:00\n",
       "1409897   2022-08-31 23:36:00\n",
       "1409898   2022-08-31 23:42:00\n",
       "1409899   2022-08-31 23:48:00\n",
       "1409900   2022-08-31 23:54:00\n",
       "Name: time, Length: 1509221, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df_concat[df_concat['time'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>anemometer_height_m</th>\n",
       "      <th>elevation</th>\n",
       "      <th>elevation_eraqc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind_dir_eraqc</th>\n",
       "      <th>sfcWind_eraqc</th>\n",
       "      <th>...</th>\n",
       "      <th>tas_eraqc</th>\n",
       "      <th>thermometer_height_m</th>\n",
       "      <th>station</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>ps</th>\n",
       "      <th>ps_eraqc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, anemometer_height_m, elevation, elevation_eraqc, lat, lon, sfcWind, sfcWind_dir, sfcWind_dir_eraqc, sfcWind_eraqc, tas, tas_eraqc, thermometer_height_m, station, hour, day, month, year, date, ps, ps_eraqc]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'station' and 'time'columns\n",
    "df_concat = df_concat.drop(\n",
    "    [\"station\", \"time\", \"hour\", \"day\", \"month\", \"year\", \"date\"], axis=1\n",
    ")\n",
    "\n",
    "df_concat.index = MultiIndex_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test option 1\n",
    "\n",
    "Run concatenate_station_pairs() as is, so the function does not export and instead returns df_concat, df_new, df_old, and df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error concatenation stations of subset            ERA-ID concat_subset\n",
      "0  MARITIME_LJAC1    MARITIME_0\n",
      "1  MARITIME_LJPC1    MARITIME_0: Length mismatch: Expected axis has 1509221 elements, new values have 135209 elements\n",
      "Error concatenation stations of subset            ERA-ID concat_subset\n",
      "2  MARITIME_ICAC1    MARITIME_1\n",
      "3  MARITIME_SMOC1    MARITIME_1: Length mismatch: Expected axis has 1367110 elements, new values have 282368 elements\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ds_concat' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m     df_new,\n\u001b[1;32m      3\u001b[0m     df_old,\n\u001b[1;32m      4\u001b[0m     df_concat,\n\u001b[1;32m      5\u001b[0m     ds_concat,\n\u001b[1;32m      6\u001b[0m     final_concat_list,\n\u001b[0;32m----> 7\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_station_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[128], line 181\u001b[0m, in \u001b[0;36mconcatenate_station_pairs\u001b[0;34m(network_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# return final_concat_list # ! this will be the final return statement, below is inlcluded for testing\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    178\u001b[0m     df_new,\n\u001b[1;32m    179\u001b[0m     df_old,\n\u001b[1;32m    180\u001b[0m     df_concat,\n\u001b[0;32m--> 181\u001b[0m     \u001b[43mds_concat\u001b[49m,\n\u001b[1;32m    182\u001b[0m     final_concat_list,\n\u001b[1;32m    183\u001b[0m )\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'ds_concat' referenced before assignment"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_new,\n",
    "    df_old,\n",
    "    df_concat,\n",
    "    ds_concat,\n",
    "    final_concat_list,\n",
    ") = concatenate_station_pairs(network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df_concat.reset_index(level=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test option 2: \n",
    "\n",
    "Run concatenate_station_pairs() with the first return statement uncommented and the second commented, and the export section uncommented. So that the function actually exports the concatenated datasets. I've generated all the concatention lists (for VALLEYWATER, MARITIME, and ASOSAWOS) needed to run the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = concatenate_station_pairs(network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import output\n",
    "# TODO: you'll need to change the url\n",
    "url_output = \"s3://wecc-historical-wx/3_qaqc_wx/{}/test_concat_{}.zarr\".format(\n",
    "    network_name, network_name\n",
    ")\n",
    "\n",
    "# TODO: open_zarr will be used for QAQC'd datasets\n",
    "ds_concat = xr.open_zarr(url_output)\n",
    "\n",
    "df_concat = ds_concat.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_list = s3_cl.get_object(\n",
    "    Bucket=bucket,\n",
    "    Key=\"3_qaqc_wx/{}/{}_concat_list_{}.csv\".format(\n",
    "        network_name, network_name, network_name\n",
    "    ),\n",
    ")\n",
    "concat_list = pd.read_csv(BytesIO(network_list[\"Body\"].read()))\n",
    "station_1 = concat_list[\"ERA-ID\"].iloc[0]\n",
    "station_2 = concat_list[\"ERA-ID\"].iloc[1]\n",
    "\n",
    "# import this subset of datasets and convert to dataframe\n",
    "url_1 = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}.zarr\".format(network_name, station_1)\n",
    "url_2 = \"s3://wecc-historical-wx/3_qaqc_wx/{}/{}.zarr\".format(network_name, station_2)\n",
    "\n",
    "ds_1 = xr.open_zarr(url_1)\n",
    "ds_2 = xr.open_zarr(url_2)\n",
    "\n",
    "df_1 = ds_1.to_dataframe()\n",
    "df_2 = ds_2.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract time index for plotting\n",
    "df_1 = df_1.reset_index(level=\"time\")\n",
    "df_2 = df_2.reset_index(level=\"time\")\n",
    "\n",
    "\n",
    "df_concat = df_concat.reset_index(level=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_1[\"time\"].max() < df_2[\"time\"].max(): \n",
    "    # if df_1 has an earlier end tiem than df_2, then d_2 is newer\n",
    "    # we also grab the name of the newer station in this step, for use later\n",
    "    df_new = df_2\n",
    "    ds_new = ds_2\n",
    "\n",
    "    df_old = df_1\n",
    "    ds_old = ds_1\n",
    "else:\n",
    "    df_new = df_1\n",
    "    ds_new = ds_1\n",
    "\n",
    "    df_old = df_2\n",
    "    ds_old = ds_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now set things up to determine if there is temporal overlap between df_new and df_old\n",
    "df_new_overlap = df_new[df_new[\"time\"].isin(df_concat[\"time\"])]\n",
    "df_concat_overlap = df_concat[df_concat[\"time\"].isin(df_new[\"time\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_overlap.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_overlap.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the two original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_var = 'ps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a specific size\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plotting the time series of given dataframe\n",
    "plt.plot(df_new[\"time\"], df_new[vis_var])\n",
    "\n",
    "# Plotting the time series of given dataframe\n",
    "plt.plot(df_old[\"time\"], df_old[vis_var])\n",
    "\n",
    "# Giving title to the chart using plt.title\n",
    "plt.title(\"input dfs\")\n",
    "\n",
    "# rotating the x-axis tick labels at 30degree\n",
    "# towards right\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "# Providing x and y label to the chart\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(vis_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the output dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a specific size\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plotting the time series of given dataframe\n",
    "plt.plot(df_concat[\"time\"], df_concat[vis_var])\n",
    "\n",
    "# Giving title to the chart using plt.title\n",
    "plt.title(\"concatenated df\")\n",
    "\n",
    "# rotating the x-axis tick labels at 30degree\n",
    "# towards right\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "# Providing x and y label to the chart\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(vis_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Mark stations that have been concatenated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
