{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c073d99",
   "metadata": {},
   "source": [
    "# Generate summed flag count tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb392abe",
   "metadata": {},
   "source": [
    "This notebook creates QAQC flag counts csv files per network from the corresponding eraqc_counts_timestep files that were generated as a part of the final processing step for stations within the Historical Data Pipeline. These tables are used to then generate statistics for the QAQC success report.\n",
    "\n",
    "This is carried out in two steps:\n",
    "\n",
    "1. Generate the per-network QAQC flag count tables, at native and hourly timesteps\n",
    "\n",
    "2. Generates one flag count table that sums all per-network tables, at native and hourly timesteps\n",
    "\n",
    "\n",
    "Using the following functions:\n",
    "\n",
    "\n",
    "- _pairwise_sum(): helper function that merges two input flag tables, used by network_sum_flag_counts() and total_sum_flag_counts().\n",
    "\n",
    "- network_sum_flag_counts(): sums all station flag count tables for a given network, creating one flag count table for that network\n",
    "\n",
    "- generate_station_tables(): runs network_sum_flag_counts() for every network\n",
    "\n",
    "- total_sum_flag_counts(): sums all network flag count tables, creating one final flag count table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce425205",
   "metadata": {},
   "source": [
    "## Step 0: Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from functools import reduce\n",
    "\n",
    "import inspect\n",
    "\n",
    "import logging\n",
    "# Create a simple logger that just prints to the console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "stations_csv_path = f\"s3://{bucket_name}/2_clean_wx/temp_clean_all_station_list.csv\"\n",
    "qaqc_dir = \"3_qaqc_wx\"\n",
    "merge_dir = \"4_merge_wx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7594f1f",
   "metadata": {},
   "source": [
    "### The functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_sum(flag_df_1, flag_df_2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts(). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df_1: pd.DataFrame\n",
    "        dataframe of previously summed station flag counts\n",
    "    flag_df_2: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summed_df: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    if len(flag_df_1) == 0:\n",
    "        return flag_df_2\n",
    "    else:\n",
    "        total_df = pd.concat([flag_df_1, flag_df_2])\n",
    "\n",
    "        summed_df = total_df.groupby('eraqc_flag_values', as_index=False).sum(numeric_only=True)\n",
    "        return summed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_table(\n",
    "    summed_counts: pd.DataFrame, flag_table: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A helper function that formats the network-level counts tables\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summed_counts: pd.DataFrame\n",
    "        dataframe of summed station flag counts\n",
    "    flag_table: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_format: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    ## Format flag meanings df\n",
    "    flag_table = flag_table.rename(columns={\"Flag_value\": \"eraqc_flag_values\"})\n",
    "\n",
    "    ## Format summed counts df\n",
    "\n",
    "    # remove the \".0\" from the flag values\n",
    "    summed_counts[\"eraqc_flag_values\"] = summed_counts[\"eraqc_flag_values\"].str.replace(\n",
    "        \".0\", \"\", regex=True\n",
    "    )\n",
    "\n",
    "    # convert flag value strings to integers\n",
    "    # ! this is old code, keeping here in case related to error\n",
    "    summed_counts[\"eraqc_flag_values\"] = summed_counts[\"eraqc_flag_values\"].apply(\n",
    "        lambda x: int(x) if x not in [\"no_flag\", \"total_obs_count\"] else x\n",
    "    )\n",
    "    summed_counts = summed_counts.applymap(lambda x: int(x) if not isinstance(x, str) else x)\n",
    "\n",
    "    ## Merge the the counts and flag meanings dataframes\n",
    "    print(f\"what is flag_table up do? before merged with summed_ counts: {flag_table}\")\n",
    "    print(f\"what is summed_counts up do? before merged with flag_table: {summed_counts}\")\n",
    "    merged_dfs = summed_counts.merge(flag_table, on=\"eraqc_flag_values\", how=\"outer\")\n",
    "\n",
    "    ## Format final dataframe\n",
    "\n",
    "    # order by flag value, in descending numerical order\n",
    "    final_format = (\n",
    "        merged_dfs.groupby(\n",
    "            merged_dfs.eraqc_flag_values.apply(type) != str, group_keys=True\n",
    "        )\n",
    "        .apply(lambda g: g.sort_values(\"eraqc_flag_values\"))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # move string flag value entries to the bottom\n",
    "    final_format = final_format.loc[\n",
    "        pd.to_numeric(final_format[\"eraqc_flag_values\"], errors=\"coerce\").sort_values().index\n",
    "    ]\n",
    "\n",
    "    return final_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789809ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_format_table(\n",
    "    summed_counts: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A helper function that formats the final, 'total' counts table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summed_counts: pd.DataFrame\n",
    "        dataframe of summed station flag counts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_format: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert flag value strings to integers\n",
    "\n",
    "    # ! this is old code, keeping here in case related to error\n",
    "    # summed_counts[\"eraqc_flag_values\"] = summed_counts['eraqc_flag_values'].apply(\n",
    "    #     lambda x: int(x) if x not in [\"no_flag\", \"total_obs_count\"] else x\n",
    "    # )\n",
    "    summed_counts = summed_counts.applymap(\n",
    "        lambda x: int(x) if not isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "    ## Format final dataframe\n",
    "\n",
    "    # order by flag value, in descending numerical order\n",
    "    final_format = (summed_counts.groupby(\n",
    "            summed_counts.eraqc_flag_values.apply(type) != str, group_keys=True\n",
    "        )\n",
    "        .apply(lambda g: g.sort_values(\"eraqc_flag_values\"))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # move string flag value entries to the bottom\n",
    "    final_format = final_format.loc[\n",
    "        pd.to_numeric(final_format[\"eraqc_flag_values\"], errors=\"coerce\").sort_values().index\n",
    "    ]\n",
    "\n",
    "    return final_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_sum_flag_counts(network: str, timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all station QAQC flag counts in a network for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network: str\n",
    "        network name\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    # read in flag meanings CSV\n",
    "\n",
    "    flag_meanings = pd.read_csv(\"era_qaqc_flag_meanings.csv\")\n",
    "\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing station flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    counts_final =_format_table(summed_counts_df, flag_meanings)\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_{timestep}_timestep/{network}_flag_counts_{timestep}_timestep.csv\"\n",
    "    counts_final.to_csv(csv_s3_filepath, index=False)\n",
    "    print(\n",
    "        f\"Sending summed counts dataframe for {network} to: {csv_s3_filepath}\"\n",
    "    )\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cf721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_flag_counts(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all network-level QAQC flag counts for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing network-level flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/per_network_flag_counts_{timestep}_timestep\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all networks CSVs\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            print(f'summing for {item.key}')\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    # format final table\n",
    "    final_table = _total_format_table(summed_counts_df)\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "    if len(summed_counts_df) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        csv_s3_filepath = (\n",
    "            f\"s3://wecc-historical-wx/4_merge_wx/total_flag_counts_{timestep}_timestep.csv\"\n",
    "        )\n",
    "        final_table.to_csv(csv_s3_filepath, index=False)\n",
    "        print(f\"Sending final summed counts dataframe for to: {csv_s3_filepath}\")\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_station_tables(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Runs network_sum_flag_counts() for every network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    # record start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    station_list = pd.read_csv(stations_csv_path)\n",
    "    network_list = station_list[\"network\"].unique()\n",
    "\n",
    "    for network in network_list:\n",
    "        network_sum_flag_counts(network, timestep)\n",
    "\n",
    "    # record end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # output time elapsed\n",
    "    time_elapsed = (end_time - start_time) / 60\n",
    "    print(f\"{time_elapsed} minutes\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b4f2e",
   "metadata": {},
   "source": [
    "## Step 1: Generate flag sum tables for ever network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47140f",
   "metadata": {},
   "source": [
    "First, loop through every network, combining each of their station flag count tables into one table. The result is one flag count table at each timestep - native and hourly - for every network.\n",
    "\n",
    "This will take around 1 hour to run for both timesteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### this is where the issue pops up! \n",
    "# something to do with merging the flag meanings table with the counts table\n",
    "# potentially related to how I convert strins to integers? see red comments in the format helper functions\n",
    "\n",
    "generate_station_tables('hourly')\n",
    "\n",
    "# 22 minutes for 27 networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_station_tables(\"hourly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a8aa6",
   "metadata": {},
   "source": [
    "## Step 2: Generate total flag sum table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ad66c",
   "metadata": {},
   "source": [
    "Now combine all the network flag count tables generated in step 1 into one final flag count table. First at the hourly timestep, and then at the native timestep.\n",
    "\n",
    "Step 1 must be complete before moving on to this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa00dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_total = total_sum_flag_counts('native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_flag_counts('hourly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
