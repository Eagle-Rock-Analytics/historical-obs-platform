{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c073d99",
   "metadata": {},
   "source": [
    "# Generate summed flag count tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb392abe",
   "metadata": {},
   "source": [
    "This notebook creates QAQC flag counts csv files per network from the corresponding eraqc_counts_timestep files that were generated as a part of the final processing step for stations within the Historical Data Pipeline. These tables are used to then generate statistics for the QAQC success report.\n",
    "\n",
    "This is carried out in two steps:\n",
    "\n",
    "1. Generate the per-network QAQC flag count tables, at native and hourly timesteps\n",
    "\n",
    "2. Generates one flag count table that sums all per-network tables, at native and hourly timesteps\n",
    "\n",
    "\n",
    "Using the following functions:\n",
    "\n",
    "\n",
    "- _pairwise_sum(): helper function that merges two input flag tables, used by network_sum_flag_counts() and total_sum_flag_counts().\n",
    "\n",
    "- network_sum_flag_counts(): sums all station flag count tables for a given network, creating one flag count table for that network\n",
    "\n",
    "- generate_station_tables(): runs network_sum_flag_counts() for every network\n",
    "\n",
    "- total_sum_flag_counts(): sums all network flag count tables, creating one final flag count table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce425205",
   "metadata": {},
   "source": [
    "## Step 0: Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e2b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from functools import reduce\n",
    "\n",
    "import inspect\n",
    "\n",
    "import logging\n",
    "# Create a simple logger that just prints to the console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7320ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "stations_csv_path = f\"s3://{bucket_name}/2_clean_wx/temp_clean_all_station_list.csv\"\n",
    "qaqc_dir = \"3_qaqc_wx\"\n",
    "merge_dir = \"4_merge_wx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7594f1f",
   "metadata": {},
   "source": [
    "### The functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8c45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_sum(flag_df_1, flag_df_2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts(). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df_1: pd.DataFrame\n",
    "        dataframe of previously summed station flag counts\n",
    "    flag_df_2: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summed_df: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    if len(flag_df_1) == 0:\n",
    "        return flag_df_2\n",
    "    else:\n",
    "        total_df = pd.concat([flag_df_1, flag_df_2])\n",
    "\n",
    "        summed_df = total_df.groupby('eraqc_flag_values', as_index=False).sum()\n",
    "        return summed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a695a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_sum_flag_counts(network: str, timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all station QAQC flag counts in a network for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network: str\n",
    "        network name\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    # read in flag meanings CSV\n",
    "\n",
    "    flag_meanings = pd.read_csv(\"era_qaqc_flag_meanings.csv\")\n",
    "\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing station flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## Format final dataframe\n",
    "\n",
    "    # merge with flag meaning dataframe\n",
    "    # - to include all flag values, and their meanings\n",
    "    \n",
    "\n",
    "    # Reorder flag values in numerical order\n",
    "    summed_counts_df = summed_counts_df.sort_values(by=\"eraqc_flag_values\")\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/{network}_flag_counts_{timestep}_timestep.csv\"\n",
    "    # summed_counts_df.to_csv(csv_s3_filepath, index=False)\n",
    "    print(\n",
    "        f\"Sending summed counts dataframe for {network} to: {csv_s3_filepath}\"\n",
    "    )\n",
    "\n",
    "    return summed_counts_df  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594cf721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_flag_counts(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all network-level QAQC flag counts for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing network-level flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/per_network_flag_counts\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all networks CSVs\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "    if len(summed_counts_df) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        csv_s3_filepath = (\n",
    "            f\"s3://wecc-historical-wx/4_merge_wx/total_flag_counts_{timestep}_timestep.csv\"\n",
    "        )\n",
    "        # summed_counts_df.to_csv(csv_s3_filepath, index=False)\n",
    "        print(f\"Sending final summed counts dataframe for to: {csv_s3_filepath}\")\n",
    "\n",
    "        return summed_counts_df  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd33d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_station_tables(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Runs network_sum_flag_counts() for every network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    station_list = pd.read_csv(stations_csv_path)\n",
    "    network_list = station_list[\"network\"].unique()\n",
    "\n",
    "    for network in network_list:\n",
    "        network_sum_flag_counts(network, timestep)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b4f2e",
   "metadata": {},
   "source": [
    "## Step 1: Generate flag sum tables for ever network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47140f",
   "metadata": {},
   "source": [
    "First, loop through every network, combining each of their station flag count tables into one table. The result is one flag count table at each timestep - native and hourly - for every network.\n",
    "\n",
    "This will take around 1 hour to run for both timesteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_station_tables('native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_station_tables(\"hourly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb0332",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25dfb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"CDEC\"\n",
    "station = \"CDEC_PVP\"\n",
    "timestep = 'native'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018fd430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending summed counts dataframe for CDEC to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/CDEC_flag_counts_native_timestep.csv\n"
     ]
    }
   ],
   "source": [
    "result = network_sum_flag_counts(network, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f42396c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eraqc_flag_values</th>\n",
       "      <th>accum_pr</th>\n",
       "      <th>elevation</th>\n",
       "      <th>pr</th>\n",
       "      <th>hurs</th>\n",
       "      <th>ps_altimeter</th>\n",
       "      <th>ps_derived</th>\n",
       "      <th>ps</th>\n",
       "      <th>rsds</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>tas</th>\n",
       "      <th>tdps_derived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3399.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2507.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70065.0</td>\n",
       "      <td>70065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9544.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35</td>\n",
       "      <td>525855.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>no_flag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>925907</td>\n",
       "      <td>516128.0</td>\n",
       "      <td>712299.0</td>\n",
       "      <td>633564.0</td>\n",
       "      <td>633564.0</td>\n",
       "      <td>703607.0</td>\n",
       "      <td>500564.0</td>\n",
       "      <td>511176.0</td>\n",
       "      <td>479828.0</td>\n",
       "      <td>822240.0</td>\n",
       "      <td>700082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_obs_count</td>\n",
       "      <td>525855.0</td>\n",
       "      <td>925907</td>\n",
       "      <td>525855.0</td>\n",
       "      <td>713636.0</td>\n",
       "      <td>703732.0</td>\n",
       "      <td>703732.0</td>\n",
       "      <td>713636.0</td>\n",
       "      <td>503963.0</td>\n",
       "      <td>513867.0</td>\n",
       "      <td>513867.0</td>\n",
       "      <td>823824.0</td>\n",
       "      <td>713636.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eraqc_flag_values  accum_pr  elevation        pr      hurs  ps_altimeter  \\\n",
       "0               11.0       0.0          0       0.0    1337.0           0.0   \n",
       "1               12.0       0.0          0       0.0       0.0           0.0   \n",
       "2               13.0       0.0          0       0.0       0.0           0.0   \n",
       "3               14.0       0.0          0       0.0       0.0           0.0   \n",
       "4               15.0       0.0          0       0.0       0.0           0.0   \n",
       "5               22.0       0.0          0       0.0       0.0       70065.0   \n",
       "6               23.0       0.0          0      40.0       0.0           0.0   \n",
       "7               25.0       0.0          0       0.0       0.0           0.0   \n",
       "8               26.0       0.0          0       0.0       0.0           0.0   \n",
       "9               27.0       0.0          0       0.0       0.0         103.0   \n",
       "10              28.0       0.0          0       0.0       0.0           0.0   \n",
       "11              29.0       0.0          0       0.0       0.0           0.0   \n",
       "12              32.0       0.0          0     192.0       0.0           0.0   \n",
       "13              34.0       0.0          0    9495.0       0.0           0.0   \n",
       "14                35  525855.0          0       0.0       0.0           0.0   \n",
       "15           no_flag       0.0     925907  516128.0  712299.0      633564.0   \n",
       "16   total_obs_count  525855.0     925907  525855.0  713636.0      703732.0   \n",
       "\n",
       "    ps_derived        ps      rsds  sfcWind_dir   sfcWind       tas  \\\n",
       "0          0.0       3.0    3399.0          2.0       0.0    1022.0   \n",
       "1          0.0       0.0       0.0          0.0       0.0       0.0   \n",
       "2          0.0       0.0       0.0          0.0       0.0       0.0   \n",
       "3          0.0       0.0       0.0       2507.0       0.0       0.0   \n",
       "4          0.0       0.0       0.0        182.0       0.0       0.0   \n",
       "5      70065.0       0.0       0.0          0.0       0.0       0.0   \n",
       "6          0.0       2.0       0.0          0.0       0.0     358.0   \n",
       "7          0.0       0.0       0.0          0.0       0.0      73.0   \n",
       "8          0.0       0.0       0.0          0.0       0.0     131.0   \n",
       "9        103.0     120.0       0.0          0.0   34039.0       0.0   \n",
       "10         0.0    9544.0       0.0          0.0       0.0       0.0   \n",
       "11         0.0     360.0       0.0          0.0       0.0       0.0   \n",
       "12         0.0       0.0       0.0          0.0       0.0       0.0   \n",
       "13         0.0       0.0       0.0          0.0       0.0       0.0   \n",
       "14         0.0       0.0       0.0          0.0       0.0       0.0   \n",
       "15    633564.0  703607.0  500564.0     511176.0  479828.0  822240.0   \n",
       "16    703732.0  713636.0  503963.0     513867.0  513867.0  823824.0   \n",
       "\n",
       "    tdps_derived  \n",
       "0            4.0  \n",
       "1         2382.0  \n",
       "2          593.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "5            0.0  \n",
       "6          657.0  \n",
       "7            0.0  \n",
       "8           14.0  \n",
       "9            0.0  \n",
       "10        9544.0  \n",
       "11         360.0  \n",
       "12           0.0  \n",
       "13           0.0  \n",
       "14           0.0  \n",
       "15      700082.0  \n",
       "16      713636.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f051c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_meanings = pd.read_csv('era_qaqc_flag_meanings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8f16ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flag_value</th>\n",
       "      <th>QAQC_function</th>\n",
       "      <th>Flag_meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>spurious_buoy_check</td>\n",
       "      <td>Suspect observation (i.e. buoy reports wind du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flag_value        QAQC_function  \\\n",
       "0           1  spurious_buoy_check   \n",
       "\n",
       "                                        Flag_meaning  \n",
       "0  Suspect observation (i.e. buoy reports wind du...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_meanings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82083e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflag_meanings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meraqc_flag_values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFlag_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/pandas/core/frame.py:10083\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10064\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10065\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10066\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10079\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10080\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10081\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10084\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10092\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10093\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10094\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/pandas/core/reshape/merge.py:111\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 111\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/pandas/core/reshape/merge.py:710\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    702\u001b[0m (\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m    706\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hist-obs/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1343\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1339\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1340\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1341\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1342\u001b[0m     ):\n\u001b[0;32m-> 1343\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "test = result.merge(flag_meanings, left_on = 'eraqc_flag_values',right_on='Flag_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm, the counts are being saved as objects instead of integers. let's see what the station level tables are like,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a8aa6",
   "metadata": {},
   "source": [
    "## Step 2: Generate total flag sum table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ad66c",
   "metadata": {},
   "source": [
    "Now combine all the network flag count tables generated in step 1 into one final flag count table. First at the hourly timestep, and then at the native timestep.\n",
    "\n",
    "Step 1 must be complete before moving on to this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_flag_counts('hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa00dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_flag_counts(\"native\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
