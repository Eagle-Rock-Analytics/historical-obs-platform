{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c073d99",
   "metadata": {},
   "source": [
    "# Generate summed flag count tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb392abe",
   "metadata": {},
   "source": [
    "This notebook creates QAQC flag counts csv files per network from the corresponding eraqc_counts_timestep files that were generated as a part of the final processing step for stations within the Historical Data Pipeline. These tables are used to then generate statistics for the QAQC success report.\n",
    "\n",
    "This is carried out in two steps:\n",
    "\n",
    "1. Generate the per-network QAQC flag count tables, at native and hourly timesteps\n",
    "\n",
    "2. Generates one flag count table that sums all per-network tables, at native and hourly timesteps\n",
    "\n",
    "\n",
    "Using the following functions:\n",
    "\n",
    "\n",
    "- _pairwise_sum(): helper function that merges two input flag tables, used by network_sum_flag_counts() and total_sum_flag_counts().\n",
    "\n",
    "- network_sum_flag_counts(): sums all station flag count tables for a given network, creating one flag count table for that network\n",
    "\n",
    "- generate_station_tables(): runs network_sum_flag_counts() for every network\n",
    "\n",
    "- total_sum_flag_counts(): sums all network flag count tables, creating one final flag count table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce425205",
   "metadata": {},
   "source": [
    "## Step 0: Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1e2b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from qaqc_success_report_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b4f2e",
   "metadata": {},
   "source": [
    "## Step 1: Generate flag sum tables for ever network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47140f",
   "metadata": {},
   "source": [
    "First, loop through every network, combining each of their station flag count tables into one table. The result is one flag count table at each timestep - native and hourly - for every network.\n",
    "\n",
    "This will take around 1 hour to run for both timesteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_station_tables(\"native\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "115c01be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending summed counts dataframe for ASOSAWOS to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/ASOSAWOS_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for CAHYDRO to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/CAHYDRO_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for CDEC to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/CDEC_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for CIMIS to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/CIMIS_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for CNRFC to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/CNRFC_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for CRN to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/CRN_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for CW3E to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/CW3E_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for CWOP to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/CWOP_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for HADS to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/HADS_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for HNXWFO to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/HNXWFO_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for HOLFUY to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/HOLFUY_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for HPWREN to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/HPWREN_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for LOXWFO to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/LOXWFO_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for MAP to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/MAP_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for MARITIME to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/MARITIME_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for MTRWFO to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/MTRWFO_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for NCAWOS to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/NCAWOS_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for NDBC to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/NDBC_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for NOS-NWLON to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/NOS-NWLON_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for NOS-PORTS to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/NOS-PORTS_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for OtherISD to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/OtherISD_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for RAWS to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/RAWS_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for SCAN to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/SCAN_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for SGXWFO to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/SGXWFO_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for SHASAVAL to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/SHASAVAL_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for SNOTEL to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/SNOTEL_flag_counts_hourly_timestep.csv\n",
      "Sending summed counts dataframe for VCAPCD to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts_hourly_timestep/VCAPCD_flag_counts_hourly_timestep.csv\n",
      "19.462883138656615 minutes\n"
     ]
    }
   ],
   "source": [
    "generate_station_tables('hourly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a8aa6",
   "metadata": {},
   "source": [
    "## Step 2: Generate total flag sum table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ad66c",
   "metadata": {},
   "source": [
    "Now combine all the network flag count tables generated in step 1 into one final flag count table. First at the hourly timestep, and then at the native timestep.\n",
    "\n",
    "Step 1 must be complete before moving on to this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa00dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_flag_counts('native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_flag_counts('hourly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
