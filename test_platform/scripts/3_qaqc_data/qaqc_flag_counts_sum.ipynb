{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c073d99",
   "metadata": {},
   "source": [
    "# Generate summed flag count tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb392abe",
   "metadata": {},
   "source": [
    "This notebook creates QAQC flag counts csv files per network from the corresponding eraqc_counts_timestep files that were generated as a part of the final processing step for stations within the Historical Data Pipeline. These tables are used to then generate statistics for the QAQC success report.\n",
    "\n",
    "This is carried out in two steps:\n",
    "\n",
    "1. Generate the per-network QAQC flag count tables, at native and hourly timesteps\n",
    "\n",
    "2. Generates one flag count table that sums all per-network tables, at native and hourly timesteps\n",
    "\n",
    "\n",
    "Using the following functions:\n",
    "\n",
    "\n",
    "- _pairwise_sum(): helper function that merges two input flag tables, used by network_sum_flag_counts() and total_sum_flag_counts().\n",
    "\n",
    "- network_sum_flag_counts(): sums all station flag count tables for a given network, creating one flag count table for that network\n",
    "\n",
    "- generate_station_tables(): runs network_sum_flag_counts() for every network\n",
    "\n",
    "- total_sum_flag_counts(): sums all network flag count tables, creating one final flag count table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce425205",
   "metadata": {},
   "source": [
    "## Step 0: Environment set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e2b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from functools import reduce\n",
    "\n",
    "import inspect\n",
    "\n",
    "import logging\n",
    "# Create a simple logger that just prints to the console\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7320ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "stations_csv_path = f\"s3://{bucket_name}/2_clean_wx/temp_clean_all_station_list.csv\"\n",
    "qaqc_dir = \"3_qaqc_wx\"\n",
    "merge_dir = \"4_merge_wx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7594f1f",
   "metadata": {},
   "source": [
    "### The functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8c45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_sum(flag_df_1, flag_df_2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts(). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df_1: pd.DataFrame\n",
    "        dataframe of previously summed station flag counts\n",
    "    flag_df_2: pd.DataFrame\n",
    "        flag counts dataframes for next station\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summed_df: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    if len(flag_df_1) == 0:\n",
    "        return flag_df_2\n",
    "    else:\n",
    "        total_df = pd.concat([flag_df_1, flag_df_2])\n",
    "\n",
    "        summed_df = total_df.groupby('eraqc_flag_values', as_index=False).sum()\n",
    "        return summed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a695a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_sum_flag_counts(network: str, timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all station QAQC flag counts in a network for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network: str\n",
    "        network name\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    # read in flag meanings CSV\n",
    "\n",
    "    flag_meanings = pd.read_csv(\"era_qaqc_flag_meanings.csv\")\n",
    "\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing station flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all CSVs are the given level\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## Format final dataframe\n",
    "\n",
    "    # merge with flag meaning dataframe\n",
    "    # - to include all flag values, and their meanings\n",
    "    \n",
    "\n",
    "    # Reorder flag values in numerical order\n",
    "    summed_counts_df = summed_counts_df.sort_values(by=\"eraqc_flag_values\")\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "\n",
    "    csv_s3_filepath = f\"s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/{network}_flag_counts_{timestep}_timestep.csv\"\n",
    "    # summed_counts_df.to_csv(csv_s3_filepath, index=False)\n",
    "    print(\n",
    "        f\"Sending summed counts dataframe for {network} to: {csv_s3_filepath}\"\n",
    "    )\n",
    "\n",
    "    return summed_counts_df  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594cf721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_flag_counts(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Sums all network-level QAQC flag counts for a given timestep (hourly or native) and sends to AWS. \n",
    "    These counts are used to generate statistics for the QAQC success report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # the function iteratively adds in flag counts to this dataframe\n",
    "    summed_counts_df = []\n",
    "\n",
    "    # point to folder containing network-level flag count CSVs\n",
    "    flags_prefix = f\"{merge_dir}/per_network_flag_counts\"\n",
    "\n",
    "    ## Merge flag counts\n",
    "\n",
    "    # loop through all networks CSVs\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix=flags_prefix):\n",
    "        obj = s3_cl.get_object(Bucket=bucket_name, Key=item.key)\n",
    "        flags = pd.read_csv(obj[\"Body\"])\n",
    "        # the CSV is empty\n",
    "        if flags.empty:\n",
    "            continue\n",
    "        # the CSV is not empty\n",
    "        else:\n",
    "            # send current dataframe and dataframe of previously summed counts to helper function\n",
    "            summed_counts_df = _pairwise_sum(summed_counts_df, flags)\n",
    "\n",
    "    ## Send final counts file to AWS as CSV\n",
    "    if len(summed_counts_df) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        csv_s3_filepath = (\n",
    "            f\"s3://wecc-historical-wx/4_merge_wx/total_flag_counts_{timestep}_timestep.csv\"\n",
    "        )\n",
    "        # summed_counts_df.to_csv(csv_s3_filepath, index=False)\n",
    "        print(f\"Sending final summed counts dataframe for to: {csv_s3_filepath}\")\n",
    "\n",
    "        return summed_counts_df  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd33d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_station_tables(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Runs network_sum_flag_counts() for every network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', merge all hourly QAQC flag count tables\n",
    "        if set to 'native', merge all native timestep QAQC flag count tables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    # only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    station_list = pd.read_csv(stations_csv_path)\n",
    "    network_list = station_list[\"network\"].unique()\n",
    "\n",
    "    for network in network_list:\n",
    "        network_sum_flag_counts(network, timestep)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b4f2e",
   "metadata": {},
   "source": [
    "## Step 1: Generate flag sum tables for ever network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47140f",
   "metadata": {},
   "source": [
    "First, loop through every network, combining each of their station flag count tables into one table. The result is one flag count table at each timestep - native and hourly - for every network.\n",
    "\n",
    "This will take around 1 hour to run for both timesteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_station_tables('native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_station_tables(\"hourly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb0332",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25dfb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"CDEC\"\n",
    "station = \"CDEC_PVP\"\n",
    "timestep = 'native'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "018fd430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending summed counts dataframe for CDEC to: s3://wecc-historical-wx/4_merge_wx/per_network_flag_counts/CDEC_flag_counts_native_timestep.csv\n"
     ]
    }
   ],
   "source": [
    "result = network_sum_flag_counts(network, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef018bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"eraqc_flag_values\"] = result[\"eraqc_flag_values\"].str.replace(\n",
    "    \".0\", \"\", regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6f051c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_meanings = pd.read_csv('era_qaqc_flag_meanings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e8f16ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the flag values in the count tables were saved as strings, so we need to convert to string to merge\n",
    "\n",
    "flag_meanings['Flag_value'] = flag_meanings['Flag_value'].astype(str)\n",
    "flag_meanings = flag_meanings.rename(columns={'Flag_value':'eraqc_flag_values'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcee1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result[~result[\"eraqc_flag_values\"].isin([\"no_flag\", \"total_obs_count\"])] = (result[~result[\"eraqc_flag_values\"].isin([\"no_flag\", \"total_obs_count\"])].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "82083e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result.merge(flag_meanings,on='eraqc_flag_values',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ec61c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(by=\"eraqc_flag_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a446d512",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meraqc_flag_values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdigit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_sort \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meraqc_flag_values\u001b[39m\u001b[38;5;124m'\u001b[39m], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdigit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "test_sort = sorted(test['eraqc_flag_values'], key=lambda x: int(''.join(filter(str.isdigit,x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e0afe9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17                  1\n",
       "26                 10\n",
       "0                  11\n",
       "1                  12\n",
       "2                  13\n",
       "3                  14\n",
       "4                  15\n",
       "27                 16\n",
       "28                 17\n",
       "29                 18\n",
       "30                 19\n",
       "18                  2\n",
       "31                 20\n",
       "32                 21\n",
       "5                  22\n",
       "6                  23\n",
       "33                 24\n",
       "7                  25\n",
       "8                  26\n",
       "9                  27\n",
       "10                 28\n",
       "11                 29\n",
       "19                  3\n",
       "34                 30\n",
       "35                 31\n",
       "12                 32\n",
       "36                 33\n",
       "13                 34\n",
       "14                 35\n",
       "37                 36\n",
       "38                 37\n",
       "39                 38\n",
       "20                  4\n",
       "21                  5\n",
       "22                  6\n",
       "23                  7\n",
       "24                  8\n",
       "25                  9\n",
       "15            no_flag\n",
       "16    total_obs_count\n",
       "Name: eraqc_flag_values, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"eraqc_flag_values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a8aa6",
   "metadata": {},
   "source": [
    "## Step 2: Generate total flag sum table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ad66c",
   "metadata": {},
   "source": [
    "Now combine all the network flag count tables generated in step 1 into one final flag count table. First at the hourly timestep, and then at the native timestep.\n",
    "\n",
    "Step 1 must be complete before moving on to this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_flag_counts('hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa00dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum_flag_counts(\"native\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
