{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f107480-b89b-4dc8-a146-8ef1fee66c4e",
   "metadata": {},
   "source": [
    "# Historical Data Platform QA/QC Event Evaluation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99606d61-b614-4ad2-9dd9-ff2a244e315c",
   "metadata": {},
   "source": [
    "**Event**: Santa Ana Wind Event<br>\n",
    "Start date: 2/16/1988<br> \n",
    "End date: 2/19/1988<br>\n",
    "Location: Los Angeles, Orange counties<br>\n",
    "Variables: wind speed, wind direction, air temperature, humidity<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf98323-af90-43a5-8a0c-ebfc0be02d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T19:25:12.997925Z",
     "iopub.status.busy": "2024-08-28T19:25:12.997802Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384607d-acf9-442f-b53e-8caaf95f08e2",
   "metadata": {},
   "source": [
    "### QAQC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0003d8-cfe1-474d-a6bd-cc40e193e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in stations\n",
    "train_stns = pd.read_csv('../qaqc_training_station_list_events.csv')\n",
    "train_stns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148f331-7fcf-43df-a6aa-957039e51094",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_stns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c02177-1301-41b8-972a-811543f61302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import CRS, Transformer\n",
    "\n",
    "def latlon_to_mercator_cartopy(lat, lon):\n",
    "\n",
    "    proj_latlon = CRS('EPSG:4326')\n",
    "    proj_mercator = CRS('EPSG:3857')\n",
    "    \n",
    "    # Transform the coordinates\n",
    "    transformer = Transformer.from_crs(proj_latlon, proj_mercator, always_xy=True)\n",
    "    x,y = transformer.transform(lon, lat)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c38c25-b50c-44e2-bec3-321d928adcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify stations with coverage of event\n",
    "event_flags = ['all', 'santa_ana_wind']\n",
    "event_stns = train_stns[train_stns['event_type'].isin(event_flags)]\n",
    "\n",
    "# exclude \"manual check on end date\" for the time being -- SNOTEL stations all have 2100 as their end date regardless of when the data actually ends\n",
    "mask = event_stns['notes'] == 'manual check on end date'\n",
    "event_stns = event_stns[~mask]\n",
    "event_stns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aed13a-2704-4ed5-8242-89245cba568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(event_stns))\n",
    "event_stns.network.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef025fe-5c45-4ffd-85a5-ad48ba4ef55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify stations that are in the geographic region we are looking for\n",
    "# santa ana wind event, focusing on LA and Orange counties\n",
    "\n",
    "census_shp_dir = \"s3://wecc-historical-wx/0_maps/ca_counties/\" \n",
    "# ca_county = gpd.read_file('../../../data/0_maps/ca_counties/CA_Counties.shp') # local\n",
    "ca_county = gpd.read_file(census_shp_dir) # from s3 bucket\n",
    "\n",
    "county_names = ['Los Angeles', 'Orange']\n",
    "target_counties = ca_county[ca_county['NAME'].isin(county_names)]\n",
    "target_counties = GeoDataFrame(target_counties, geometry=target_counties.geometry)\n",
    "target_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c45358-ac62-492b-9fdc-3529173bda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process event list to subset\n",
    "geometry = [Point(latlon_to_mercator_cartopy(lat,lon)) for lat,lon in zip (event_stns.latitude, event_stns.longitude)]\n",
    "event_stns = GeoDataFrame(event_stns,geometry=geometry).set_crs(crs=\"EPSG:3857\", allow_override=True) # adding geometry column\n",
    "\n",
    "event_stns_local = gpd.overlay(event_stns, target_counties, how=\"intersection\") # subsetting for stations within county boundaries\n",
    "\n",
    "# subset further based on number, if needed\n",
    "if len(event_stns_local) > 20:\n",
    "    event_stns_local = event_stns_local.sample(20)\n",
    "print(len(event_stns_local))\n",
    "event_stns_local.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778de385-b96f-4cc2-87d5-61bdf44e66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIMIS_75 = event_stns[event_stns['era-id']==\"CIMIS_75\"]\n",
    "lon,lat = CIMIS_75.longitude.values[0], CIMIS_75.latitude.values[0]\n",
    "x,y = latlon_to_mercator_cartopy(lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370621ae-3ff4-4a24-b5d0-18605aba7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "orange = ca_county.query(\"NAME=='Orange'\")\n",
    "orange_geom = orange['geometry'].iloc[0]\n",
    "LA = ca_county.query(\"NAME=='Los Angeles'\")\n",
    "LA_geom = LA['geometry'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae74b5-6867-402c-b74c-0e1e9069029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(subplot_kw={'projection':ccrs.epsg(3857)})\n",
    "\n",
    "ax.coastlines()\n",
    "ax.add_feature(cf.BORDERS)\n",
    "ax.add_geometries(LA_geom, crs=ccrs.epsg(3857), color=\"C0\", alpha=0.25)\n",
    "ax.add_geometries(orange_geom, crs=ccrs.epsg(3857), color=\"C1\", alpha=0.25)\n",
    "ax.add_feature(cf.STATES, lw=0.5)\n",
    "ax.set_extent([-118.2, -117.4, 33.3, 34])\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.plot(lon, lat, 'ok', markersize=8, transform=ccrs.PlateCarree(), mfc='none')\n",
    "ax.plot(x, y, '.r', markersize=4)\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=[\"bottom\", \"left\"],\n",
    "                  ls=\":\", lw=0.5)\n",
    "ax.set_title(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065bb5f-ccc6-41be-89f9-19c8d34ad162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b00e665-e432-4c39-9b82-a006e9104f4a",
   "metadata": {},
   "source": [
    "### Step 2: Holistic / qualitative station evaluation\n",
    "* downloading these stations manually into train_files, but should grab from AWS unless a better way to read nc files from AWS..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd820afe-d276-4674-be6b-6dc67150c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 2 look at full timeseries for flags -- grabbing clean version, not qaqc version to build out\n",
    "# alternatively.... some of these files may be very large and we should avoid reading in all because of memory concerns\n",
    "\n",
    "# for stn in event_stns:\n",
    "#     want to pull out all flags noted, frequency of flags of time record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf088a-dbfc-4f09-8ac9-013095f13177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a single station in\n",
    "stn = xr.open_dataset('/Users/hector/Downloads/CIMIS_75.nc')\n",
    "stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81303e7a-25f3-4d27-aa17-d9be71adecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_all_flags(ds):\n",
    "    '''Prints all unique values of all eraqaqc flags'''\n",
    "    ds_vars = list(stn.keys())\n",
    "    qc_vars = [i for i in ds_vars if '_eraqc' in i]\n",
    "    if len(qc_vars) == 0:\n",
    "        print('Station has no eraqc variables -- please double check that this station has completed QA/QC!')\n",
    "    else:\n",
    "        for var in qc_vars:\n",
    "            print(var, np.unique(ds[var].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0c6ca-942f-4d95-85d1-af190604594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_all_flags(stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd16189-6cbe-49df-b303-a6e367b5ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at full timeseries for holistic view\n",
    "stn.sfcWind.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c2a17-378c-4062-9474-de30bca1cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at timeseries of all months of that event (e.g., all februaries) to understand climatological signal?\n",
    "month = [2]\n",
    "stn_monthly_clim = stn.isel(time=stn.time.dt.month.isin(month))\n",
    "\n",
    "stn_monthly_clim.sfcWind.plot()\n",
    "\n",
    "# hmm not so useful, perhaps a climatology of the month to compare with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70975d0e-d3a1-4fbe-9c9c-6f723453c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at timeseries during event for flags\n",
    "# decision: do we add a few days prior/after event end date to evaluate \"event anomaly\"? i think this may be useful\n",
    "# santa ana event was 2/16/1988 to 2/19/1988; including +/- 1 week\n",
    "event_start_date = '1988-02-09'\n",
    "event_end_date = '1988-02-26'\n",
    "\n",
    "# subset for event period of time\n",
    "event = stn.sel(time=slice(event_start_date, event_end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca37d3-be7a-40bb-aac2-085742a1ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just grabbing a single var for the event itself\n",
    "event.sfcWind.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7ac46-4d97-4fe8-8f08-bd24023cadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "event.sfcWind_dir.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4c772-02b3-420d-bf5a-c7bfbda79c10",
   "metadata": {},
   "source": [
    "#### Append local GHCNh library path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4982cc3-4a99-4d39-96a9-d139f3efac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghcnh_lib_path = \"/Users/hector/ERA_work/historical-obs-platform/test_platform/scripts/3_qaqc_data/qaqc_eval_notebooks/GHCNh\"\n",
    "sys.path.append(ghcnh_lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb170a-39f7-49d4-baad-6dfcd247af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GHCNh.GHCNh_lib import GHCNh  # If GHCNh is within current folder\n",
    "from GHCNh_lib import GHCNh # If GHCNh is was appended to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdeeae0-1f91-43bc-8913-49ea4a1bd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ghcnh = GHCNh(stations_local=True)\n",
    "ghcnh.select_wecc()\n",
    "id = ghcnh.stations_df['id'].iloc[0]\n",
    "ghcnh.read_data_from_url(id, save=True)\n",
    "ghcnh.convert_df_to_gpd()\n",
    "ghcnh.station_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40286890-26e4-4cd5-8daa-089d9bd1567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = ghcnh.station_data.Longitude.mean()\n",
    "lat = ghcnh.station_data.Latitude.mean()\n",
    "print(\"{}, {:.5f}, {:.5f}\".format(id, lon, lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71250ee-30df-4dd4-bc38-45841e96dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(9,3))\n",
    "\n",
    "ghcnh.station_data.plot(ax=ax, x=\"time\", y=\"temperature\")\n",
    "ghcnh.station_data.plot(ax=ax, x=\"time\", y=\"dew_point_temperature\")\n",
    "ax.set_title(\"{}  ({:.3f}, {:.3f})\".format(id,lon,lat));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86d35c-36cf-43b2-9207-d0501f829a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial test for identifying the event: large jumps on windspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a7ac5-a348-44d7-a0e6-d63d999b01c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cf666-4eea-48cb-8156-e7f871d9b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ghcn_vars(ghcn_df, input_var):\n",
    "    '''\n",
    "    Given an input variable, return GHCNh location variables and all relevant data variables,\n",
    "    rather than utilizing the whole 240 cols, or having to know how ghcnh labels the cols.\n",
    "\n",
    "    input_var must follow ERA naming scheme (tas, tdps, ps, pr, etc.)\n",
    "    '''\n",
    "    ghcnh_vars = pd.read_csv('ghcnh_data_headers.csv')\n",
    "\n",
    "    # include station-ID, time, loc, elevation (cols 1-10)\n",
    "    stn_info_cols = ['Station_ID', 'Station_name',\n",
    "                     'Year','Month','Day','Hour','Minute',\n",
    "                     'Latitude','Longitude','Elevation']\n",
    "    \n",
    "    var_cols = []\n",
    "    if input_var == 'tas':\n",
    "        varquery = 'temperature'\n",
    "        \n",
    "    elif input_var == 'tdps' or 'tdps_derived':\n",
    "        varquery = 'dew_point_temperature'\n",
    "        \n",
    "    elif input_var == 'ps' or 'psl':\n",
    "        varquery = 'station_level_pressure'\n",
    "        \n",
    "    elif input_var == 'sfcWind_dir':\n",
    "        varquery = 'wind_direction'\n",
    "        \n",
    "    elif input_var == 'sfcWind':\n",
    "        varquery = ['wind_speed', 'wind_gust']\n",
    "\n",
    "    elif input_var == 'hurs':\n",
    "        varquery = 'relative_humidity'\n",
    "        \n",
    "    elif input_var == 'rsds':\n",
    "        print('GHCNh data does not have solar radiation data to evaluate against.')\n",
    "        varquery = '' \n",
    "        \n",
    "    elif input_var == 'pr' or input_var == 'pr_1h' or input_var == 'pr_5min':\n",
    "        varquery = 'precipitation'\n",
    "\n",
    "    i = ghcn_df.query(\n",
    "    \n",
    "    var_cols = [i for i in ghcnh_vars if varquery in i]\n",
    "    cols_to_return = stn_info_cols + var_cols\n",
    "    return ghcn_df[[cols_to_return]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713ae27-071e-4b05-928c-134c234bdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ghcn_vars(ghcn_df, input_var):\n",
    "    '''\n",
    "    Given an input variable, return GHCNh location variables and all relevant data variables,\n",
    "    rather than utilizing the whole 240 cols, or having to know how ghcnh labels the cols.\n",
    "\n",
    "    input_var must follow ERA naming scheme (tas, tdps, ps, pr, etc.)\n",
    "    '''\n",
    "    ghcnh_vars = pd.read_csv('ghcnh_data_headers.csv')\n",
    "\n",
    "    # include station-ID, time, loc, elevation (cols 1-10)\n",
    "    stn_info_cols = ['Station_ID', 'Station_name',\n",
    "                     'Year','Month','Day','Hour','Minute',\n",
    "                     'Latitude','Longitude','Elevation']\n",
    "\n",
    "    vars = {\n",
    "        'tas': 'temperature',\n",
    "        'tdps': 'dew_point_temperature',\n",
    "        'tdps_derived': 'dew_point_temperature',\n",
    "        'ps': 'station_level_pressure',\n",
    "        'psl': 'station_level_pressure',\n",
    "        'sfcWind_dir': 'wind_direction',\n",
    "        'sfcWind': 'wind_speed',\n",
    "        'tas': 'temperature',\n",
    "        'hurs': 'wind_gust',\n",
    "        'rsds': \"N/A\",\n",
    "        'pr': 'precipitation',\n",
    "        'pr_1h': 'precipitation',\n",
    "        'pr_5min': 'precipitation',\n",
    "        '': '',\n",
    "    }\n",
    "    i = df.columns.get_loc(vars[input_var])\n",
    "    j = i+6\n",
    "    df.iloc[:, i:j]\n",
    "    \n",
    "    return ghcn_df.iloc[:, i:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced9c0a8-4ebe-4062-b9dd-70d71c10540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_ghcn_vars(ghcnh.station_data, 'tas').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72bea76-1cb1-4a20-9402-d12618722701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac02a18-6c88-4b62-8988-67a09f12a967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135cc90-4075-4c87-8628-0d26909334dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91aecc-89cb-4d66-bef1-758cb394e80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3140cb-c2d6-434d-8852-783c799353d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d65b6a-a121-4943-bd96-f963362b8104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "hist-obs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
