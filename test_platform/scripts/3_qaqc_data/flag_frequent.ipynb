{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f150ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3cf3d9c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victoriaford/anaconda3/envs/histobs/lib/python3.11/site-packages/pandas/core/arrays/timedeltas.py:908: RuntimeWarning: invalid value encountered in cast\n",
      "  base = data.astype(np.int64)\n",
      "/Users/victoriaford/anaconda3/envs/histobs/lib/python3.11/site-packages/pandas/core/arrays/timedeltas.py:912: RuntimeWarning: invalid value encountered in cast\n",
      "  data = (base * m + (frac * m).astype(np.int64)).view(\"timedelta64[ns]\")\n"
     ]
    }
   ],
   "source": [
    "fn = xr.open_dataset('/Users/victoriaford/Desktop/Train_Files/ASOSAWOS_72586494182.nc')\n",
    "df = fn.to_dataframe()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1e794c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(data, bin_size=0.25):\n",
    "    '''Create bins from data covering entire data range'''\n",
    "\n",
    "    # set up bins\n",
    "    b_min = np.floor(np.nanmin(data))\n",
    "    b_max = np.ceil(np.nanmax(data))\n",
    "    bins = np.arange(b_min - bin_size, b_max + (3. * bin_size), bin_size)\n",
    "\n",
    "    return bins\n",
    "\n",
    "def bins_to_flag(bins, bar_counts, bin_main_thresh=30, secondary_bin_main_thresh=30):\n",
    "    '''Returns the specific bins to flag as suspect'''\n",
    "    bins_to_flag = [] # list of bins that will be flagged\n",
    "    \n",
    "    for i in range(0, len(bar_counts)):\n",
    "        # identify main bin + 3 on either side\n",
    "        bin_start = i-3\n",
    "        bin_end = i+4\n",
    "\n",
    "        # need handling for first 3 blocks as there is no front\n",
    "        if i < 3:\n",
    "            bin_start = 0\n",
    "\n",
    "        bin_block_sum = bar_counts[bin_start:bin_end].sum() # num of obs in the 7-bin block\n",
    "        bin_main_sum = bar_counts[i] # num of obs in main bin\n",
    "\n",
    "        # determine whether main bin is more than half sum in 7-block bin\n",
    "        bin_block_50 = bin_block_sum * 0.5 # primary check at 50%\n",
    "        bin_block_90 = bin_block_sum * 0.9 # secondary check at 90%\n",
    "\n",
    "        if (bin_main_sum > bin_block_50) == True:            \n",
    "            # ensure that bin_main_sum is greater than bin_main_thresh\n",
    "            if bin_main_sum > bin_main_thresh:\n",
    "                bins_to_flag.append(bins[i])\n",
    "                \n",
    "                # annual/seasonal check\n",
    "                if (bin_main_sum > bin_block_90) == True:\n",
    "                    if bin_main_sum > secondary_bin_main_thresh:\n",
    "                        bins_to_flag.append(bins[i]) \n",
    "                \n",
    "            else: # less than bin_main_thresh obs in bin_main_sum, do not indicate as suspect\n",
    "                continue\n",
    "                \n",
    "    return bins_to_flag # returns a list of values that are suspicious\n",
    "\n",
    "def frequent_bincheck(df, data_group):\n",
    "    '''Approach: \n",
    "        - histograms created with 0.5 or 1.0 or hpa increments (depending on accuracy of instrument)\n",
    "        - each bin compared to the three on either side\n",
    "        - if this bin contains more than half the total population of the seven bins combined\n",
    "        - and more than 30 observations over the station record (20 for seasonal)\n",
    "        - then histogram bin is highlighted for further investigation\n",
    "        - minimum number limit imposted to avoid removing true tails of distribution\n",
    "    '''\n",
    "    \n",
    "    if data_group == 'all':\n",
    "        bins = create_bins(df[var], bin_size=1) # using 1 degC/hPa bin width\n",
    "        bar_counts, bins = np.histogram(df[var], bins=bins)\n",
    "        flagged_bins = bins_to_flag(bins, bar_counts)\n",
    "        \n",
    "        # flag values in that bin as suspect\n",
    "        if len(flagged_bins) != 0:\n",
    "            for sus_bin in flagged_bins:\n",
    "                # indicate as suspect bins\n",
    "                    # DECISION: preliminary flag? and then remove if okay/reset to nan?\n",
    "                df.loc[(df[var]==bins[i]) & (df[var]==bins[i+1]), var+'_eraqc'] = 100 # highlight for further review flag, either overwritten with real flag or removed in next step\n",
    "        \n",
    "    elif data_group == 'annual':\n",
    "        for yr in df.year.unique():\n",
    "            df_yr = df.loc[df['year'] == yr]\n",
    "            bins = create_bins(df_yr[var], bin_size=1) # using 1 degC/hPa bin width\n",
    "            bar_counts, bins = np.histogram(df_yr[var], bins=bins)\n",
    "            flagged_bins = bins_to_flag(df_yr, bin_main_thresh=20, secondary_bin_main_thresh=10)\n",
    "            \n",
    "            if flagged_bins !=0:\n",
    "                for sus_bin in flagged_bins:\n",
    "                    df.loc[(df[var]==bins[i]) & (df[var]==bins[i+1]), var+'_eraqc'] = 22 # see era_qaqc_flag_meanings.csv\n",
    "                \n",
    "    return df\n",
    "\n",
    "def qaqc_frequent_vals(df, plots=True):\n",
    "    '''Frequent values check:\n",
    "        - Initially > 50% of all data in current 0.5 degC/hPa bin \n",
    "        - out of \"this and +/- 3 bins for all data to highlight with >30 (obs?) in the bin\n",
    "        - On yearly basis using highlighted bins with 50% of data and >=20 obs in this and +/- 3 bins OR\n",
    "        - 90% data and >=10 observations in this and +/-3 bins\n",
    "        - for seasons, bin size thresholds are reduced to 20, 15, and 10 respectively\n",
    "        \n",
    "        Note: tas and tdps are synergistic\n",
    "            - if t is bad, tdps is also removed, and vice versa\n",
    "    '''\n",
    "    \n",
    "    # this check is only done on air temp, dewpoint temp, and pressure\n",
    "    vars_to_remove = ['qc', 'duration', 'method']\n",
    "    vars_to_include = ['tas', 'tdps', 'ps'] # list of var substrings to remove if present in var\n",
    "    vars_to_check = [var for var in df.columns if any(True for item in vars_to_include if item in var) and not any(True for item in vars_to_remove if item in var)]\n",
    "\n",
    "    df = df.reset_index() \n",
    "    df['month'] = pd.to_datetime(df['time']).dt.month # sets month to new variable\n",
    "    df['year'] = pd.to_datetime(df['time']).dt.year # sets year to new variable\n",
    "    \n",
    "    for var in vars_to_check:\n",
    "        \n",
    "        # set-up flag vars\n",
    "        df[var+'_eraqc'] = np.nan\n",
    "        \n",
    "        # first scans suspect values using entire record\n",
    "        # all years\n",
    "        df = frequent_bincheck(df, data_group='all')\n",
    "\n",
    "        # if no values are flagged as suspect, end function, no need to proceed\n",
    "        if len(df.loc[df[var+'_eraqc'] == 100]) == 0:\n",
    "            print('No unusually frequent values detected for entire {} observation record'.format(var))\n",
    "            # goes to seasonal check\n",
    "\n",
    "        else:\n",
    "            # year by year\n",
    "            # then scans for each value on a year-by-year basis to flag if they are a problem within that year\n",
    "                # DECISION: the annual check uses the unfiltered data\n",
    "                # previously flagged values are included here -- this would interfere with our entire workflow\n",
    "            df = frequent_bincheck(df, data_group='annual')\n",
    "\n",
    "        # seasonal scan (JF+D, MAM, JJA, SON) \n",
    "        # each season is scanned over entire record to identify problem values\n",
    "        # only flags applied on annual basis using the three months on their own\n",
    "        # NOTE: HadISD approach is to use the current year's december, rather than the preceeding december\n",
    "\n",
    "        # seasonal version because seasonal shift in distribution of temps/dewpoints can reveal hidden values\n",
    "        # all years\n",
    "        szns = [[3,4,5], [6,7,8], [9,10,11], [12,1,2]] ## DECISION: December is from the current year\n",
    "        for szn in szns:\n",
    "            df_szn = df.loc[(df['month']==szn[0]) | (df['month']==szn[1]) | (df['month']==szn[2])]\n",
    "\n",
    "            df_szn = frequent_bincheck(df_szn, data_group='all')\n",
    "            if len(df_szn.loc[df_szn[var+'_eraqc'] == 100]) == 0:\n",
    "                print('No unusually frequent values detected for seasonal {} observation record'.format(var))\n",
    "                continue # bypasses to next variable\n",
    "\n",
    "            else:\n",
    "                # year by year --> December selection will be problematic\n",
    "                df_szn = frequent_bincheck(df_szn, data_group='annual')\n",
    "\n",
    "        # remove any lingering preliminary flags, data passed check\n",
    "        df.loc[df[var+'_eraqc'] == 100, var+'_eraqc'] == np.nan\n",
    "        \n",
    "    # plots item\n",
    "    if plots==True:\n",
    "        for var in vars_to_check:\n",
    "            if 22 in df[var+'_eraqc'].values: # only plot a figure if a value is flagged\n",
    "                # histogram\n",
    "                frequent_vals_plot(df, var)\n",
    "\n",
    "                # entire timeseries figure\n",
    "                flagged_timeseries_plot(df, flag_to_viz=frequent_flags)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def frequent_vals_plot(df, var):\n",
    "    '''\n",
    "    Produces a histogram of the diagnostic histogram per variable, \n",
    "    and any bin that is indicated as \"too frequent\" by the qaqc_frequent_vals test \n",
    "    is visually flagged\n",
    "    ''' \n",
    "    bins = create_bins(df[var], 1)\n",
    "    ax = df.plot.hist(column=var, bins=bins, alpha=0.5)\n",
    "    \n",
    "    # plot flagged values\n",
    "    \n",
    "    # first identify which values are flagged\n",
    "    vals_to_flag = df.loc[df[var+'_eraqc'] == 22][var].unique()\n",
    "    bars_to_flag = []\n",
    "    for i in vals_to_flag:\n",
    "        if math.isnan(i) == False:\n",
    "            bars_to_flag.append(math.floor(i))\n",
    "\n",
    "    # flag bars if too frequent\n",
    "    for bar in ax.patches:\n",
    "        x = bar.get_x() + 0.5 * bar.get_width()\n",
    "        if x in bars_to_flag: # right tail\n",
    "            bar.set_color('r')\n",
    "\n",
    "    # plot aesthetics\n",
    "    plt.xlabel('Temperature [K]')\n",
    "    plt.title('Frequent value check: {}'.format(df['station'].unique()[0]),\n",
    "             fontsize=10);\n",
    "    \n",
    "    \n",
    "    # save figure to AWS\n",
    "    bucket_name = 'wecc-historical-wx'\n",
    "    directory = '3_qaqc_wx'\n",
    "    img_data = BytesIO()\n",
    "    plt.savefig(img_data, format='png')\n",
    "    img_data.seek(0)\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    figname = 'qaqc_frequent_value_check_{0}_{1}'.format(df['station'].unique()[0], var)\n",
    "    bucket.put_object(Body=img_data, ContentType='image/png',\n",
    "                     Key='{0}/{1}/qaqc_figs/{2}.png'.format(\n",
    "                     directory, network, figname))\n",
    "\n",
    "    # close figures to save memory\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9b4260f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unusually frequent values detected for entire ps observation record\n",
      "No unusually frequent values detected for seasonal ps observation record\n",
      "No unusually frequent values detected for seasonal ps observation record\n",
      "No unusually frequent values detected for seasonal ps observation record\n",
      "No unusually frequent values detected for seasonal ps observation record\n",
      "No unusually frequent values detected for entire tas observation record\n",
      "No unusually frequent values detected for seasonal tas observation record\n",
      "No unusually frequent values detected for seasonal tas observation record\n",
      "No unusually frequent values detected for seasonal tas observation record\n",
      "No unusually frequent values detected for seasonal tas observation record\n",
      "No unusually frequent values detected for entire tdps observation record\n",
      "No unusually frequent values detected for seasonal tdps observation record\n",
      "No unusually frequent values detected for seasonal tdps observation record\n",
      "No unusually frequent values detected for seasonal tdps observation record\n",
      "No unusually frequent values detected for seasonal tdps observation record\n",
      "No unusually frequent values detected for entire ps_altimeter observation record\n",
      "No unusually frequent values detected for seasonal ps_altimeter observation record\n",
      "No unusually frequent values detected for seasonal ps_altimeter observation record\n",
      "No unusually frequent values detected for seasonal ps_altimeter observation record\n",
      "No unusually frequent values detected for seasonal ps_altimeter observation record\n",
      "No unusually frequent values detected for entire psl observation record\n",
      "No unusually frequent values detected for seasonal psl observation record\n",
      "No unusually frequent values detected for seasonal psl observation record\n",
      "No unusually frequent values detected for seasonal psl observation record\n",
      "No unusually frequent values detected for seasonal psl observation record\n"
     ]
    }
   ],
   "source": [
    "tester = qaqc_frequent_vals(df, plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ea2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
