{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce162d6",
   "metadata": {},
   "source": [
    "# Station Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b61f8",
   "metadata": {},
   "source": [
    "This notebook generates a station map and a chart showing station distribution over time, for a given stage (raw, clean, QAQC, merge). Note that this reflects the information provided in station lists, and not actual station data availability (i.e., this figure should be re-made following the cleaning stage to reflect dropped stations and the actual temporal availability of data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e80ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "from io import BytesIO, StringIO\n",
    "from datetime import datetime, timezone, date\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "BUCKET_NAME = \"wecc-historical-wx\"\n",
    "RAW_DIR = \"1_raw_wx\"\n",
    "CLEAN_DIR = \"2_clean_wx\"\n",
    "QAQC_DIR = \"3_qaqc_wx\"\n",
    "MERGE_DIR = \"4_merge_wx\"\n",
    "phase_dict = {\"pull\": RAW_DIR, \"clean\": CLEAN_DIR, \"qaqc\": QAQC_DIR, \"merge\": MERGE_DIR}\n",
    "\n",
    "\n",
    "shapepath = \"s3://wecc-historical-wx/0_maps/tl_2021_us_state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc6d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = pd.read_csv(\n",
    "    f\"s3://{BUCKET_NAME}/{RAW_DIR}/all_network_stationlist_pull.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8fe627a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>start-date</th>\n",
       "      <th>end-date</th>\n",
       "      <th>pulled</th>\n",
       "      <th>time_checked</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BOISE AIR TERMINAL/GOWEN FD AIRPORT</td>\n",
       "      <td>43.567</td>\n",
       "      <td>-116.241</td>\n",
       "      <td>860.5</td>\n",
       "      <td>1931-01-01 00:00:00+00:00</td>\n",
       "      <td>2023-03-22 00:00:00+00:00</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-03-23 21:42:22+00:00</td>\n",
       "      <td>ASOSAWOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 name  latitude  longitude  \\\n",
       "0           0  BOISE AIR TERMINAL/GOWEN FD AIRPORT    43.567   -116.241   \n",
       "\n",
       "   elevation                 start-date                   end-date pulled  \\\n",
       "0      860.5  1931-01-01 00:00:00+00:00  2023-03-22 00:00:00+00:00      Y   \n",
       "\n",
       "                time_checked   network  \n",
       "0  2023-03-23 21:42:22+00:00  ASOSAWOS  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_list.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40001ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1931-01-01 00:00:00+00:00\n",
       "1        2006-01-01 00:00:00+00:00\n",
       "2        2006-01-01 00:00:00+00:00\n",
       "3        2006-01-01 00:00:00+00:00\n",
       "4        2006-01-01 00:00:00+00:00\n",
       "                   ...            \n",
       "15875    2010-05-27 00:00:00+00:00\n",
       "15876    2010-05-27 00:00:00+00:00\n",
       "15877    2010-05-27 00:00:00+00:00\n",
       "15878    2010-05-27 00:00:00+00:00\n",
       "15879    2012-10-04 00:00:00+00:00\n",
       "Name: start-date, Length: 15880, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_list['start-date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list[\"start-date\"] = pd.to_datetime(station_list[\"start-date\"], utc=True)\n",
    "station_list[\"end-date\"] = pd.to_datetime(station_list[\"end-date\"], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5636f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1931-01-01 00:00:00+00:00\n",
       "1       2006-01-01 00:00:00+00:00\n",
       "2       2006-01-01 00:00:00+00:00\n",
       "3       2006-01-01 00:00:00+00:00\n",
       "4       2006-01-01 00:00:00+00:00\n",
       "                   ...           \n",
       "15875   2010-05-27 00:00:00+00:00\n",
       "15876   2010-05-27 00:00:00+00:00\n",
       "15877   2010-05-27 00:00:00+00:00\n",
       "15878   2010-05-27 00:00:00+00:00\n",
       "15879   2012-10-04 00:00:00+00:00\n",
       "Name: start-date, Length: 15880, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_list[\"start-date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6876bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = station_list.loc[~station_list[\"start-date\"].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349f1553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15410"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30d6378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15880"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e240f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out non-downloaded rows\n",
    "subdf = subdf.loc[subdf[\"pulled\"] != \"N\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "712fb5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cbfba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_dict = {\"pull\": RAW_DIR, \"clean\": CLEAN_DIR, \"qaqc\": QAQC_DIR, \"merge\": MERGE_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab33c2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_raw_wx'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_dict['pull']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d299593",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b87aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_chart(phase,phase_dict):\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phase: str\n",
    "        \"pull\", \"clean\", \"qaqc\" or \"merge\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "\n",
    "    \"\"\"\n",
    "    if phase not in [\"pull\", \"clean\", \"qaqc\", \"merge\"]:\n",
    "        print(f\"invalid phase:{phase}\")\n",
    "        return None\n",
    "\n",
    "    ## Get station list\n",
    "    directory = phase_dict[phase]\n",
    "    station_list = pd.read_csv(\n",
    "        f\"s3://{BUCKET_NAME}/{directory}/all_network_stationlist_{phase}.csv\"\n",
    "    )\n",
    "\n",
    "    # #! only in qaqc\n",
    "    # # read in qaqc training station list\n",
    "    # stns = pd.read_csv(\"../3_qaqc_data/qaqc_training_station_list.csv\")\n",
    "\n",
    "    # station_list = station_list[station_list[\"era-id\"].isin(stns[\"era-id\"])]\n",
    "    # #! only in qaqc ^\n",
    "\n",
    "    ## Get period\n",
    "\n",
    "    # Format dates in datetime format (this gets lost in import).\n",
    "    station_list[\"start-date\"] = pd.to_datetime(station_list[\"start-date\"], utc=True)\n",
    "    station_list[\"end-date\"] = pd.to_datetime(station_list[\"end-date\"], utc=True)\n",
    "\n",
    "    # Fix nas\n",
    "    ## Filter out rows w/o start date\n",
    "    # print(dffull[dffull['network']==\"MARITIME\"])\n",
    "    subdf = station_list.loc[~station_list[\"start-date\"].isnull()].copy()\n",
    "\n",
    "    if phase == \"pull\":\n",
    "        ## Filter out non-downloaded rows  #! raw only\n",
    "        subdf = subdf.loc[subdf[\"pulled\"] != \"N\"].copy()\n",
    "    else:\n",
    "        # Filter out non-cleaned rows #! clean and QAQC\n",
    "        subdf = subdf.loc[subdf[\"cleaned\"] != \"N\"].copy()\n",
    "\n",
    "    # manually filter dates to >01-01-1980 and <today.\n",
    "    # Timezones so far ignored here but we presume on the scale of month we can safely ignore them for the moment.\n",
    "    # Note!: This implicitly assumes stations w/o end date run until present.\n",
    "    subdf[\"start-date\"] = subdf[\"start-date\"].apply(\n",
    "        lambda x: (\n",
    "            x\n",
    "            if x > datetime(1980, 1, 1, tzinfo=timezone.utc)\n",
    "            else datetime(1980, 1, 1, tzinfo=timezone.utc)\n",
    "        )\n",
    "    )\n",
    "    subdf[\"end-date\"] = subdf[\"end-date\"].apply(\n",
    "        lambda x: (\n",
    "            x\n",
    "            if x < datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "            else datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get period of months for range of dates for each station\n",
    "    subdf[\"period\"] = [\n",
    "        pd.period_range(*v, freq=\"M\")\n",
    "        for v in zip(subdf[\"start-date\"], subdf[\"end-date\"])\n",
    "    ]\n",
    "\n",
    "    subdf = subdf[subdf.period.str.len() > 0]\n",
    "    subdf = subdf.reset_index(drop=True)\n",
    "\n",
    "    if phase == \"pull\":\n",
    "        #! from raw phase function\n",
    "        out = subdf.explode(\"period\").pivot_table(\n",
    "            values=\"name\",\n",
    "            index=\"network\",\n",
    "            columns=\"period\",\n",
    "            aggfunc=\"count\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "    else:\n",
    "        #! from clean phase function\n",
    "        out = subdf.explode(\"period\").pivot_table(\n",
    "            values=\"era-id\",\n",
    "            index=\"network\",\n",
    "            columns=\"period\",\n",
    "            aggfunc=\"count\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc6a881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'pull'\n",
    "test = get_station_chart(phase, phase_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chart(phase, phase_dict):\n",
    "    \"\"\"\n",
    "    Sums two input flag count dataframes. This is a helper function for sum_flag_counts().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phase: str\n",
    "        \"pull\", \"clean\", \"qaqc\" or \"merge\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out:\n",
    "\n",
    "    \"\"\"\n",
    "    out = get_station_chart(phase, phase_dict)\n",
    "    # Plot\n",
    "    outt = out.T.reset_index()\n",
    "\n",
    "    # Fix time component\n",
    "    outt[\"date\"] = outt[\"period\"].astype(str)\n",
    "    outt[\"date\"] = pd.to_datetime(outt[\"date\"])\n",
    "\n",
    "    # Plot parameters\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "    # Subplot parameters\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    outt.plot.area(\n",
    "        x=\"date\",\n",
    "        title=\"Stations by network over time\",\n",
    "        ax=ax,\n",
    "        x_compat=True,\n",
    "        cmap=\"tab20c_r\",\n",
    "    )  # Get area plot\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5))  # Fix legend\n",
    "    ax.tick_params(labelcolor=\"black\", labelsize=\"medium\", width=3)\n",
    "    ax.set_facecolor(\"w\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Number of stations\")\n",
    "\n",
    "    # Change axis bounds\n",
    "    ax.set_xlim([date(1980, 1, 1), date(2022, 8, 1)])\n",
    "\n",
    "    # Change tick marks\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_major_locator(matplotlib.dates.YearLocator(3))\n",
    "    ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter(\"%Y\"))\n",
    "    ax.xaxis.set_minor_locator(matplotlib.dates.YearLocator(1))\n",
    "\n",
    "    # Change y ticks\n",
    "    plt.locator_params(axis=\"y\", nbins=12)\n",
    "    ax.yaxis.get_ticklocs(minor=True)\n",
    "\n",
    "    # Set x axis labels\n",
    "    # #plt.title(\"Stations Over Time By Network\")\n",
    "    plt.subplots_adjust(left=0.2, bottom=0.2, top=0.8, right=0.8)\n",
    "\n",
    "    # Annotate text for total number\n",
    "    # hard coding the number for now, come back to this\n",
    "    plt.annotate(\n",
    "        \"Total # of QA/QC'd stations: 937\", xy=(0.025, 0.95), xycoords=\"axes fraction\"\n",
    "    )\n",
    "\n",
    "    # Save to AWS\n",
    "    img_data = BytesIO()\n",
    "    plt.savefig(img_data, format=\"png\")\n",
    "    img_data.seek(0)\n",
    "\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    bucket = s3.Bucket(BUCKET_NAME))\n",
    "    export_folder = phase_dict[phase]\n",
    "    export_key = f\"{export_folder}/{phase}_stations_over_time.png\"\n",
    "    bucket.put_object(\n",
    "        Body=img_data,\n",
    "        ContentType=\"image/png\",\n",
    "        Key=\"3_qaqc_wx/qaqc_training_stations_over_time.png\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
