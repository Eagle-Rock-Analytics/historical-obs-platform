{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script is used to make a map and a chart showing station distribution over time for the QA/QC training subset of 937 stations. This training subset of stations was selected based on a representative sample of elevation, temperature, precipitation, and windspeed. Stations without time information in their station lists are not reflected in the time-based chart, but are included in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "from io import BytesIO, StringIO\n",
    "from datetime import datetime, timezone, date\n",
    "import geopandas as gpd\n",
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: plot station chart\n",
    "def get_station_chart(bucket_name, directory):\n",
    "    s3 = boto3.resource(\"s3\") \n",
    "    s3_cl = boto3.client('s3') # for lower-level processes\n",
    "    \n",
    "    # read in cleaned station list\n",
    "    obj = s3_cl.get_object(Bucket = bucket_name, Key = \"2_clean_wx/temp_clean_all_station_list.csv\")\n",
    "    body = obj['Body'].read()\n",
    "    dfall = pd.read_csv(BytesIO(body), encoding='utf8')\n",
    "    \n",
    "    # read in qaqc training station list\n",
    "    stns = pd.read_csv('qaqc_training_station_list.csv')\n",
    "    \n",
    "    dffull = dfall[dfall['era-id'].isin(stns['era.id'])]\n",
    "    \n",
    "    # Get period\n",
    "\n",
    "    # Format dates in datetime format (this gets lost in import).\n",
    "    dffull['start-date'] = pd.to_datetime(dffull['start-date'], utc = True)\n",
    "    dffull['end-date'] = pd.to_datetime(dffull['end-date'], utc = True)\n",
    "\n",
    "    # Fix nas\n",
    "    ## Filter out rows w/o start date\n",
    "    ## Note here: we lose MARITIME and NDBC networks.\n",
    "    #print(dffull[dffull['network']==\"MARITIME\"])\n",
    "    subdf = dffull.loc[~dffull['start-date'].isnull()].copy()\n",
    "\n",
    "    ## Filter out non-cleaned rows\n",
    "    subdf = subdf.loc[subdf['cleaned']!=\"N\"].copy()\n",
    "    \n",
    "    # manually filter dates to >01-01-1980 and <today.\n",
    "    # Timezones so far ignored here but we presume on the scale of month we can safely ignore them for the moment.\n",
    "    # Note!: This implicitly assumes stations w/o end date run until present. \n",
    "    subdf['start-date'] = subdf['start-date'].apply(lambda x: x if x > datetime(1980,1,1, tzinfo=timezone.utc) else datetime(1980,1,1, tzinfo=timezone.utc))\n",
    "    subdf['end-date'] = subdf['end-date'].apply(lambda x: x if x < datetime.utcnow().replace(tzinfo=timezone.utc) else datetime.utcnow().replace(tzinfo=timezone.utc))\n",
    "    \n",
    "    # Get period of months for range of dates for each station\n",
    "    subdf['period'] = [pd.period_range(*v, freq='M') for v in zip(subdf['start-date'], subdf['end-date'])]\n",
    "    \n",
    "    subdf = subdf[subdf.period.str.len()>0]\n",
    "    subdf = subdf.reset_index(drop = True)\n",
    "\n",
    "    out = subdf.explode('period').pivot_table(\n",
    "        values = 'era-id', index = 'network', columns = 'period', aggfunc='count', fill_value=0)\n",
    "    #out.columns = out.columns.strftime('%b-%y')\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run functions - generate station chart\n",
    "bucket_name = \"wecc-historical-wx\"\n",
    "directory = \"3_qaqc_wx/\"\n",
    "\n",
    "#station_list = get_station_list(bucket_name, directory) # Get combined station list.\n",
    "out = get_station_chart(bucket_name, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "outt = out.T.reset_index()\n",
    "\n",
    "# Fix time component\n",
    "outt['date'] = outt['period'].astype(str)\n",
    "outt['date'] = pd.to_datetime(outt['date'])\n",
    "\n",
    "# Plot parameters\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Subplot parameters\n",
    "fig, ax = plt.subplots(figsize = (8, 6))\n",
    "outt.plot.area(x = 'date', title = 'Stations by network over time', ax = ax, x_compat = True, cmap = 'tab20c_r') # Get area plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5)) # Fix legend \n",
    "ax.tick_params(labelcolor='black', labelsize='medium', width=3)\n",
    "ax.set_facecolor('w')\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Number of stations\")\n",
    "\n",
    "# Change axis bounds\n",
    "ax.set_xlim([date(1980, 1, 1), date(2022, 8, 1)])\n",
    "\n",
    "# Change tick marks\n",
    "ax.minorticks_on()\n",
    "ax.xaxis.set_major_locator(matplotlib.dates.YearLocator(3))\n",
    "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter(\"%Y\"))\n",
    "ax.xaxis.set_minor_locator(matplotlib.dates.YearLocator(1))\n",
    "\n",
    "# Change y ticks\n",
    "plt.locator_params(axis='y', nbins=12)\n",
    "ax.yaxis.get_ticklocs(minor=True)\n",
    "\n",
    "# Set x axis labels\n",
    "# #plt.title(\"Stations Over Time By Network\")\n",
    "plt.subplots_adjust(left=0.2,bottom=0.2, top = 0.8, right = 0.8)\n",
    "\n",
    "# Save to AWS\n",
    "img_data = BytesIO()\n",
    "plt.savefig(img_data, format='png')\n",
    "img_data.seek(0)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "bucket.put_object(Body=img_data, ContentType='image/png', Key=\"3_qaqc_wx/qaqc_training_stations_over_time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function - generate station map\n",
    "\n",
    "def get_station_map(bucket_name, directory, shapepath):\n",
    "    s3 = boto3.resource(\"s3\") \n",
    "    s3_cl = boto3.client('s3') # for lower-level processes\n",
    "\n",
    "    # read in cleaned station list\n",
    "    obj = s3_cl.get_object(Bucket = bucket_name, Key = \"2_clean_wx/temp_clean_all_station_list.csv\")\n",
    "    body = obj['Body'].read()\n",
    "    dfall = pd.read_csv(BytesIO(body), encoding='utf8')\n",
    "    \n",
    "    # read in qaqc training station list\n",
    "    stns = pd.read_csv('qaqc_training_station_list.csv')\n",
    "    \n",
    "    dffull = dfall[dfall['era-id'].isin(stns['era.id'])]\n",
    "\n",
    "    # Get period\n",
    "\n",
    "    # Format dates in datetime format (this gets lost in import).\n",
    "    dffull['start-date'] = pd.to_datetime(dffull['start-date'], utc = True)\n",
    "    dffull['end-date'] = pd.to_datetime(dffull['end-date'], utc = True)\n",
    "\n",
    "    # Quality control.\n",
    "    # Fix nas\n",
    "    ## Filter out rows w/o start date\n",
    "    subdf = dffull.loc[~dffull['start-date'].isnull()].copy()\n",
    "    # Filter out rows without data between 1980 and now.\n",
    "    subdf = subdf.loc[(subdf['start-date']<=datetime.utcnow().replace(tzinfo=timezone.utc)) & (subdf['end-date']>='1980-01-01')]\n",
    "    \n",
    "    # Make a geodataframe.\n",
    "    gdf = gpd.GeoDataFrame(subdf, geometry=gpd.points_from_xy(subdf.longitude, subdf.latitude))\n",
    "    gdf.set_crs(epsg=4326, inplace=True) # Set CRS\n",
    "    \n",
    "    # Project data to match base tiles.\n",
    "    gdf_wm = gdf.to_crs(epsg=3857) # Web mercator\n",
    "\n",
    "    # Read in geometry of continental US.\n",
    "    us = gpd.read_file(shapepath)\n",
    "\n",
    "    # Remove territories, AK, HI\n",
    "    rem_list = [\"HI\", \"AK\", \"MP\", \"GU\", \"AS\", \"PR\", \"VI\"]\n",
    "    us = us.loc[us.STUSPS.isin(rem_list) == False]\n",
    "\n",
    "    # Use to clip stations\n",
    "    us = us.to_crs(epsg = 3857)\n",
    "    gdf_us = gdf_wm.clip(us)\n",
    "\n",
    "    \n",
    "    # Version 1 - full map\n",
    "    ax = gdf_us.plot(\"network\", figsize=(15, 15), alpha=1, markersize = 3, legend = True, cmap = 'nipy_spectral')\n",
    "    cx.add_basemap(ax, source=cx.providers.Stamen.TonerLite)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Save to AWS\n",
    "    img_data = BytesIO()\n",
    "    plt.savefig(img_data, format='png')\n",
    "    img_data.seek(0)\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    bucket.put_object(Body=img_data, ContentType='image/png', Key=\"3_qaqc_wx/qaqc_training_station_map.png\")\n",
    "        \n",
    "shapepath = \"s3://wecc-historical-wx/0_maps/tl_2021_us_state.shp\"\n",
    "get_station_map(bucket_name, directory, shapepath = shapepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b143eb979cf5515e2cd3ecb004a34bf20911b4f75739c4d295f9535d4cc57dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
