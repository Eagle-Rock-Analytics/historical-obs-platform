{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab6fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "from io import BytesIO, StringIO\n",
    "from datetime import datetime, timezone, date\n",
    "import xarray as xr\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab31c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_list = pd.read_csv('/Users/victoriaford/Desktop/temp_clean_master_station_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9571fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_stnlist_cleanvars(network, update=False):\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    s3_cl = boto3.client(\"s3\")\n",
    "    \n",
    "    bucket_name=\"wecc-historical-wx\"\n",
    "    directory=\"2_clean_wx/\"\n",
    "    \n",
    "    if update == False:\n",
    "        obj = s3_cl.get_object(Bucket = bucket_name, Key = \"2_clean_wx/temp_clean_master_station_list.csv\")        \n",
    "        body = obj['Body'].read()\n",
    "        df_clean = pd.read_csv(BytesIO(body), encoding='utf8')\n",
    "        \n",
    "    # add in default columns of \"N\" to cleaned station list for all core variables\n",
    "    core_vars = ['tas', 'ps', 'tdps', 'hurs', 'pr', 'sfcWind', 'sfcWind_dir', 'rsds']\n",
    "    for var in core_vars:\n",
    "        df_clean[str(var)] = \"N\"\n",
    "                \n",
    "    # open cleaned datafile\n",
    "    files = [] # Get files\n",
    "    cleandir = \"{0}{1}/\".format(directory, network)\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix = cleandir):\n",
    "        file = str(item.key)\n",
    "        files += [file]\n",
    "        \n",
    "    # get list of station filenames successfully cleaned    \n",
    "    files = list(filter(lambda f: f.endswith(\".nc\"), files)) \n",
    "    print('{0}: {1} stations'.format(network, len(files)))\n",
    "    \n",
    "    for file in files: \n",
    "        if file not in files: # dont run qa/qc on a station that isn't cleaned\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                fs = s3fs.S3FileSystem()\n",
    "                aws_url = \"s3://wecc-historical-wx/\"+file\n",
    "\n",
    "                with fs.open(aws_url) as fileObj:\n",
    "                    ds = xr.open_dataset(fileObj, engine='h5netcdf')\n",
    "\n",
    "                    # mark each variable as present if in dataset\n",
    "                    for var in ds.variables:\n",
    "                        if var == \"tdps_derived\":  # tdps requires handling for tdps_derived\n",
    "                            df_clean.loc[df_clean['era-id']==ds.station.values[0], 'tdps'] = 'Y'\n",
    "                            \n",
    "                        elif var == \"pr_1h\" or var==\"pr_24h\" or var=='pr_5min': # pr has multiple options, this is one\n",
    "                            df_clean.loc[df_clean['era-id']==ds.station.values[0], 'pr'] = 'Y'  \n",
    "                            \n",
    "                        elif var == \"ps_altimeter\" or var == \"psl\" or var=='ps_derived':\n",
    "                            df_clean.loc[df_clean['era-id']==ds.station.values[0], 'ps'] = 'Y'\n",
    "                            \n",
    "                        elif var in core_vars:\n",
    "                            df_clean.loc[df_clean['era-id']==ds.station.values[0], str(var)] = 'Y'\n",
    "\n",
    "                    # close dataset\n",
    "                    ds.close()\n",
    "            except:\n",
    "                print('{} not opening'.format(file))\n",
    "                continue\n",
    "\n",
    "    # resort by network\n",
    "    df_clean.sort_values(by=['network'], inplace = True)\n",
    "\n",
    "    # reset index\n",
    "    df_clean = df_clean.reset_index(drop = True)\n",
    "    \n",
    "    return df_clean.loc[df_clean['network']==network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee1870b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITIME: 80 stations\n",
      "CPU times: user 1min 43s, sys: 36.5 s, total: 2min 20s\n",
      "Wall time: 17min 59s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>era-id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>start-date</th>\n",
       "      <th>end-date</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>time_cleaned</th>\n",
       "      <th>network</th>\n",
       "      <th>tas</th>\n",
       "      <th>ps</th>\n",
       "      <th>tdps</th>\n",
       "      <th>hurs</th>\n",
       "      <th>pr</th>\n",
       "      <th>sfcWind</th>\n",
       "      <th>sfcWind_dir</th>\n",
       "      <th>rsds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11621</th>\n",
       "      <td>11700</td>\n",
       "      <td>MARITIME_poro3</td>\n",
       "      <td>42.739</td>\n",
       "      <td>-124.498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-02-06 22:23:34+00:00</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11622</th>\n",
       "      <td>11701</td>\n",
       "      <td>MARITIME_erkc1</td>\n",
       "      <td>40.778</td>\n",
       "      <td>-124.196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11623</th>\n",
       "      <td>11702</td>\n",
       "      <td>MARITIME_elxc1</td>\n",
       "      <td>36.815</td>\n",
       "      <td>-121.738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11624</th>\n",
       "      <td>11703</td>\n",
       "      <td>MARITIME_elqc1</td>\n",
       "      <td>36.818</td>\n",
       "      <td>-121.739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11625</th>\n",
       "      <td>11704</td>\n",
       "      <td>MARITIME_ehsc1</td>\n",
       "      <td>36.835</td>\n",
       "      <td>-121.738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11740</th>\n",
       "      <td>11660</td>\n",
       "      <td>MARITIME_omhc1</td>\n",
       "      <td>37.801</td>\n",
       "      <td>-122.330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-02-06 22:20:04+00:00</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11741</th>\n",
       "      <td>11661</td>\n",
       "      <td>MARITIME_ptac1</td>\n",
       "      <td>38.955</td>\n",
       "      <td>-123.741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-02-06 22:28:08+00:00</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11742</th>\n",
       "      <td>11662</td>\n",
       "      <td>MARITIME_okxc1</td>\n",
       "      <td>37.811</td>\n",
       "      <td>-122.333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-02-06 22:19:17+00:00</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11743</th>\n",
       "      <td>11663</td>\n",
       "      <td>MARITIME_ohbc1</td>\n",
       "      <td>33.720</td>\n",
       "      <td>-118.273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-02-06 22:18:31+00:00</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>11658</td>\n",
       "      <td>MARITIME_pslc1</td>\n",
       "      <td>35.169</td>\n",
       "      <td>-120.754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-02-06 22:26:31+00:00</td>\n",
       "      <td>MARITIME</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          era-id  latitude  longitude  elevation start-date  \\\n",
       "11621       11700  MARITIME_poro3    42.739   -124.498        NaN        NaN   \n",
       "11622       11701  MARITIME_erkc1    40.778   -124.196        NaN        NaN   \n",
       "11623       11702  MARITIME_elxc1    36.815   -121.738        NaN        NaN   \n",
       "11624       11703  MARITIME_elqc1    36.818   -121.739        NaN        NaN   \n",
       "11625       11704  MARITIME_ehsc1    36.835   -121.738        NaN        NaN   \n",
       "...           ...             ...       ...        ...        ...        ...   \n",
       "11740       11660  MARITIME_omhc1    37.801   -122.330        NaN        NaN   \n",
       "11741       11661  MARITIME_ptac1    38.955   -123.741        NaN        NaN   \n",
       "11742       11662  MARITIME_okxc1    37.811   -122.333        NaN        NaN   \n",
       "11743       11663  MARITIME_ohbc1    33.720   -118.273        NaN        NaN   \n",
       "11744       11658  MARITIME_pslc1    35.169   -120.754        NaN        NaN   \n",
       "\n",
       "      end-date cleaned               time_cleaned   network tas ps tdps hurs  \\\n",
       "11621      NaN       Y  2023-02-06 22:23:34+00:00  MARITIME   Y  Y    N    N   \n",
       "11622      NaN       N                        NaN  MARITIME   N  N    N    N   \n",
       "11623      NaN       N                        NaN  MARITIME   N  N    N    N   \n",
       "11624      NaN       N                        NaN  MARITIME   N  N    N    N   \n",
       "11625      NaN       N                        NaN  MARITIME   N  N    N    N   \n",
       "...        ...     ...                        ...       ...  .. ..  ...  ...   \n",
       "11740      NaN       Y  2023-02-06 22:20:04+00:00  MARITIME   N  N    N    N   \n",
       "11741      NaN       Y  2023-02-06 22:28:08+00:00  MARITIME   Y  Y    N    N   \n",
       "11742      NaN       Y  2023-02-06 22:19:17+00:00  MARITIME   Y  Y    N    N   \n",
       "11743      NaN       Y  2023-02-06 22:18:31+00:00  MARITIME   N  Y    N    N   \n",
       "11744      NaN       Y  2023-02-06 22:26:31+00:00  MARITIME   Y  Y    N    N   \n",
       "\n",
       "      pr sfcWind sfcWind_dir rsds  \n",
       "11621  N       Y           Y    N  \n",
       "11622  N       N           N    N  \n",
       "11623  N       N           N    N  \n",
       "11624  N       N           N    N  \n",
       "11625  N       N           N    N  \n",
       "...   ..     ...         ...  ...  \n",
       "11740  N       Y           Y    N  \n",
       "11741  N       Y           Y    N  \n",
       "11742  N       Y           Y    N  \n",
       "11743  N       N           N    N  \n",
       "11744  N       Y           Y    N  \n",
       "\n",
       "[124 rows x 18 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "update_stnlist_cleanvars(network='MARITIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a66416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/Users/victoriaford/Downloads/VCAPCD_TO.nc')\n",
    "df = ds.to_dataframe()\n",
    "df.head()\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_stnlist_cleanvars(bucket_name, directory, update = False):\n",
    "    s3 = boto3.resource(\"s3\") \n",
    "    s3_cl = boto3.client('s3')\n",
    "    \n",
    "    if update == False:\n",
    "        obj = s3_cl.get_object(Bucket = bucket_name, Key = \"2_clean_wx/temp_clean_master_station_list.csv\")\n",
    "        body = obj['Body'].read()\n",
    "        df_clean = pd.read_csv(BytesIO(body), encoding='utf8')\n",
    "        \n",
    "    # add in default columns of \"N\" to cleaned station list\n",
    "    core_vars = ['tas', 'ps', 'tdps', 'hurs', 'pr', 'sfcWind', 'sfcWind_dir', 'rsds']\n",
    "    for var in core_vars:\n",
    "        df_clean[str(var)] = \"N\"\n",
    "                \n",
    "    # open cleaned datafile\n",
    "    files = [] # Get files\n",
    "    for item in s3.Bucket(bucket_name).objects.filter(Prefix = directory):\n",
    "        file = str(item.key)\n",
    "        files += [file]\n",
    "\n",
    "    # get list of station filenames successfully cleaned    \n",
    "    files = list(filter(lambda f: f.endswith(\".nc\"), files)) \n",
    "    print(len(files))\n",
    "        \n",
    "    for file in files: \n",
    "        if file not in files: # dont run qa/qc on a station that isn't cleaned\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                print(file)\n",
    "                fs = s3fs.S3FileSystem()\n",
    "                aws_url = \"s3://wecc-historical-wx/\"+file\n",
    "\n",
    "                with fs.open(aws_url) as fileObj:\n",
    "                    ds = xr.open_dataset(fileObj, engine='h5netcdf')\n",
    "\n",
    "                    # mark each variable as present if in dataset\n",
    "                    for var in ds.variables:\n",
    "                        if var in core_vars:\n",
    "                            df_clean.loc[df_clean['era-id']==ds.station.values[0], str(var)] = \"Y\"\n",
    "\n",
    "                    # close dataset\n",
    "                    ds.close()\n",
    "            except:\n",
    "                print('{} not opening'.format(file))\n",
    "                continue\n",
    "\n",
    "    # resort by network\n",
    "    df_clean.sort_values(by=['network'], inplace = True)\n",
    "\n",
    "    # reset index\n",
    "    df_clean = df_clean.reset_index(drop = True)\n",
    "                \n",
    "    # save station chart to AWS\n",
    "    csv_buffer = StringIO()\n",
    "    df_clean.to_csv(csv_buffer, na_rep = \"NaN\")\n",
    "    content = csv_buffer.getvalue()\n",
    "    s3_cl.put_object(Bucket=bucket_name, Body=content, Key=\"2_clean_wx/temp_clean_master_station_list_withvars.csv\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"wecc-historical-wx\"\n",
    "directory = \"2_clean_wx/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "update_stnlist_cleanvars(bucket_name, directory)\n",
    "# note this takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1f0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
