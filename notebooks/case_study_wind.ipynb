{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f98ffc0",
   "metadata": {},
   "source": [
    "### Extreme Event Case Study: October 2007 Santa Ana winds + wildfire\n",
    "The *Historical Observations Data Platform* is a cloud-based, historical weather observations dataset that enables access to high-quality, rigorously quality-controlled open climate and weather data. The historical weather stations included in this dataset include information that can assess the severity, duration, frequency, and rate of change over time of extreme weather events, as well as supporting projections downscaling efforts. Stringent QA/QC procedures, in-line with international protocols, are applied with custom modifications relevant to the Western US and the energy sector are included (such as temperature and precipitation extremes, winds, and solar radiation). This notebook is a detailed investigation into how the QA/QC protocol performed during a known extreme event that stressed communities and the electric grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfd622",
   "metadata": {},
   "source": [
    "The event took place in the following counties:\n",
    "- San Diego\n",
    "- Los Angeles\n",
    "- Ventura\n",
    "- Santa Barbara\n",
    "- San Bernardino\n",
    "- Orange\n",
    "\n",
    "\n",
    "variables of interest\n",
    "- 'hurs' or 'hurs_derived' - relative humidity, derived\n",
    "- 'sfcWind' - wind speed at 10m\n",
    "- 'sfcWind_dir' - wind direction\n",
    "- 'tas' - air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa38cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "import sys  # Used for progress bar\n",
    "from case_study_eval_utils import *\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import qaqc stage plot functions\n",
    "sys.path.append(os.path.abspath(\"../scripts/3_qaqc_data\"))\n",
    "from qaqc_plot import flagged_timeseries_plot, _plot_format_helper, id_flag\n",
    "\n",
    "\n",
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "BUCKET_NAME = \"wecc-historical-wx\"\n",
    "QAQC_DIR = \"3_qaqc_wx\"\n",
    "MERGE_DIR = \"4_merge_wx\"\n",
    "stations_csv_path = f\"s3://{BUCKET_NAME}/{QAQC_DIR}/all_network_stationlist_qaqc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a30889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_other_events(\n",
    "    df, event_start, event_end, buffer=14, subset=None, return_stn_ids=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Event finder not tied to specified case study events.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    df : pd.DataFrame\n",
    "        stationlist\n",
    "    event_start : str\n",
    "        start of event, format \"YYYY-MM-DD\"\n",
    "    event_end : str\n",
    "        end of event, format \"YYYY-MM-DD\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eval_stns : pd.DataFrame\n",
    "        subset of stations for other events of interest\n",
    "\n",
    "    To dos\n",
    "    ------\n",
    "    1. Manual end date check no longer relevant, make sure stationlist passed is the correct updated version.\n",
    "    2. Start / end date format check\n",
    "    \"\"\"\n",
    "\n",
    "    print(\n",
    "        f\"Subsetting station record for event duration with {str(buffer)} day buffer...\"\n",
    "    )\n",
    "\n",
    "    df[\"start-date\"] = pd.to_datetime(df[\"start-date\"])\n",
    "    df[\"end-date\"] = pd.to_datetime(df[\"end-date\"])\n",
    "    event_start = pd.to_datetime(event_start).tz_localize(\"UTC\")\n",
    "    event_end = pd.to_datetime(event_end).tz_localize(\"UTC\")\n",
    "\n",
    "    event_sub = df.loc[\n",
    "        (df[\"start-date\"] <= (event_start - datetime.timedelta(days=buffer)))\n",
    "        & (df[\"end-date\"] >= (event_end + datetime.timedelta(days=buffer)))\n",
    "    ]\n",
    "\n",
    "    # # exclude \"manual check on end date\" stations since we don't know when they actually end\n",
    "    # event_sub = event_sub.loc[event_sub[\"notes\"] != \"manual check on end date\"]\n",
    "\n",
    "    # subset to make more manageable\n",
    "    if subset != None:\n",
    "        if len(event_sub) <= subset:\n",
    "            eval_stns = event_sub\n",
    "        else:\n",
    "            eval_stns = event_sub.sample(subset, replace=False)\n",
    "            print(f\"{subset} stations selected for evaluation for comparison!\")\n",
    "    else:\n",
    "        eval_stns = event_sub\n",
    "\n",
    "    # return station ids for ease\n",
    "    if return_stn_ids:\n",
    "        print(\"Stations selected for evaluation:\\n\", list(eval_stns[\"era-id\"]))\n",
    "\n",
    "    return eval_stns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96113b1",
   "metadata": {},
   "source": [
    "## Step 1: Subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up event start and end dates, and affected counties\n",
    "event_start_date = \"2007-10-05\"\n",
    "event_end_date = \"2007-11-30\"\n",
    "event_counties = ['San Diego','Los Angeles','Ventura','Santa Barbara','San Bernardino','Orange','Riverside']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde2d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in merge station list\n",
    "stn_list = pd.read_csv(\n",
    "    \"s3://wecc-historical-wx/4_merge_wx/all_network_stationlist_merge.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it into geodataframe\n",
    "stns_gdf = gpd.GeoDataFrame(\n",
    "    stn_list,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        stn_list.longitude, stn_list.latitude, crs=\"EPSG:4326\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in  CA county boundaries shapefile\n",
    "ca_counties = gpd.read_file(\n",
    "    \"s3://wecc-historical-wx/0_maps/ca_counties/CA_Counties.shp\"\n",
    ")\n",
    "ca_counties = ca_counties.to_crs(stns_gdf.crs)  # Convert to station CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ce075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the event geometry - we'll focus on once county for now (San Diego - where the largest fires occurred)\n",
    "event_geom = ca_counties[ca_counties[\"NAME\"] == (\"San Diego\")]  # .isin(event_counties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12919516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter down to stations that are in the target county\n",
    "stns_gdf[\"intersects\"] = stns_gdf.intersects(\n",
    "    event_geom.unary_union\n",
    ")  # See which stations intersect with the event polygon\n",
    "\n",
    "event_stns = stns_gdf[stns_gdf[\"intersects\"] == True].reset_index(\n",
    "    drop=True\n",
    ")  # Get just those stations, drop the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...AND with start and end date within the event timeframe\n",
    "event_stns = event_stns[\n",
    "    (event_stns[\"start-date\"] < event_end_date)\n",
    "    & (event_stns[\"end-date\"] > event_start_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992af301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which stations are in there?\n",
    "event_stns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d9b1c",
   "metadata": {},
   "source": [
    "## Step 2: Investigate specific stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = f\"s3://{BUCKET_NAME}/{MERGE_DIR}/SGXWFO/SGXWFO_SDUSS.zarr\"\n",
    "\n",
    "ds1 = xr.open_zarr(url1)\n",
    "\n",
    "df1 = ds1.to_dataframe()\n",
    "df1 = df1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555cc67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = event_subset(df1, 'santa_ana_wind', 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_during_event(subset1, \"sfcWind\", \"santa_ana_wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_visualize(\"SGXWFO_SDL34\", stn_list, \"santa_ana_wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a18406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe down to 2 weeks before and after the event window\n",
    "mask = (df1[\"time\"] >= \"2007-10-05\") & (df1[\"time\"] <= \"2007-11-30\")\n",
    "df_filt = df1.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_plot(df_filt, \"tas\", \"santa_ana_wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_flag(flag_to_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Identifies flag based on numerical value assigned for plotting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_to_id : int\n",
    "        specific flag to identify\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fn_name : str\n",
    "        name of QA/QC flag\n",
    "    \"\"\"\n",
    "\n",
    "    flag_df = pd.read_csv(\"../data/era_qaqc_flag_meanings.csv\")\n",
    "    fn_name = flag_df.loc[flag_df[\"Flag_value\"] == int(flag_to_id)][\n",
    "        \"QAQC_function\"\n",
    "    ].values[0]\n",
    "\n",
    "    return fn_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e9c63",
   "metadata": {},
   "source": [
    "## Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d15fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some kind of map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f3e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table / stats \"read out\" on extremes during the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table / stats \"read out\" on QC flags, including if we think refinement to QC tests would improve coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some function/thing in terms of how many stations \"detected\" the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary information via markdown close out of what we have learned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdp-slim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
