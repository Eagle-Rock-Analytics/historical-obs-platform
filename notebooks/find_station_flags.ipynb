{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24263655-e41b-4a21-89a4-c257218966b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:48:40.598634Z",
     "iopub.status.busy": "2024-10-08T17:48:40.597905Z",
     "iopub.status.idle": "2024-10-08T17:48:40.610572Z",
     "shell.execute_reply": "2024-10-08T17:48:40.609081Z",
     "shell.execute_reply.started": "2024-10-08T17:48:40.598586Z"
    }
   },
   "source": [
    "# Find weather stations that set flags\n",
    "From the AWS data catalog of station data, find the subset of weather stations that set flags \n",
    "<br>Output a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8d2d2",
   "metadata": {},
   "source": [
    "## 1. Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37908e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flags(station_ds):\n",
    "    \"\"\"Find unique flags in a Dataset.\n",
    "    Filters through flag variables; assumes flag variables contain the substring '_eraqc'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    station_ds: xr.Dataset\n",
    "        Dataset containing station data, with each variable as a unique data variable\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    unique_flags: list or None\n",
    "        List of unique flag values found in station_ds\n",
    "        Returns None if no flags found for any variable\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the string names of the eraqc flag variables\n",
    "    era_flag_var_names = [var for var in station_ds.data_vars if \"_eraqc\" in var]\n",
    "\n",
    "    # Subset Dataset to just contain flag variables\n",
    "    station_flags_ds = station_ds[era_flag_var_names]\n",
    "\n",
    "    # Check for nulls in the flag variables\n",
    "    # If all are null, that means the station set no flags for this event!\n",
    "    all_null = station_flags_ds.to_array().isnull().all().item()\n",
    "    unique_flags = None\n",
    "\n",
    "    # If there are some flags set, find out what they are\n",
    "    if not all_null:\n",
    "        # Stack all the variables, since we don't care which variables the flags belong to\n",
    "        # Makes it easier to search the array (fewer lines of code :)\n",
    "        # Works like np.flatten, but on an xarray object\n",
    "        stacked = station_flags_ds.to_array().stack(\n",
    "            {\"everything\": [\"variable\", \"time\"]}\n",
    "        )\n",
    "\n",
    "        # Drop all non-null values\n",
    "        # i.e. [nan, nan, 23, nan, 17] --> [23, 17]\n",
    "        all_flags = stacked.where(~stacked.isnull(), drop=True)\n",
    "\n",
    "        # Get unique flag values as integers\n",
    "        # nan is treated as a float so the .isnull() step converted floats to ints (I think)\n",
    "        # i.e. [23.0, 23.0, 23.0, 17.0, 23.0, 19.0, 19.0] --> [23, 17, 19]\n",
    "        unique_flags = list(np.unique(all_flags.values).astype(int))\n",
    "\n",
    "    return unique_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e980d4",
   "metadata": {},
   "source": [
    "## 2. Read in county shapefile and station metadata csv\n",
    "County shapefile is used for getting event geometry <br>Station metadata is used to get the station ids to read in station data from the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a list of weather stations\n",
    "# We just use the names of the stations to filter\n",
    "# Ideally I'd like to see this moved to the AWS bucket\n",
    "train_stns = pd.read_csv(\"../data/qaqc_training_station_list.csv\")\n",
    "\n",
    "# Create new geometry column from lat and lon columns\n",
    "# This will enable us to filter through the GeoDataFrame using our county geometry\n",
    "train_stns = gpd.GeoDataFrame(\n",
    "    train_stns,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        train_stns.longitude, train_stns.latitude, crs=\"EPSG:4326\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f18ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in county shapefiles from S3\n",
    "ca_counties = gpd.read_file(\n",
    "    \"s3://wecc-historical-wx/0_maps/ca_counties/CA_Counties.shp\"\n",
    ")\n",
    "ca_counties = ca_counties.to_crs(train_stns.crs)  # Convert to station CRS\n",
    "# ca_counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the stations and all the counties\n",
    "# This is a check to ensure both have the same projection\n",
    "fig, ax = plt.subplots()\n",
    "ca_counties.boundary.plot(color=\"black\", ax=ax, linewidth=0.75, zorder=10)\n",
    "train_stns.geometry.plot(markersize=0.9, ax=ax, zorder=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c665d",
   "metadata": {},
   "source": [
    "## 3. Set your event date and (optional) event geometry\n",
    "For example, lets use the Montecito mudslide from January 5-9, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_start_date = \"2018-01-01\"  # Start a few days before the mudslide\n",
    "event_end_date = \"2018-01-09\"\n",
    "\n",
    "event_geom = ca_counties[ca_counties[\"NAME\"] == \"Santa Barbara\"]  # Get event geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7537350",
   "metadata": {},
   "source": [
    "## 4. Get the stations that intersect the event geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18387ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stns[\"intersects\"] = train_stns.intersects(\n",
    "    event_geom.unary_union\n",
    ")  # See which stations intersect with the event polygon\n",
    "event_stns = train_stns[train_stns[\"intersects\"] == True].reset_index(\n",
    "    drop=True\n",
    ")  # Get just those stations, drop the others\n",
    "event_stns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534579fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot to visualize the stations and event poly\n",
    "fig, ax = plt.subplots()\n",
    "event_geom.boundary.plot(color=\"black\", ax=ax, zorder=10)\n",
    "event_stns.geometry.plot(markersize=15, ax=ax, zorder=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774a027",
   "metadata": {},
   "source": [
    "## 5. Filter through stations to see if flags were set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc48585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags, network, and station ID will be stored here\n",
    "# Dictionary can be easily convered to a DataFrame and output as a csv\n",
    "stations_with_flags = {\"network\": [], \"era-id\": [], \"flags\": []}\n",
    "\n",
    "# Loop through each station to look for flags\n",
    "for i in tqdm(range(len(event_stns))):\n",
    "    # Get info for one station\n",
    "    network_name, station_id = event_stns.iloc[i][[\"network\", \"era-id\"]]\n",
    "\n",
    "    station_ds = xr.open_zarr(f\"s3://wecc-historical-wx/3_qaqc_wx/{network_name}/{station_id}.zarr\").compute()\n",
    "\n",
    "    # Reduce dimension of object\n",
    "    # \"station\" is a singleton dimension\n",
    "    station_ds = station_ds.squeeze()\n",
    "\n",
    "    # Subset Dataset to event time period\n",
    "    station_ds = station_ds.sel(time=slice(event_start_date, event_end_date))\n",
    "\n",
    "    # Look for flags\n",
    "    # If no flags found, find_flags returns None\n",
    "    unique_flags = find_flags(station_ds)\n",
    "\n",
    "    # If flags are found, save them to the dictionary\n",
    "    if unique_flags is not None:\n",
    "        stations_with_flags[\"network\"].append(network_name)\n",
    "        stations_with_flags[\"era-id\"].append(station_id)\n",
    "        stations_with_flags[\"flags\"].append(unique_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a DataFrame\n",
    "# Note: No record which variables these flags belong to\n",
    "stations_with_flags_df = pd.DataFrame(stations_with_flags)\n",
    "stations_with_flags_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist-obs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
