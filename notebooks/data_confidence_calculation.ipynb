{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab78e098",
   "metadata": {},
   "source": [
    "# Order Stations by Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bded32",
   "metadata": {},
   "source": [
    "This notebook sorts HDP stations by their QC percentage. It does this by calculating the number of QAQC flags set per station.\n",
    "- High values indicate that a station has a large number of flagged observations.\n",
    "- Low values indicate that a station has a few number of flagged observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c169c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Set AWS credentials\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3_cl = boto3.client(\"s3\")  # for lower-level processes\n",
    "\n",
    "# Set relative paths to other folders and objects in repository.\n",
    "BUCKET_NAME = \"wecc-historical-wx\"\n",
    "MERGE_DIR = \"4_merge_wx\"\n",
    "stations_csv_path = f\"s3://{BUCKET_NAME}/{MERGE_DIR}/all_network_stationlist_merge.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_count(\n",
    "    flag_df: pd.DataFrame, running_count_df, station_name: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates consolidated flag counts dataframe for input per-variable station flag counts dataframe and then adds it to the running flag count dataframe.\n",
    "    Helper function for station_counts_table().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag_df: pd.DataFrame\n",
    "        flag rates dataframe for next station\n",
    "    running_count_df: pd.DataFrame\n",
    "        dataframe of previously added station flag counts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    counts_df_merged: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    # Make the eraqc_flag_values column the index\n",
    "    flag_df = flag_df.set_index(\"eraqc_flag_values\")\n",
    "\n",
    "    # Count up the flagged observations - so counts in all but the \"no_flag\" and \"total_obs_count\" rows\n",
    "    subset = flag_df[flag_df.index.isin([\"no_flag\", \"total_obs_count\"])]\n",
    "    counts_sum = subset.sum(axis=1)\n",
    "\n",
    "    # Transpose\n",
    "    counts_sum_df = counts_sum.to_frame()\n",
    "    counts_sum_df = counts_sum_df.transpose()\n",
    "\n",
    "    # Select only the two relevant columns\n",
    "    counts_sum_df[[\"no_flag\", \"total_obs_count\"]]\n",
    "\n",
    "    # Calculate the fraction of flagged observations, as the station \"confidence\"\n",
    "    counts_sum_df[\"qc_percent\"] = (\n",
    "        1 - counts_sum_df[\"no_flag\"] / counts_sum_df[\"total_obs_count\"]\n",
    "    )\n",
    "\n",
    "    # Add in station name to index\n",
    "    counts_sum_df.index = [station_name]\n",
    "\n",
    "    counts_sum_df = counts_sum_df.reset_index()\n",
    "\n",
    "    if len(running_count_df) == 0:\n",
    "        return counts_sum_df\n",
    "\n",
    "    else:\n",
    "        counts_df_merged = pd.merge(counts_sum_df, running_count_df, how=\"outer\")\n",
    "        return counts_df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_counts_table(timestep: str) -> None:\n",
    "    \"\"\"\n",
    "    Generates a table of total flag counts per station.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestep: str\n",
    "        if set to 'hourly', generate flag count table from hourly flag counts\n",
    "        if set to 'native', generate flag count table from native flag counts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    ## Setup\n",
    "\n",
    "    # Only run for a valid \"timestep\" input\n",
    "    if timestep not in (\"hourly\", \"native\"):\n",
    "        print(\"invalid timestep: \", timestep)\n",
    "        return None\n",
    "\n",
    "    # List of networks to iterate over\n",
    "    station_list = pd.read_csv(stations_csv_path)\n",
    "    network_list = station_list[\"network\"].unique()\n",
    "\n",
    "    # The function iteratively adds in flag counts to this dataframe\n",
    "    flag_count_df = []\n",
    "\n",
    "    for network in network_list:\n",
    "        # Point to folder containing station flag count CSVs\n",
    "        flags_prefix = f\"{MERGE_DIR}/{network}/eraqc_counts_{timestep}_timestep\"\n",
    "\n",
    "        ## Merge flag counts\n",
    "\n",
    "        # Loop through all CSVs at the given level\n",
    "        for item in s3.Bucket(BUCKET_NAME).objects.filter(Prefix=flags_prefix):\n",
    "            obj = s3_cl.get_object(Bucket=BUCKET_NAME, Key=item.key)\n",
    "            flags = pd.read_csv(obj[\"Body\"])\n",
    "            station_name = item.key.split(flags_prefix + \"/\")[1].split(\"_flag\")[0]\n",
    "            # the CSV is empty\n",
    "            if flags.empty:\n",
    "                continue\n",
    "            # the CSV is not empty\n",
    "            else:\n",
    "                # Send current dataframe and dataframe of previously generated rates to helper function\n",
    "                flag_count_df = _pairwise_count(flags, flag_count_df, station_name)\n",
    "\n",
    "    # Rename \"index\" column as \"station\"\n",
    "    flag_count_df = flag_count_df.rename(columns={\"index\": \"station\"})\n",
    "\n",
    "    # Sort by \"qc_percent\"\n",
    "    flag_counts_sorted = flag_count_df.sort_values(\n",
    "        by=\"qc_percent\", ascending=False\n",
    "    )\n",
    "\n",
    "    ## Send final flag rates file to AWS as CSV\n",
    "    csv_s3_filepath = (\n",
    "        f\"s3://wecc-historical-wx/4_merge_wx/station_{timestep}_confidence.csv\"\n",
    "    )\n",
    "\n",
    "    print(f\"Sending {timestep} timestep station flag counts CSV to: {csv_s3_filepath}\")\n",
    "    flag_counts_sorted.to_csv(csv_s3_filepath, index=False)\n",
    "\n",
    "    ## Output time elapsed\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time) / 60\n",
    "    print(f\"{time_elapsed} minutes\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_counts_table('hourly') # takes ~20-40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704288f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_counts_table(\"native\")  # expected to take ~30 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdp-slim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
